[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "J.Isaula",
    "section": "",
    "text": "Welcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJan 14, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\n  \n\n\n\n\nMicroeconomía Intermedia con R\n\n\nCurvas de Indiferencia\n\n\n\n\nEconomía\n\n\nMicroeconomía\n\n\nR\n\n\nRStudio\n\n\n\n\n\n\n\n\n\n\n\nJan 9, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog-Isaula",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nMicroeconomía Intermedia con R\n\n\nUtilidad y sus Curvas de Indiferencia\n\n\n\n\nEconomía\n\n\nMicroeconomía\n\n\nR\n\n\nRStudio\n\n\n\n\n\n\n\n\n\n\n\nJan 9, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nMachine Learning en Tidyverse\n\n\nMúltiples Modulos con broom\n\n\n\n\nMachine Learning\n\n\nForecasting\n\n\nR\n\n\nRStudio\n\n\nbroom\n\n\n\n\n\n\n\n\n\n\n\nSep 30, 2022\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nModelo Prophet de Facebook\n\n\nPronóstico aplicado al tipo de cambio USD/HNL\n\n\n\n\nProphet\n\n\nForecasting\n\n\nR\n\n\nRStudio\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2022\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nARIMA Models in Python\n\n\n\n\n\n\n\nARIMA\n\n\nForecasting\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2021\n\n\nJuan Isaula\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Microeconomía Intermedia con R",
    "section": "",
    "text": "Una forma de iniciar el análisis de los individuos es plantear un conjunto básico de postulados, o axiomas, que describen el comportamiento racional del mismo. Supondremos que dadas tres canastas de consumo cualesquiera \\((x_1,x_2)\\), \\((y_1,y_2)\\) y \\((z_1,z_2)\\). El consumidor puede ordenarlas según su atractivo. Es decir, puede decidir que una de ellas es estrictamente mejor que la otra o bien que le son indiferentes.\nUtilizaremos la notación:\n\n\\(\\succ\\) Para indicar que una canasta se prefiere estrictamente a otra, es decir, \\((x_1,x_2) \\succ (y_1,y_2)\\).\n\\(\\sim\\) Para indicar que al consumidor le resulta indiferente elegir una u otra de las dos canastas de bienes y lo representamos matemáticamente como \\((x_1,x_2)\\sim (y_1,y_2)\\).\n\\(\\succeq\\) Para indicar si el individuo prefiere una de las dos canastas o es indiferente entre ellas, decimos que prefiere debilmente la canasta \\((x_1,x_2)\\) a la \\((y_1,y_2)\\) y escribimos \\((x_1,x_2)\\succeq (y_1,y_2)\\).\n\n\n\nCon base en lo anterior, ya estamos preparados para conocer los tres axiomas de la teoría del consumidor. Decimos que las preferencias son:\n\nCompletas: suponemos que es posible comprar dos canastas cualesquiera, es decir, dada cualquier canasta \\(\\textbf{X}\\) y cualquier canasrta \\(\\textbf{Y}\\), suponemos que \\((x_1,x_2)\\succeq (y_1,y_2)\\) o \\((y_1,y_2) \\succeq (x_1,x_2)\\) o las dos cosas, en cuyo caso el consumidor es indiferente entre las dos canastas.\nReflexivas: suponemos que cualquier canasta es al menos tan buena como ella misma: \\((x_1,x_2)\\succeq (y_1,y_2)\\).\nTransitiva: si \\((x_1,x_2)\\succeq (y_1,y_2)\\) y \\((y_1,y_2)\\succeq (z_1,z_2) \\Longrightarrow (x_1,x_2)\\succeq (z_1,z_2)\\). Es decir, si el consumidor piensa que la canasta \\(\\textbf{X}\\) es al menos tan buena como la \\(\\textbf{Y}\\) y que la \\(\\textbf{Y}\\) es al menos tan buena como la \\(\\textbf{Z}\\), piensa que la \\(\\textbf{X}\\) es al menos tan buena como la \\(\\textbf{Z}\\).\n\nConsidere que cuando nos referimos a las canastas \\(\\textbf{X}, \\textbf{Y}\\) o \\(\\textbf{Z}\\) estamos haciendo referencia a:\n\n\\(\\textbf{X} = (x_1,x_2)\\)\n\\(\\textbf{Y} = (y_1.y_2)\\)\n\\(\\textbf{Z} = (z_1,z_2)\\)\n\nSi las preferencias no fueran transitivas, podría muy bien haber un conjunto de canastas tal que ninguna de las elecciones fuera la mejor. Sin embargo, en el curso de microeconomía II estamos trabajando bajo el modelo tradicional, donde asumimos que el individuo es razonal, tomando en cuenta que siempre va a preferir mas que menos.\n\n\n\nEl primer axioma, la completitud, es dificilmente criticable, al menos en el caso de los tipos de elecciones que suelen analizar los economistas. Decir que pueden compararse dos canastas cualesquiera es decir simplemente que el consumidor es capaz de elegir entre dos canasas cualesquiera.\nEl segundo axioma, la reflexividad, plantea más problemas. Una canasta cualquiera es ciertamente tan buena como una canasta idéntica.\nEl tercer axioma, la transitividad, plantea más problemas. No esta claro que las preferencias deban tener necesariamente esta propiedad. El supuesto de que son transitivas no parece evidente desde un punto de vista puramente lógico, y, de hecho, no lo es. La transitividad es una hipótesis sobre la conducta de los individuos en sus elecciones y no una afirmación lógica. Sin embargo, no importa que sea o no un hecho lógico básico; lo que importa es que sea o no una descripción razonablemente exacta del comportamiento de los individuos.\n¿Qué pensarías de una persona que dijera que prefiere la canasta \\(\\textbf{X}\\) a la \\(\\textbf{Y}\\) y la \\(\\textbf{Y}\\) a la \\(\\textbf{Z}\\), pero que también dijera que prefiere la \\(\\textbf{Z}\\) a la \\(\\textbf{X}\\)? Desde luego, lo consideraríamos como prueba de una conducta particular. Y lo que es más importante, ¿Cómo se comportaría este consumidor si tuviera que elegir entre las tres canastas \\(\\textbf{X}, \\textbf{Y}\\) y \\(\\textbf{Z}\\)?"
  },
  {
    "objectID": "posts/post-with-code/index.html#curvas-de-indiferencia",
    "href": "posts/post-with-code/index.html#curvas-de-indiferencia",
    "title": "Microeconomía Intermedia con R",
    "section": "Curvas de Indiferencia",
    "text": "Curvas de Indiferencia\nCon base en la definición previa de utilidad, podemos concluir, una función de utilidad es la que explica la cantidad de utilidad que posee un consumidor dado su consumo de dos bienes diferentes. \\(x, y\\). Una curva de indiferencia es solo una rebanada infenitesimal de esa función que describe todas las diferentes combinaciones entre dos bienes que producen la misma cantidad de utilidad (es decir, a la que una persona sería indiferente).\nSupongamos que una persona clasifica las hamburguesas \\((y)\\) y las bebidas \\((x)\\) de acuerdo con la función de utilidad\n\\[\nU(x,y) = \\sqrt{xy}\n\\]\nEn el caso de esta función, obtenemos la curva de indiferencia identificando un conjunto de combinaciones de \\(x,y\\) en el cual la utilidad tiene el mismo valor. Suponga que arbitrariamente decimos que la utilidad tiene un valor de 10. Entonces, la ecuación de esta curva sera:\n\\[\nU(x,y) = 10 = \\sqrt{xy}\n\\]Note que si elevamos esta función al cuadrado se mantiene el mismo orden, por lo cual también podemos representar esta curva de indiferencia como\n\\[\n100 = xy\n\\]\nEs importante siempre despejar este tipo de ecuaciones para \\(y\\) la importancia esta en que será mucho más facil posteriormente encontrar su tasa marginal de sustitución ( en otra sección de esta publicación estudiaremos a detalle esto), entonces, al despejar obtenemos:\n\\[\ny = \\frac{100}{x}\n\\]\nPara trazar su curva de indiferencia, lo haremos en R , a continuación les muestro como hacerlo. Puedes realizar este ejercicio en tu PC tu mismo.\n\n# 1. Primero cargamos las librerias que utilizaremos, en caso que nos las tengas \n#    instaladas sugiero lo hagas usando install.package(\"libreria\") en su consola\n#    de Rstudio.\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.5.0 \n✔ readr   2.1.2      ✔ forcats 0.5.1 \n✔ purrr   0.3.5      \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n# 2. Creamos la función de utilidad del ejemplo \nutilidad <- function(x,y){\n  sqrt(x*y) \n}\n\n# 3. Creamos una matriz para hacer un bucle en la función de utilidad\nvalores_matriz <- matrix(0,nrow = 200, ncol = 200)\n\n# 3.1 Llenamos la matriz con usando la función de utilidad \nfor(fila in 1:nrow(valores_matriz)){\n  for(columna in 1:ncol(valores_matriz)){\n    valores_matriz[fila,columna] <- utilidad(fila,columna)\n  }\n}\n\n# 4. Función que nos permitira graficar las curvas de indiferencia \n\nC_indiferencia <- function(entrada_utilidad){\n  y <- c()\n  \n  for(i in 1:50){\n    y_coord <- entrada_utilidad^2/i\n    y       <- c(y,y_coord)\n  }\n  \n  data <- data.frame(\n    x = 1:50,\n    y = y,\n    z = rep(entrada_utilidad,50)\n  )\n  \n  return(data)\n}\n\n\n# 4.1 Resultado de utilidades obtenidas \nlista_utilidades <- lapply(10, C_indiferencia)\n\nfull_df <- do.call(rbind, lista_utilidades)\n\nAhora si ya estamos preparados para graficar nuestras curvas de indiferencia para \\(10 = \\sqrt{xy}\\)\n\n# 5. Gráfico\n\nggplot() + \n  geom_point(data = full_df, aes(x = x, y = y, color = z)) + \n  geom_path(data = full_df, aes(x = x, y = y, color = z)) +\n  theme_minimal()+\n  ylim(0,100) + \n  labs(x = \"Bebidad\", y = \"Hamburguesas\") + \n  scale_color_continuous(name = \"Utilidad\")\n\n\n\n\nNote que la curva previa representa una utilidad = 10.\nA continuación te muestro un grafico animado de la curva de indiferencia previa. Para generar el gráfico presiona el boton PLAY.\n\n\n\n\n\n\nVeamos que sucede cuando tenemos diferentes niveles de utilidad, en base al resultado usted puede deducir su propio análisis.\n\nutilidad <- function(x,y){\n  sqrt(x*y) \n}\n\nvalores_matriz <- matrix(0,nrow = 200, ncol = 200)\n\nfor(fila in 1:nrow(valores_matriz)){\n  for(columna in 1:ncol(valores_matriz)){\n    valores_matriz[fila,columna] <- utilidad(fila,columna)\n  }\n}\n\nC_indiferencia <- function(entrada_utilidad){\n  y <- c()\n  \n  for(i in 1:100){\n    y_coord <- entrada_utilidad^2/i\n    y       <- c(y,y_coord)\n  }\n  \n  data <- data.frame(\n    x = 1:100,\n    y = y,\n    z = rep(entrada_utilidad,100)\n  )\n  \n  return(data)\n}\n\nlista_utilidades <- lapply(seq(from =10, to = 60, by = 10), C_indiferencia)\n\nfull_df <- do.call(rbind, lista_utilidades)\n\n\nggplot() +\n  geom_point(data = full_df, aes(x = x, y = y, color = z)) +\n  geom_path(data = full_df, aes(x = x, y = y, color = z)) +\n  theme_minimal() +\n  ylim(0,200) +\n  labs(x = \"Bebidas\", y = \"Hamburguesas\") +\n  scale_color_continuous(name = \"Utilidad\")\n\nWarning: Removed 41 rows containing missing values (`geom_point()`).\n\n\n\n\n\nAquí podemos señalar lo siguiente:\n\nA medida que aumenta la utilidad, las curvas se desplazan hacia la derecha y hacia la izquierda a medida que disminuye la utilidad.\nObserve que las curvas se inclinan hacia abajo, esto debe ser necesariamente el caso; a medida que uno aumenta su consumo de bebidas renuncia al otro bien que les era indiferente, hamburguesa.\nTodo lo que está debajo de la curva representa paquetes con menos utilidad. La teoría de la utilidad asume que un consumidor siempre buscará maximizar la utilidad.\nComprende que la pendiente no es lineal. En genera, cuanto más se tiene de algo, menos utilidad se obtendrá de otra unidad y, por el contrario, más se renunciaría a adquirir el otro bien. Esta pendiente tiene un nombre oficial: Tasa Marginal de Sustitución o TMS hablaremos de esto en una sección posterior.\n\nPero esas son solo algunas rebanadas que ya he señalado como infinitesimalmente pequeñas.\nPara concluir esta sección te dejo un gráfico animado de los diferentes niveles de utilidad, por favor presiona el boton PLAY para que logres verlo."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Modelo Prophet de Facebook",
    "section": "",
    "text": "En este post, te presento la implementación de Facebook Prophet, así como sus principales hiperparámetros ajustados para generar el modelo predictivo, dicho modelo lo implementaremos para predecir el tipo de cambio de Honduras versus el dólar EE:UU (USD/HNL), considerando que esto será unicamente para conocer el funcionamiento del modelo, no para justificar que es el mejor modelo para realizar la actividad descrita previamente."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Perfil",
    "section": "",
    "text": "Licenciado en Matemáticas con orientación en Estadística, Data Scientist y candidato a economista en UNAH; trabajo en el modelado predictivo y visualización con un enfoque en teoría economica, soy un amante de los modelos predictivos de Machine Learning y Deep Learnig. Mi trabajo actual se centra en el uso del servicio de analisis de datos de Microsoft Power BI y lenguajes de programación como R y Python para el tratamiento de datos, uso de modelos actuariales para estimación de Balances Actuariales, Reservas Técnicas, seguimiento de Indicadores Actuariales y Revalorización de Pensiones en el Instituto Hondureño de Seguridad Social.\n\nEn este blog comparto y enseño todo lo que aprendo.\nCampos de Interés y Trabajos Realizados\nBlack box models for forecasting financial time series\nBLiTZ-Bayesian LSTM for Uncertainty Quantification.\nIntermediate Microeconomics with R\nFacebook Prophet Model (Forecast Aplied to the USD/HNL exchange rate)\nMichine Learning in Tidyverse (Multiple Modules with broom)\nMachine Learning in Tidyverse (regression model and random forest model)\nActuarial Science"
  },
  {
    "objectID": "about.html#campos-de-interés-y-trabajos-realizados",
    "href": "about.html#campos-de-interés-y-trabajos-realizados",
    "title": "Perfil",
    "section": "Campos de Interés y Trabajos Realizados",
    "text": "Campos de Interés y Trabajos Realizados\n\nBlack box models for forecasting financial time series\nBLiTZ-Bayesian LSTM for Uncertainty Quantification.\nIntermediate Microeconomics with R\nFacebook Prophet Model (Forecast Aplied to the USD/HNL exchange rate)\nMichine Learning in Tidyverse (Multiple Modules with broom)\nMachine Learning in Tidyverse (regression model and random forest model)\nActuarial Science"
  },
  {
    "objectID": "about.html#paquetes-r-y-python-que-más-utilizo",
    "href": "about.html#paquetes-r-y-python-que-más-utilizo",
    "title": "CV",
    "section": "Paquetes R y Python que más utilizo",
    "text": "Paquetes R y Python que más utilizo\nTidyverse | Coleccion de paquetes orientados a manipulación, importación, exploración y visualización de datos.\nPyTorch | Biblioteca de Deep Learning con aplicaciones para redes neuronales.\nShiny | Paquete de R que facilita la creación de aplicaciones Web interactivas directamente desde R.\nlifecontingencies | Permite al usuario crear y manejar tablas de mortalidad, tablas actuariales (también tablas de decrementos múltiples). Además, contiene funciones para realizar facilmente matemáticas demográficas, financieras y actuariales en los cálculos de seguros de contingencias de vida.\nPerformanceAnalytics | Colección de funciones econométricas para el análisis de desempeño y riesg"
  },
  {
    "objectID": "about.html#paquetes-de-r-y-python-que-más-utilizo",
    "href": "about.html#paquetes-de-r-y-python-que-más-utilizo",
    "title": "Perfil",
    "section": "Paquetes de R y Python que más utilizo",
    "text": "Paquetes de R y Python que más utilizo\nTidyverse | Coleccion de paquetes orientados a manipulación, importación, exploración y visualización de datos.\nPyTorch | Biblioteca de Deep Learning con aplicaciones para redes neuronales.\nShiny | Paquete de R que facilita la creación de aplicaciones Web interactivas directamente desde R.\nlifecontingencies | Permite al usuario crear y manejar tablas de mortalidad, tablas actuariales (también tablas de decrementos múltiples). Además, contiene funciones para realizar facilmente matemáticas demográficas, financieras y actuariales en los cálculos de seguros de contingencias de vida.\nPerformanceAnalytics | Colección de funciones econométricas para el análisis de desempeño y riesg"
  },
  {
    "objectID": "posts/welcome/index.html#descripción-general-del-modelo",
    "href": "posts/welcome/index.html#descripción-general-del-modelo",
    "title": "Modelo Prophet de Facebook",
    "section": "Descripción General del Modelo",
    "text": "Descripción General del Modelo\nFacebook Prophet es un modelo y una biblioteca que proporciona características tanto de modelos lineales generalizados (MLG) como de modelos aditivos (MA), principalmente extendiendo el MLG mediante el uso de funciones de suavizado no lineal. Fue especificado por Taylor y Letham en 2017.\nProphet es un software de código abierto lanzado por el equipo Core Data Science de Facebook. Está disponible para su descarga en CRAN y PyPI. En esta ocasión usaremos el lenguaje R para implementar el modelo, sin embargo, tu puedes hacerlo en Python si es de tu preferencia.\nProphet funciona mejor con series temporales que tienen fuertes efectos estacionales y varias temporadas de datos históricos. Prophet es resistente a los datos faltantes y los cambios en la tendencia, y por lo general maneja bien los valores atípicos. Prophet esta diseñado especificamente para la predicción de series temporales de negocios.\nSu modelo aditivo que consta de cuatro componentes, esta dado por:\n\\[\ny(t) = g(t) + s(t) + h(t) + \\epsilon_{t}\n\\]\ndonde,\n\n\\(g(t)\\): Representa la tendencia y el objetivo es capturar la tendencia de la serie. Por ejemplo, es probable que la cantidad de vistas de anuncios de Facebook aumente con el tiempo a medida que más personas se unen a la red. Pero, ¿cuál sería la función exacta del aumento?\n\\(s(t)\\): Es el componente de Estacionalidad. El número de anuncios también puede depender de la temporada. Por ejemplo, en el hemisferio norte durante los meses de verano, es probable que las personas pasen más tiempo al aire libre y menos tiempo frente a sus computadoras. Tales fluctuaciones pueden ser muy diferentes para diferentes series temporales de negocios. El segundo componente es, por lo tanto, una función que modela las tendencias estacionales.\n\\(h(t)\\): Representa los efectos de las vaciones. Usamos la información para días festivos que tienen claro impacto en la mayoria de las series temporales comerciales. Tenga en cuenta que las vaciones varían entre años, países, etc. Y, por lo tanto, la información debe proporcionarse explícitamente al modelo.\n\\(\\epsilon_{t}\\): Es el término de error. Representa fluctuaciones aleatorias que el modelo no puede explicar. Como de costumbre, se supone que \\(\\epsilon_{t}\\) sigue una distribución \\(N(0,1)\\) con media cero y varianza desconocida \\(\\sigma\\) que debe derivarse de los datos ."
  },
  {
    "objectID": "posts/welcome/index.html#hiperparámetros",
    "href": "posts/welcome/index.html#hiperparámetros",
    "title": "Modelo Prophet de Facebook",
    "section": "Hiperparámetros",
    "text": "Hiperparámetros\nHay varios parámetros personalizables en la implementación de Facebook Prophet (revisar), siendo los principales:\n\nPuntos de cambio: definen los cambios de tendencia. Estos pueden ser encontrados por el propio algoritmo o también pueden ser definidos y ajustados por el analista.\nEstacionalidad: define las funciones periódicas que pueden afectar a la serie temporal. De forma predeterminada, Prophet considera la estacionalidad anual, semanal y diaria e intenta encontrar tendencias que representan esos efectos periódicos en los datos.\nDías festivos: los días especiales (días festivos o cualquier otro evento recurrente) también pueden ser modelados por el modelo aditivo.\n\nEn R, se usa la API de ajuste de modelo normal. Proporcionamos una función prophet que realiza el ajuste y devuelve un objeto de modelo. Posteriormeente usted puede llamar a la función predict y plot en este objeto modelo."
  },
  {
    "objectID": "posts/welcome/index.html#datos-y-preparación",
    "href": "posts/welcome/index.html#datos-y-preparación",
    "title": "Modelo Prophet de Facebook",
    "section": "Datos y Preparación",
    "text": "Datos y Preparación\nLos datos que utilizaremos los encontramos en Yahoo! Finance. Así como Python tiene un paquete para importar datos directamente de Yahoo Finance, R también cuenta con sus paquetes particular que nos permiten realizar una tarea similar. Necesitamos los siguiente paquetes:\n\nlibrary(TTR)\nlibrary(quantmod)\n\nLoading required package: xts\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nSi aún no los tienes instalados sugiero los instales usando install.packages(\"name paquete\"). Muy bien, ahora si estamos listos para poder extraer nuestros datos de yahoo finance y para ello usaremos la funcion getSymbols del paquete quantmod. Veamos,\n\ndf <- getSymbols('HNL=X',src = 'yahoo',\n                 from = \"2010-01-01\",\n                 to = \"2022-12-20\",\n                 auto.assign = FALSE)\n\nTenga en cuenta que from =  \"2010-01-01\" y to = \"2022-12-20\" nos ayudan a indicar desde que fecha quiero comenzar a tomar mis datos y hasta que fecha quiero tomarlos. Además, auto.assign = FALSE indica a getSymbols que devuelva los datos.\nAhora, conozcamos nuestros datos\n\nhead(df)\n\n           HNL=X.Open HNL=X.High HNL=X.Low HNL=X.Close HNL=X.Volume\n2010-01-04     18.690     18.691    18.517      18.518            0\n2010-01-05     18.550     18.550    18.550      18.550            0\n2010-01-06     18.572     18.645    18.544      18.545            0\n2010-01-07     18.451     18.550    18.451      18.539            0\n2010-01-08     18.556     18.556    18.556      18.556            0\n2010-01-11     18.550     18.550    18.550      18.550            0\n           HNL=X.Adjusted\n2010-01-04         18.518\n2010-01-05         18.550\n2010-01-06         18.545\n2010-01-07         18.539\n2010-01-08         18.556\n2010-01-11         18.550\n\n\nDe estos datos únicamente usaremos el valor de cierre (HNL=X.Close) de manera diaria del lempira hondureño contra el dólar, para enfocarnos solo en esos datos, primero convertiremos nuestro conjunto de datos df en un dataframe, dado que inicialmente es un objeto de tipo xts,\n\nclass(df)\n\n[1] \"xts\" \"zoo\"\n\n\npara realizar el cambio a un dataframe, considere la siguiente función\n\nxts_to_datframe<-function(data_xts){\n  df_t<-data.frame(fecha=(index(data_xts)),\n                   value=coredata(data_xts))\n  colnames(df_t)<-c(\"ds\", \"y\")\n  df_t\n}\n\nTiene que tener cuidado con el nombramiento de sus columnas, dado que prophet reconoce unicamente marcos de datos con columnas nombras como ds y y, qu contienen la fecha y el valor numérico de sus observaciones respectivamente. Con esto en mente, pasemos a transformar df a un objeto de clase dataframe por medio de la función que construimos previamente:\n\nHNL <- xts_to_datframe(df$`HNL=X.Close`) \nclass(HNL)\n\n[1] \"data.frame\"\n\n\nPuede apreciar que ya tenemos nuestro marco de datos como un dataframe, y estamos listos para comenzar a crear nuestro modelo."
  },
  {
    "objectID": "posts/welcome/index.html#implementación-del-modelo",
    "href": "posts/welcome/index.html#implementación-del-modelo",
    "title": "Modelo Prophet de Facebook",
    "section": "Implementación del Modelo",
    "text": "Implementación del Modelo\nPrimero visualicemos nuestros datos\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.5.0 \n✔ readr   2.1.2      ✔ forcats 0.5.1 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::first()  masks xts::first()\n✖ dplyr::lag()    masks stats::lag()\n✖ dplyr::last()   masks xts::last()\n\nlibrary(ggplot2)\n\nHNL %>% ggplot(aes(x = ds, y = y))+\n  geom_line()+\n  theme_minimal()+\n   labs(title = 'Datos Historicos del Tipo de Cambio del USD/HNL',\n       subtitle = '2010 - 2022',\n       x = 'Fecha',\n       y = 'HNL',\n       caption = 'Elaboracion propia con datos de yahoo finance')\n\n\n\n\n\nlibrary(prophet)\n\nLoading required package: Rcpp\n\n\nLoading required package: rlang\n\n\n\nAttaching package: 'rlang'\n\n\nThe following objects are masked from 'package:purrr':\n\n    %@%, as_function, flatten, flatten_chr, flatten_dbl, flatten_int,\n    flatten_lgl, flatten_raw, invoke, splice\n\nm <- prophet(HNL,daily.seasonality = TRUE)\n\nfuture <- make_future_dataframe(m,periods = 3,freq = 'day')\ntail(future)\n\n             ds\n3380 2022-12-16\n3381 2022-12-19\n3382 2022-12-20\n3383 2022-12-21\n3384 2022-12-22\n3385 2022-12-23\n\n\n\nforecast <- predict(m, future)\n\ndyplot.prophet(m, forecast)\n\n\n\n\n\nDe la figura previa,\n\nLos puntos negros representan medidas reales\nLa linea azul el pronóstico de Prophet\nLa banda azul representa el intervalo de incertidumbre"
  },
  {
    "objectID": "posts/welcome/index.html#desglose-del-pronóstico",
    "href": "posts/welcome/index.html#desglose-del-pronóstico",
    "title": "Modelo Prophet de Facebook",
    "section": "Desglose del Pronóstico",
    "text": "Desglose del Pronóstico\nSi bien el pronóstico arroja muchas cosas, podemos centrarnos en algunas como:\n\nds fecha que se pronostica\nyhat predicción para el valor y (tipo de cambio) ese día en particular.\nyhat_lower valor esperado más bajo para el rango del valor y previsto ese día\nyhat_upper valor esperado más alto para el rango de valor y previsto de ese día\n\nCon tail() podemos ver la salida de los últimos días pronosticados los cuales son 21, 22 y 23 de diciembre 2022.\n\ntail(forecast[c('ds', 'yhat', 'yhat_lower', 'yhat_upper')])\n\n             ds     yhat yhat_lower yhat_upper\n3380 2022-12-16 24.10924   23.40298   24.86902\n3381 2022-12-19 24.04473   23.33234   24.78901\n3382 2022-12-20 24.11075   23.32914   24.83456\n3383 2022-12-21 24.08755   23.29702   24.83339\n3384 2022-12-22 24.12633   23.38198   24.85544\n3385 2022-12-23 24.13436   23.40071   24.89330\n\n\nSegun nuestros resultados, nuestro modelo nos ve obteniendo para el día 21 de diciembre entre 23.35901 (yhat_lower) y 24.83438 (yhat_upper) lempiras por un dolar de EE.UU.\nPara entender el pronóstico más a detalle, podemos gráficar sus componentes con:\n\nprophet_plot_components(m,forecast)\n\n\n\n\nRecuerde que el fin de este post, no es abogar por el uso indiscriminado de Prophet como el mejor modelo para pronosticar el tipo de cambio hondureño vs el dólar. Espero hayas conocido las generalidades de este modelo y su utilidad en el ambito predictivo."
  },
  {
    "objectID": "posts/Machinne Learnig - Tidyverse/index.html",
    "href": "posts/Machinne Learnig - Tidyverse/index.html",
    "title": "Machinne Learning en Tidyverse",
    "section": "",
    "text": "Asumire que el lector tiene cierto conocimiento de la teoría de modelos lineales, en caso de no ser así, no te preocupes visita este link para que puedas ir a leer las generalidades de estos modelos y su uso en R, principalmente los tres paquetes de broom que le permiten explorar estos modelos. En este post trataremos de combinar estas técnica para aprender más sobre estos modelos y sus datos."
  },
  {
    "objectID": "posts/Machinne Learnig-Tidyverse/index.html",
    "href": "posts/Machinne Learnig-Tidyverse/index.html",
    "title": "Machinne Learning en Tidyverse",
    "section": "",
    "text": "Asumire que el lector tiene cierto conocimiento de la teoría de modelos lineales, en caso de no ser así, no te preocupes visita este link para que puedas ir a leer las generalidades de estos modelos y su uso en R, principalmente los tres paquetes de broom que le permiten explorar estos modelos. En este post trataremos de combinar estas técnica para aprender más sobre estos modelos y sus datos."
  },
  {
    "objectID": "posts/tidyverse/index.html",
    "href": "posts/tidyverse/index.html",
    "title": "Machine Learning en Tidyverse",
    "section": "",
    "text": "Asumire que el lector tiene cierto conocimiento de la teoría de modelos lineales, en caso de no ser así, no te preocupes visita este link para que puedas ir a leer las generalidades de estos modelos y su uso en R, principalmente los tres paquetes de broom que le permiten explorar estos modelos. En este post trataremos de combinar estas técnica para aprender más sobre estos modelos y sus datos.\nA continuación cargaremos algunos de los paquetes que nos ayudaran para poder realizar nuestra tarea,\n\nlibrary(tidyverse) # para manipulación de datos\nlibrary(gapminder) # marco de datos que utilizaremos \nlibrary(dslabs)    # conjunto de datos y funciones para analisis de datos\nlibrary(broom)     # Resumen informacion sobre objetos estadisticos en tibbles\n\nRecuerde que el marco de gapminder contiene informacion sobbre cada país desde 1960 hasta 2016. Crearemos una variable que llamaremos gap_anidado para obtener que las características de cada país este anidadas como un tibble. La ventaja de usar estos tibble es que podemos construir modelos lineales simples que predicen la esperanza de vida por año para cada país. Nos centraremos en aprender a usar los coeficientes de estos modelos para obtener nuevos conocimientos sobre los datos de gapminder.\n\ngap_anidado <- gapminder %>% group_by(country) %>% nest()\n\nhead(gap_anidado)\n\n# A tibble: 6 × 2\n# Groups:   country [6]\n  country             data             \n  <fct>               <list>           \n1 Albania             <tibble [57 × 8]>\n2 Algeria             <tibble [57 × 8]>\n3 Angola              <tibble [57 × 8]>\n4 Antigua and Barbuda <tibble [57 × 8]>\n5 Argentina           <tibble [57 × 8]>\n6 Armenia             <tibble [57 × 8]>\n\n\nTal como lo mencionamos previamente, gap_anidado contiene las características de cada país anidadas como un tibble. Con esto hecho, procederemos a construir modelos lineales para cada país, para ello usaremos la función map() del paquete purrr\n\ngap_models <- gap_anidado %>% \n  mutate(model = map(data, ~lm(life_expectancy~year,data = .x)))\n\ngap_models\n\n# A tibble: 185 × 3\n# Groups:   country [185]\n   country             data              model \n   <fct>               <list>            <list>\n 1 Albania             <tibble [57 × 8]> <lm>  \n 2 Algeria             <tibble [57 × 8]> <lm>  \n 3 Angola              <tibble [57 × 8]> <lm>  \n 4 Antigua and Barbuda <tibble [57 × 8]> <lm>  \n 5 Argentina           <tibble [57 × 8]> <lm>  \n 6 Armenia             <tibble [57 × 8]> <lm>  \n 7 Aruba               <tibble [57 × 8]> <lm>  \n 8 Australia           <tibble [57 × 8]> <lm>  \n 9 Austria             <tibble [57 × 8]> <lm>  \n10 Azerbaijan          <tibble [57 × 8]> <lm>  \n# … with 175 more rows\n\n\n\n\n\\[y = \\alpha + \\beta x\\]\nRepasemos brevemente cómo interpretar los coeficientes para un modelo de regresión lineal simple. Recuerda que esto implica calcular dos términos de coeficientes que relacionan la variable dependiente con la variable independiente \\(x\\).\nPara nuestros modelos, las variales:\n\n\\(y\\): Representa la esperanza de vida en relación con el año (variable \\(x\\)).\n\\(\\alpha\\): Representa el coeficiente del intercepto, nos dice la esperanza en el año 0. Esto no es significativo para nuestros datos, por lo que lo pasaremos por alto.\n\\(\\beta\\): Es el coeficiente del año (variable \\(x\\)), que para un modelo de regresión lineal simple corresponde directamente a la pendiente del mismo.\n\nUsando la función tidy() del paquete broom en el primer modelo, aprenderemos que con cada año que pasa la esperanza de vida promedio de la población de este país en particular aumenta aproximadamente 0.23 años. Este enfoque puede brindarle información sobre el crecimiento o la falta de crecimiento en la esperanza de vida a lo largo del tiempo para los países que esta modelando.\n\ntidy(gap_models$model[[1]])\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept) -397.     12.4         -32.1 2.48e-37\n2 year           0.236   0.00622      38.0 3.72e-41\n\n\n\n\n\nPuede generar estos coeficientes mapeando la funcíon tidy() para cada uno de nuestros modelos y luego simplificando el nuevo marco de datos usando la función unnest(). Esto da como resultado un tibble que contiene la estimación para cada coeficiente de cada país.\n\ngap_models %>% \n  mutate(coef = map(model, ~tidy(.x))) %>% \n  unnest(coef)\n\n# A tibble: 370 × 8\n# Groups:   country [185]\n   country             data     model  term    estimate std.e…¹ stati…²  p.value\n   <fct>               <list>   <list> <chr>      <dbl>   <dbl>   <dbl>    <dbl>\n 1 Albania             <tibble> <lm>   (Inter… -3.97e+2 1.24e+1   -32.1 2.48e-37\n 2 Albania             <tibble> <lm>   year     2.36e-1 6.22e-3    38.0 3.72e-41\n 3 Algeria             <tibble> <lm>   (Inter… -1.10e+3 4.05e+1   -27.2 1.51e-33\n 4 Algeria             <tibble> <lm>   year     5.86e-1 2.04e-2    28.8 7.84e-35\n 5 Angola              <tibble> <lm>   (Inter… -7.48e+2 1.12e+1   -67.0 2.03e-54\n 6 Angola              <tibble> <lm>   year     4.01e-1 5.62e-3    71.4 6.69e-56\n 7 Antigua and Barbuda <tibble> <lm>   (Inter… -3.79e+2 1.56e+1   -24.2 5.19e-31\n 8 Antigua and Barbuda <tibble> <lm>   year     2.26e-1 7.87e-3    28.8 7.64e-35\n 9 Argentina           <tibble> <lm>   (Inter… -3.56e+2 7.67e+0   -46.4 8.83e-46\n10 Argentina           <tibble> <lm>   year     2.15e-1 3.86e-3    55.7 4.58e-50\n# … with 360 more rows, and abbreviated variable names ¹​std.error, ²​statistic\n\n\n\n\n\nAnteriormente aprovechamos la función tidy() de broom para explorar los coeficientes de nuestros modelos. Al hacerlo, obtuvimos información sobre cómo cambió la esperanza de vida con el tiempo para cada uno de los países en nuestro conjunto de datos. Ahora, aprenderá a usar la función glance() de broom para medir que tan bien se ajusta cada uno de estos modelos a sus datos subyacentes.\nUna forma de medir el ajuste de un modelo de regresión lineal es calcular su métrica \\(R^2\\)\n\\[\nR^2 = \\frac{\\%~variación~explicada~por~el~modelo}{\\%~variación~total~de~los~datos}\n\\]\nLa métrica \\(R^2\\) mide la relación entre la variación explicada por el modelo de regresión y la variación total de los datos. Toma valores entre 0 y 1.\nEn la siguiente figura, le muestro dos ejemplos, el primero con un valor alto y el segundo con un valor bajo de su \\(R^2\\) respectivamente. Note que en el caso donde el \\(R^2 = 0.009\\) es bajo o cercano a cero, esto nos indica que un modelo lineal esta capturando una cantidad proporcionalmente pequeña de la variación en los datos y. por lo tanto, no se ajusta bien. Por el contrario el modelo con \\(R^2 = 0.965\\) valor que es más cercano a 1, lo que indica que este modelo lineal se ajusta bien a los datos. Puede evaluar el ajuste de los modelos midiendo el valor del \\(R^2\\) para cada modelo.\n\nMuy bien, con el conocimiento previo, hechemos un vistazo a nuestros modelos. Para ello usamos map() y glance() para crear un marco de datos de estadísticas de resumen para cada modelo almacenado como la columna coef. Luego, puede simplificar estos marcos de datos usando la función unnest(). Esto nos dará como resultado un tibble que contendrá las estadisticas del modelo para cada modelo de país.\n\nmodel_perf <- gap_models %>% \n  mutate(coef = map(model,~glance(.x))) %>% \n  unnest(coef)\n\nmodel_perf\n\n# A tibble: 185 × 15\n# Groups:   country [185]\n   country    data     model r.squ…¹ adj.r…² sigma stati…³  p.value    df logLik\n   <fct>      <list>   <lis>   <dbl>   <dbl> <dbl>   <dbl>    <dbl> <dbl>  <dbl>\n 1 Albania    <tibble> <lm>    0.963   0.963 0.772  1443.  3.72e-41     1  -65.1\n 2 Algeria    <tibble> <lm>    0.938   0.937 2.53    828.  7.84e-35     1 -133. \n 3 Angola     <tibble> <lm>    0.989   0.989 0.698  5091.  6.69e-56     1  -59.3\n 4 Antigua a… <tibble> <lm>    0.938   0.937 0.977   828.  7.64e-35     1  -78.6\n 5 Argentina  <tibble> <lm>    0.983   0.982 0.479  3103.  4.58e-50     1  -37.9\n 6 Armenia    <tibble> <lm>    0.288   0.275 1.57     22.2 1.70e- 5     1 -106. \n 7 Aruba      <tibble> <lm>    0.882   0.880 0.964   412.  3.28e-27     1  -77.8\n 8 Australia  <tibble> <lm>    0.983   0.983 0.540  3240.  1.42e-50     1  -44.7\n 9 Austria    <tibble> <lm>    0.989   0.989 0.430  4949.  1.45e-55     1  -31.7\n10 Azerbaijan <tibble> <lm>    0.679   0.673 1.54    116.  3.48e-15     1 -105. \n# … with 175 more rows, 5 more variables: AIC <dbl>, BIC <dbl>, deviance <dbl>,\n#   df.residual <int>, nobs <int>, and abbreviated variable names ¹​r.squared,\n#   ²​adj.r.squared, ³​statistic\n\n\nSi observamos los valores de \\(R^2\\) de los primeros 5 modelos notamos que tienen un \\(R^2\\) alto, lo que nos dice que los modelos para estos países se han ajustado bien a los datos de esos países en particular.\n\n\n\nSiendo un poco más curiosos, tratemos de explorar el ajuste de los modelos. Para ver esto, podemos filtrar los valores más alto de r.squared, tomaremos como un r.squared alto 0.995 en adelante.\nPor ejemplo, podemos usar la función slice_max() de dplyr para encontrar los modelos que mejor se ajustan. Asimismo, podemos encontrar los modelos con el peor ajuste utilizando la función slice_min(). Hechemos un vistazo al código y los resultados generados,\n\nmejores_models <- model_perf %>% filter(r.squared > 0.995)\nmejores_models\n\n# A tibble: 3 × 15\n# Groups:   country [3]\n  country     data     model r.squ…¹ adj.r…² sigma stati…³  p.value    df logLik\n  <fct>       <list>   <lis>   <dbl>   <dbl> <dbl>   <dbl>    <dbl> <dbl>  <dbl>\n1 Bahamas     <tibble> <lm>    0.995   0.995 0.235  11428. 1.74e-65     1  2.67 \n2 Israel      <tibble> <lm>    0.996   0.996 0.250  15626. 3.29e-69     1 -0.826\n3 Switzerland <tibble> <lm>    0.996   0.995 0.244  12349. 2.08e-66     1  0.508\n# … with 5 more variables: AIC <dbl>, BIC <dbl>, deviance <dbl>,\n#   df.residual <int>, nobs <int>, and abbreviated variable names ¹​r.squared,\n#   ²​adj.r.squared, ³​statistic\n\n\ny para los peores filtremos los países que tienen un modelo con un r.squared menor a 0.3\n\npeores_modelos <- model_perf %>% filter(r.squared < 0.3) \npeores_modelos\n\n# A tibble: 12 × 15\n# Groups:   country [12]\n   country    data     model r.squ…¹ adj.r.…² sigma stati…³ p.value    df logLik\n   <fct>      <list>   <lis>   <dbl>    <dbl> <dbl>   <dbl>   <dbl> <dbl>  <dbl>\n 1 Armenia    <tibble> <lm>  2.88e-1  0.275    1.57 2.22e+1 1.70e-5     1 -106. \n 2 Botswana   <tibble> <lm>  8.21e-4 -0.0173   4.98 4.52e-2 8.32e-1     1 -171. \n 3 Central A… <tibble> <lm>  2.76e-1  0.262    3.13 2.09e+1 2.76e-5     1 -145. \n 4 Latvia     <tibble> <lm>  1.92e-1  0.177    1.88 1.31e+1 6.49e-4     1 -116. \n 5 Lesotho    <tibble> <lm>  3.46e-2  0.0170   5.23 1.97e+0 1.66e-1     1 -174. \n 6 Lithuania  <tibble> <lm>  2.94e-1  0.281    1.24 2.29e+1 1.32e-5     1  -92.0\n 7 Russia     <tibble> <lm>  2.63e-2  0.00856  1.80 1.48e+0 2.28e-1     1 -113. \n 8 South Afr… <tibble> <lm>  2.69e-1  0.256    3.57 2.03e+1 3.54e-5     1 -152. \n 9 Swaziland  <tibble> <lm>  6.92e-5 -0.0181   5.83 3.80e-3 9.51e-1     1 -180. \n10 Ukraine    <tibble> <lm>  1.73e-1  0.158    1.41 1.15e+1 1.30e-3     1  -99.4\n11 Zambia     <tibble> <lm>  4.13e-2  0.0239   4.13 2.37e+0 1.30e-1     1 -161. \n12 Zimbabwe   <tibble> <lm>  1.37e-1  0.122    5.75 8.75e+0 4.55e-3     1 -180. \n# … with 5 more variables: AIC <dbl>, BIC <dbl>, deviance <dbl>,\n#   df.residual <int>, nobs <int>, and abbreviated variable names ¹​r.squared,\n#   ²​adj.r.squared, ³​statistic\n\n\n\n\n\nPara hacer esto, primero debe crear un marco de datos que contenga tanto los valores predichos como los originales. Esto requiere primero usar map() y augment() para trabajar en la columna de la lista que contiene los modelos para crear marcos de datos anidados que contengan tanto los valores originales como los predichos. Luego, puede usar unnest() en esta nueva columna para simplificar estos marcos de datos y permitir una mayor exploración.\n\naugment_models <- gap_models %>% \n  mutate(augmented = map(model,~augment(.x))) %>% \n  unnest(augmented)\n\naugment_models\n\n# A tibble: 10,545 × 11\n# Groups:   country [185]\n   country data     model  life_exp…¹  year .fitted .resid   .hat .sigma .cooksd\n   <fct>   <list>   <list>      <dbl> <int>   <dbl>  <dbl>  <dbl>  <dbl>   <dbl>\n 1 Albania <tibble> <lm>         62.9  1960    65.7 -2.80  0.0684  0.672 0.517  \n 2 Albania <tibble> <lm>         63.9  1961    65.9 -1.99  0.0648  0.728 0.245  \n 3 Albania <tibble> <lm>         64.8  1962    66.1 -1.30  0.0614  0.758 0.0989 \n 4 Albania <tibble> <lm>         65.6  1963    66.4 -0.778 0.0581  0.772 0.0332 \n 5 Albania <tibble> <lm>         66.2  1964    66.6 -0.434 0.0549  0.777 0.00970\n 6 Albania <tibble> <lm>         66.6  1965    66.9 -0.260 0.0518  0.779 0.00327\n 7 Albania <tibble> <lm>         66.9  1966    67.1 -0.206 0.0489  0.779 0.00193\n 8 Albania <tibble> <lm>         67.1  1967    67.3 -0.213 0.0461  0.779 0.00192\n 9 Albania <tibble> <lm>         67.3  1968    67.6 -0.239 0.0435  0.779 0.00227\n10 Albania <tibble> <lm>         67.6  1969    67.8 -0.245 0.0409  0.779 0.00224\n# … with 10,535 more rows, 1 more variable: .std.resid <dbl>, and abbreviated\n#   variable name ¹​life_expectancy\n\n\nAhora, visualizaremos algunos de estos modelos.\n\n\n\nNote que dado que su \\(R^2\\) es bastante alto, podemos asumir que el modelo lineal se ajusta bien a los datos. Puede comparar el ajuste del modelo con los datos originales trazando ambos en el mismo gráfico. En este ejemplo, usaremos ggplot2 para trazar los valores originales de la esperanza de vida como un diagrama de dispensión usando geom_point() y agregué el ajuste del modelo lineal como una línea roja usando geom_line()\n\naugment_models %>% filter(country == \"Bahamas\") %>% \n  ggplot(aes(x = year, y = life_expectancy)) + \n  geom_point() + \n  geom_line(aes(y = .fitted), color = \"red\") + \n  labs(title = \"Modelo Regresión Lineal para Bahamas\",\n       x = \"Año\",\n       y = \"Esperanza de Vida\") + \n  theme_minimal()\n\n\n\n\nSi observa el gráfico, podemos pensar que un modelo de regresión lineal se va ajustando bien a los datos de este país en particular.\n\n\n\nAhora veamos el modelo correspondiente al país Ukraine, que tiene un valor de \\(R^2\\) super más bajo que el de Bahamas. Claramente, esperariamos encontrarnos con un modelo que no se ajuste bien a los datos dado el antecedente del \\(R^2\\)\n\naugment_models %>% filter(country == \"Ukraine\") %>% \n  ggplot(aes(x = year, y = life_expectancy)) + \n  geom_point() + \n  geom_line(aes(y = .fitted), color = \"red\") + \n  labs(title = \"Modelo de Regresión Lineal para Ukraine\", \n       x = \"Año\", \n       y = \"Esperanza de  Vida\") + \n  theme_minimal()\n\n\n\n\nComo pudo ver en estos dos ejemplos, augment() y ggplot() facilitan la exploración visual del ajuste de un modelo.\n\n\n\nEn este caso, prepararemos los cuatro mejores modelos que consideramos anteriormente y los peores y los visualizaremos,\n\nmejores_augment <- mejores_models %>% \n  mutate(augmented = map(model, ~augment(.x))) %>% \n  unnest(augmented)\n\npeores_augment <- peores_modelos %>% \n  mutate(augmented = map(model, ~augment(.x))) %>% \n  unnest(augmented)\n\nBien, ahora visualizamos los modelos\n\nmejores_augment %>% \n  ggplot(aes(x = year)) + \n  geom_point(aes(y = life_expectancy)) + \n  geom_line(aes(y = .fitted), color = \"red\") + \n  facet_wrap(~country, scales = \"free_y\") + \n  theme_minimal()\n\n\n\n\n\npeores_augment %>% \n  ggplot(aes(x = year)) + \n  geom_point(aes(y = life_expectancy)) + \n  geom_line(aes(y = .fitted), color = \"red\") + \n  facet_wrap(~country, scales = \"free_y\") + \n  theme_minimal()\n\n\n\n\nParcelas geniales! Puede ver que un modelo lineal hace un gran trabajo para los mejores 3 modelos de ajuste, pero los peores modelos de ajuste no parecen tener una relación lineal. Trabajaremos para mejorar este ajuste en la proxima serie de ejercicios mediante la incorporación de funciones adicionales.\n\n\n\nCon la información que reunimos con Augment() y glance(), aprendimos que algunos de los modelos de regresión lineal simple no se ajustan adecuadamente a las tendencias subyacentes de nuestros datos. Para separar esto emplearemos un modelo de regresión múltiple.\n\n\n\\[Y = \\alpha + \\beta_1x_1 9 \\beta_2x_2 + . . . \\]\nEste modelo es una extensión natural del modelo de regresión lineal simple. La diferencia clave es que usa más variables explicativas para explicar el resultados, lo que significa que, en lugar de ajustar una linea de mejor ajuste, estamos ajustando un plano multidimensional. En el conjunto de datos gapminder, podemos usar características adicionales de nuestras observaciones para modelr la esperanza de vida. Entonces, vamos a usarlo,\nLa elección de que características usar se puede controlar en el campo de fórmula de la función lm(). Recuerde que para un modelo simple usamos la fórmula de la esperanza de vida explicada por año. De manera similar para un modelo de regresión múltiple, puede definir explícitamente la fórmula incluyendo el nombre de cada característica separada por un signo + o si sabe que desa incluir todas las características, puede capturarlas usando un punto,como veremos posteriormente.\n\n\n\nEl comportamiento de las funciones de broom sigue siendo el mismo. tidy() devuelve las estimaciones de los coeficientes de los modelos, esto ahora incluye estimaciones para las cuatro características adicionales. Lo mismo ocurre con augment(), además, de los valores ajustados para cada observación, se devuelven los valores de cuatro caracteristicas nuevas. y aunque la salida esperada de glance() sigue siendo la misma, tenemos que cambiar nuestro enfoque del valor de r cuadrado al valor de r cuadrado ajustado al evaluar el ajuste de nuestros modelos o comparar modelos de regresión lineal simple y múltiple.\n\n\n\nRecuerde que r.squared mide la variación explicada por el modelo. Agregar cualquier característica nueva a un modelo, independientemente de su relación con la variable dependiente, siempre aumentará el valor de r.squared del modelo. Esto se vuelve problemático cuando se compara el ajuste de modelos con diferente número de características explicativas utilizadas. Para compensar esto, en su lugar, utilizará el valor adj.r.squared (r cuadrado ajustado) esta es una métrica r cuadrada modificada cuyo cálculo tiene en cuenta la cantidad de características utilizadas en el modelo.\nLa interpretación del adj.r.squared es muy similar al r.squared y lo usaremos para evaluar el ajuste de nuestros modelos y compararlos con los modelos lineales simples creados anteriormente.\n\n\n\n\nAnteriormente, creamos una colección de modelos simples para ajustarse a la expectativa de vida usando la característica de año. Su análisis anterior mostro que algunos de estos modelos no encajaban muy bien.\nEn esta sección, construiremos modelos de regresión múltiple para cada país utilizando todas las funciones disponibles. Puede que le interese comparar el rendimiento de los 12 modelos con el peor ajuste\n\n\n\nPaís\nAdj.r.squared\n\n\n\n\nArmenia\n0.274831633\n\n\nBotswana\n-0.017346290\n\n\nCentral African Republic\n0.262392009\n\n\nLatvia\n0.177428933\n\n\nLesotho\n0.017078583\n\n\nLithuania\n0.281255888\n\n\nRussia\n0.008564872\n\n\nSouth Africa\n0.255968853\n\n\nSwaziland\n-0.018111402\n\n\nUkraine\n0.157855451\n\n\nZambia\n0.023859596\n\n\nZimbabwe\n0.1216212616\n\n\n\nAhora si, apliquemos un modelo lineal generalizado para ver si mejorar estos datos\n\n# Creamos un modelo lineal para cada país\ngap_fullmodel <- gap_anidado %>% \n  mutate(model = map(data, \n                     ~lm(life_expectancy~year+population+fertility+gdp, data = .x)))\n\nfullmodel_perf <- gap_fullmodel %>% \n  # Extraigaimos las estadísticas de ajuste de cada modelo en marcos de datos\n  mutate(fit = map(model, ~glance(.x))) %>% \n  # Simplifiquemos los marcos de datos de ajuste para cada modelo\n  unnest(fit)\n\n# Vea el rendimiento de los 12 países con el peor ajuste, es decir, \n# los dos modelos simples que viste antes\nfullmodel_perf %>% \n  filter(country %in% peores_modelos$country) %>% \n  select(country, adj.r.squared)\n\n# A tibble: 12 × 2\n# Groups:   country [12]\n   country                  adj.r.squared\n   <fct>                            <dbl>\n 1 Armenia                          0.923\n 2 Botswana                         0.736\n 3 Central African Republic         0.931\n 4 Latvia                           0.687\n 5 Lesotho                          0.855\n 6 Lithuania                        0.893\n 7 Russia                           0.652\n 8 South Africa                     0.896\n 9 Swaziland                        0.905\n10 Ukraine                          0.692\n11 Zambia                           0.872\n12 Zimbabwe                         0.978\n\n\nNote que los valores para adj.r.squared mejoraron considerablemente. Si bien adj.r.squared nos dice qué tan bien se ajusta el modelo a nuestros datos, no da ninguna indicación sobre cómo se desempeñaria con nuevos datos. En otro post, les mostraré como estimar el rendimiento del modelo utilizando los datos retenidos de la construcción del modelo."
  },
  {
    "objectID": "posts/tidyverse/index.html#descripción-general-del-modelo",
    "href": "posts/tidyverse/index.html#descripción-general-del-modelo",
    "title": "Machine Learning en Tidyverse",
    "section": "Descripción General del Modelo",
    "text": "Descripción General del Modelo\nFacebook Prophet es un modelo y una biblioteca que proporciona características tanto de modelos lineales generalizados (MLG) como de modelos aditivos (MA), principalmente extendiendo el MLG mediante el uso de funciones de suavizado no lineal. Fue especificado por Taylor y Letham en 2017.\nProphet es un software de código abierto lanzado por el equipo Core Data Science de Facebook. Está disponible para su descarga en CRAN y PyPI. En esta ocasión usaremos el lenguaje R para implementar el modelo, sin embargo, tu puedes hacerlo en Python si es de tu preferencia.\nProphet funciona mejor con series temporales que tienen fuertes efectos estacionales y varias temporadas de datos históricos. Prophet es resistente a los datos faltantes y los cambios en la tendencia, y por lo general maneja bien los valores atípicos. Prophet esta diseñado especificamente para la predicción de series temporales de negocios.\nSu modelo aditivo que consta de cuatro componentes, esta dado por:\n\\[\ny(t) = g(t) + s(t) + h(t) + \\epsilon_{t}\n\\]\ndonde,\n\n\\(g(t)\\): Representa la tendencia y el objetivo es capturar la tendencia de la serie. Por ejemplo, es probable que la cantidad de vistas de anuncios de Facebook aumente con el tiempo a medida que más personas se unen a la red. Pero, ¿cuál sería la función exacta del aumento?\n\\(s(t)\\): Es el componente de Estacionalidad. El número de anuncios también puede depender de la temporada. Por ejemplo, en el hemisferio norte durante los meses de verano, es probable que las personas pasen más tiempo al aire libre y menos tiempo frente a sus computadoras. Tales fluctuaciones pueden ser muy diferentes para diferentes series temporales de negocios. El segundo componente es, por lo tanto, una función que modela las tendencias estacionales.\n\\(h(t)\\): Representa los efectos de las vaciones. Usamos la información para días festivos que tienen claro impacto en la mayoria de las series temporales comerciales. Tenga en cuenta que las vaciones varían entre años, países, etc. Y, por lo tanto, la información debe proporcionarse explícitamente al modelo.\n\\(\\epsilon_{t}\\): Es el término de error. Representa fluctuaciones aleatorias que el modelo no puede explicar. Como de costumbre, se supone que \\(\\epsilon_{t}\\) sigue una distribución \\(N(0,1)\\) con media cero y varianza desconocida \\(\\sigma\\) que debe derivarse de los datos ."
  },
  {
    "objectID": "posts/tidyverse/index.html#hiperparámetros",
    "href": "posts/tidyverse/index.html#hiperparámetros",
    "title": "Machine Learning en Tidyverse",
    "section": "Hiperparámetros",
    "text": "Hiperparámetros\nHay varios parámetros personalizables en la implementación de Facebook Prophet (revisar), siendo los principales:\n\nPuntos de cambio: definen los cambios de tendencia. Estos pueden ser encontrados por el propio algoritmo o también pueden ser definidos y ajustados por el analista.\nEstacionalidad: define las funciones periódicas que pueden afectar a la serie temporal. De forma predeterminada, Prophet considera la estacionalidad anual, semanal y diaria e intenta encontrar tendencias que representan esos efectos periódicos en los datos.\nDías festivos: los días especiales (días festivos o cualquier otro evento recurrente) también pueden ser modelados por el modelo aditivo.\n\nEn R, se usa la API de ajuste de modelo normal. Proporcionamos una función prophet que realiza el ajuste y devuelve un objeto de modelo. Posteriormeente usted puede llamar a la función predict y plot en este objeto modelo."
  },
  {
    "objectID": "posts/tidyverse/index.html#datos-y-preparación",
    "href": "posts/tidyverse/index.html#datos-y-preparación",
    "title": "Machine Learning en Tidyverse",
    "section": "Datos y Preparación",
    "text": "Datos y Preparación\nLos datos que utilizaremos los encontramos en Yahoo! Finance. Así como Python tiene un paquete para importar datos directamente de Yahoo Finance, R también cuenta con sus paquetes particular que nos permiten realizar una tarea similar. Necesitamos los siguiente paquetes:\n\nlibrary(TTR)\nlibrary(quantmod)\n\nLoading required package: xts\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nSi aún no los tienes instalados sugiero los instales usando install.packages(\"name paquete\"). Muy bien, ahora si estamos listos para poder extraer nuestros datos de yahoo finance y para ello usaremos la funcion getSymbols del paquete quantmod. Veamos,\n\ndf <- getSymbols('HNL=X',src = 'yahoo',\n                 from = \"2010-01-01\",\n                 to = \"2022-12-20\",\n                 auto.assign = FALSE)\n\nTenga en cuenta que from =  \"2010-01-01\" y to = \"2022-12-20\" nos ayudan a indicar desde que fecha quiero comenzar a tomar mis datos y hasta que fecha quiero tomarlos. Además, auto.assign = FALSE indica a getSymbols que devuelva los datos.\nAhora, conozcamos nuestros datos\n\nhead(df)\n\n           HNL=X.Open HNL=X.High HNL=X.Low HNL=X.Close HNL=X.Volume\n2010-01-04     18.690     18.691    18.517      18.518            0\n2010-01-05     18.550     18.550    18.550      18.550            0\n2010-01-06     18.572     18.645    18.544      18.545            0\n2010-01-07     18.451     18.550    18.451      18.539            0\n2010-01-08     18.556     18.556    18.556      18.556            0\n2010-01-11     18.550     18.550    18.550      18.550            0\n           HNL=X.Adjusted\n2010-01-04         18.518\n2010-01-05         18.550\n2010-01-06         18.545\n2010-01-07         18.539\n2010-01-08         18.556\n2010-01-11         18.550\n\n\nDe estos datos únicamente usaremos el valor de cierre (HNL=X.Close) de manera diaria del lempira hondureño contra el dólar, para enfocarnos solo en esos datos, primero convertiremos nuestro conjunto de datos df en un dataframe, dado que inicialmente es un objeto de tipo xts,\n\nclass(df)\n\n[1] \"xts\" \"zoo\"\n\n\npara realizar el cambio a un dataframe, considere la siguiente función\n\nxts_to_datframe<-function(data_xts){\n  df_t<-data.frame(fecha=(index(data_xts)),\n                   value=coredata(data_xts))\n  colnames(df_t)<-c(\"ds\", \"y\")\n  df_t\n}\n\nTiene que tener cuidado con el nombramiento de sus columnas, dado que prophet reconoce unicamente marcos de datos con columnas nombras como ds y y, qu contienen la fecha y el valor numérico de sus observaciones respectivamente. Con esto en mente, pasemos a transformar df a un objeto de clase dataframe por medio de la función que construimos previamente:\n\nHNL <- xts_to_datframe(df$`HNL=X.Close`) \nclass(HNL)\n\n[1] \"data.frame\"\n\n\nPuede apreciar que ya tenemos nuestro marco de datos como un dataframe, y estamos listos para comenzar a crear nuestro modelo."
  },
  {
    "objectID": "posts/tidyverse/index.html#implementación-del-modelo",
    "href": "posts/tidyverse/index.html#implementación-del-modelo",
    "title": "Machine Learning en Tidyverse",
    "section": "Implementación del Modelo",
    "text": "Implementación del Modelo\nPrimero visualicemos nuestros datos\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.5.0 \n✔ readr   2.1.2      ✔ forcats 0.5.1 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::first()  masks xts::first()\n✖ dplyr::lag()    masks stats::lag()\n✖ dplyr::last()   masks xts::last()\n\nlibrary(ggplot2)\n\nHNL %>% ggplot(aes(x = ds, y = y))+\n  geom_line()+\n  theme_minimal()+\n   labs(title = 'Datos Historicos del Tipo de Cambio del USD/HNL',\n       subtitle = '2010 - 2022',\n       x = 'Fecha',\n       y = 'HNL',\n       caption = 'Elaboracion propia con datos de yahoo finance')\n\n\n\n\n\nlibrary(prophet)\n\nLoading required package: Rcpp\n\n\nLoading required package: rlang\n\n\n\nAttaching package: 'rlang'\n\n\nThe following objects are masked from 'package:purrr':\n\n    %@%, as_function, flatten, flatten_chr, flatten_dbl, flatten_int,\n    flatten_lgl, flatten_raw, invoke, splice\n\nm <- prophet(HNL,daily.seasonality = TRUE)\n\nfuture <- make_future_dataframe(m,periods = 3,freq = 'day')\ntail(future)\n\n             ds\n3380 2022-12-16\n3381 2022-12-19\n3382 2022-12-20\n3383 2022-12-21\n3384 2022-12-22\n3385 2022-12-23\n\n\n\nforecast <- predict(m, future)\n\ndyplot.prophet(m, forecast)\n\n\n\n\n\nDe la figura previa,\n\nLos puntos negros representan medidas reales\nLa linea azul el pronóstico de Prophet\nLa banda azul representa el intervalo de incertidumbre"
  },
  {
    "objectID": "posts/tidyverse/index.html#desglose-del-pronóstico",
    "href": "posts/tidyverse/index.html#desglose-del-pronóstico",
    "title": "Machine Learning en Tidyverse",
    "section": "Desglose del Pronóstico",
    "text": "Desglose del Pronóstico\nSi bien el pronóstico arroja muchas cosas, podemos centrarnos en algunas como:\n\nds fecha que se pronostica\nyhat predicción para el valor y (tipo de cambio) ese día en particular.\nyhat_lower valor esperado más bajo para el rango del valor y previsto ese día\nyhat_upper valor esperado más alto para el rango de valor y previsto de ese día\n\nCon tail() podemos ver la salida de los últimos días pronosticados los cuales son 21, 22 y 23 de diciembre 2022.\n\ntail(forecast[c('ds', 'yhat', 'yhat_lower', 'yhat_upper')])\n\n             ds     yhat yhat_lower yhat_upper\n3380 2022-12-16 24.10924   23.38237   24.77015\n3381 2022-12-19 24.04473   23.34807   24.83821\n3382 2022-12-20 24.11075   23.42157   24.87120\n3383 2022-12-21 24.08755   23.35328   24.79132\n3384 2022-12-22 24.12633   23.40594   24.81080\n3385 2022-12-23 24.13436   23.37964   24.81741\n\n\nSegun nuestros resultados, nuestro modelo nos ve obteniendo para el día 21 de diciembre entre 23.35901 (yhat_lower) y 24.83438 (yhat_upper) lempiras por un dolar de EE.UU.\nPara entender el pronóstico más a detalle, podemos gráficar sus componentes con:\n\nprophet_plot_components(m,forecast)\n\n\n\n\nRecuerde que el fin de este post, no es abogar por el uso indiscriminado de Prophet como el mejor modelo para pronosticar el tipo de cambio hondureño vs el dólar. Espero hayas conocido las generalidades de este modelo y su utilidad en el ambito predictivo."
  },
  {
    "objectID": "posts/arima/index.html",
    "href": "posts/arima/index.html",
    "title": "ARIMA Models in Python",
    "section": "",
    "text": "¿Alguna vez has tratado de predecir el futuro? Lo que se avecina es un misterio que normalmente solo se resuelve esperando. En este artículo, dejara de esperar y aprenderá a usar los poderosos modelos de la clase ARIMA para pronosticar el futuro. Aprenderá a usar el paquete statsmodels para analizar series de tiempo, construir modelos personalizados y pronosticar bajo incertidumbre. ¿Cómo se movera el mercado de valores en las próximas 24 horas? ¿Como cambiaran los niveles de CO2 en la próxima década? ¿Cuántos terremotos habrá el próximo año? aprenderás a resolver todos estos problemas y más.\n\nModelos ARMA\nVamos adentrarnos directamente y aprender sobre las propiedades más importantes de las series temporales. Aprenderá sobre la estacionariedad y como esto es importante para los modelos ARMA. Aprenderá como probar la estacionariedad a simple vista y con una prueba estadistica estandar. Finalmente aprenderá la estructura básica de los modelos ARMA y la usara para generar algunos datos ARMA y ajustar un modelo ARMA.\n\nSeries temporales y Estacionariedad\nLos datos de series temporales están en todas partes en este mundo. Se utilizan en una amplia variedad de campos. Hay muchos conjuntos de datos para los que nos gustaría poder predecir el futuro. Conocer el futuro de las tasas de obesidad podría ayudarnos a intervenir ahora por la salud pública; predecir las demandas de energía de los consumidores podría ayudar a que las centrales electricas funcionen de manera más eficiente; y predecir como cambiara la población de una ciudad podría ayudarnos a construir la infraestructura que necesitamos.\nComencemos examinando una serie de tiempo. Podemos cargar una serie temporal desde csv usando pandas. Aquí establecemos el índice como la columna de fecha (index_col) y analizamos la fecha en el tipo de dato decha y hora (parse_dates)\n\nimport pandas as pd \nimport matplotlib.pyplot as plt \n\ndf = pd.read_csv(\"candy_production.csv\",index_col = \"fecha\", parse_dates = True)\ndf\n\n\n\n\n\n  \n    \n      \n      IPG3113N\n    \n    \n      fecha\n      \n    \n  \n  \n    \n      1972-01-01\n      85.6945\n    \n    \n      1972-01-02\n      71.8200\n    \n    \n      1972-01-03\n      66.0229\n    \n    \n      1972-01-04\n      64.5645\n    \n    \n      1972-01-05\n      65.0100\n    \n    \n      ...\n      ...\n    \n    \n      2017-01-04\n      107.4288\n    \n    \n      2017-01-05\n      101.9209\n    \n    \n      2017-01-06\n      104.2022\n    \n    \n      2017-01-07\n      102.5861\n    \n    \n      2017-01-08\n      114.0613\n    \n  \n\n548 rows × 1 columns\n\n\n\n\nTendencia\nUna caracteristica importante de una serie de tiempo es su tendencia. Una tendencia positiva es una línea que generalmente se inclinan hacia arriba: los valores aumentan con el tiempo. Del mismo modo, una tendencia negativa es donde los valores disminuyen.\n\n\n\nEstacionalidad\nOtra característica importante es la estacionalidad. Una serie temporal estacional tiene patrones que se repiten a intervalos regulares, por ejemplo ventas altas todos los fines de semana\n\n\n\nCiclicidad\nPor el contrario, la ciclicidad es donde hay un patrón repetitivo pero no un periodo fijo\n\n\n\nRuido Blanco\nEl ruido blanco es un concepto importante en series temporales y modelos ARIMA. El ruido blanco es una serie de mediciones, donde cada valor no esta correlacionado con los valores anteriores. Puede pensar en esto como lanzar una moneda, el resultado de un lanzamiento de moneda no depende de los resultados de lanzamiento anteriores. De manera similar, con el ruido blanco, el valor de la serie no depende de los valores anteriores."
  }
]