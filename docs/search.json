[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "J.Isaula",
    "section": "",
    "text": "Welcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJan 14, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\n  \n\n\n\n\nMicroeconomía Intermedia con R\n\n\nCurvas de Indiferencia\n\n\n\n\nEconomía\n\n\nMicroeconomía\n\n\nR\n\n\nRStudio\n\n\n\n\n\n\n\n\n\n\n\nJan 9, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Post",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nEstructuras de Mercado con Python\n\n\nCompetencia Perfecta, Monopolio y Oligopolio\n\n\n\n\nCMg\n\n\nCVP\n\n\nCTP\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nApr 13, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nPortfolio management\n\n\nGeneralidades\n\n\n\n\nDiversificación\n\n\nPortafolio\n\n\nVolatilidad\n\n\nFrontera eficiente\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nTópicos Actuariales con R\n\n\nAnualidades y Seguros\n\n\n\n\nlifecontingencies\n\n\nAnualidades\n\n\nActuary\n\n\nR\n\n\nSeguros\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nMachine Learning en Tidyverse\n\n\nMúltiples Modulos con broom\n\n\n\n\nMachine Learning\n\n\nForecasting\n\n\nR\n\n\nRStudio\n\n\nbroom\n\n\n\n\n\n\n\n\n\n\n\nJan 21, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nMicroeconomía Intermedia con R\n\n\nUtilidad y sus Curvas de Indiferencia\n\n\n\n\nEconomía\n\n\nMicroeconomía\n\n\nR\n\n\nRStudio\n\n\n\n\n\n\n\n\n\n\n\nJan 9, 2023\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nModelo Prophet de Facebook\n\n\nPronóstico aplicado al tipo de cambio USD/HNL\n\n\n\n\nProphet\n\n\nForecasting\n\n\nR\n\n\nRStudio\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2022\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nIntroducción a R\n\n\nGeneralidades\n\n\n\n\nR\n\n\nRStudio\n\n\n\n\n\n\n\n\n\n\n\nJan 20, 2022\n\n\nJuan Isaula\n\n\n\n\n\n\n  \n\n\n\n\nSeries de Tiempo\n\n\n\n\n\n\n\nTime Series\n\n\nRStudio\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2021\n\n\nJuan Isaula\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Microeconomía Intermedia con R",
    "section": "",
    "text": "Una forma de iniciar el análisis de los individuos es plantear un conjunto básico de postulados, o axiomas, que describen el comportamiento racional del mismo. Supondremos que dadas tres canastas de consumo cualesquiera \\((x_1,x_2)\\), \\((y_1,y_2)\\) y \\((z_1,z_2)\\). El consumidor puede ordenarlas según su atractivo. Es decir, puede decidir que una de ellas es estrictamente mejor que la otra o bien que le son indiferentes.\nUtilizaremos la notación:\n\n\\(\\succ\\) Para indicar que una canasta se prefiere estrictamente a otra, es decir, \\((x_1,x_2) \\succ (y_1,y_2)\\).\n\\(\\sim\\) Para indicar que al consumidor le resulta indiferente elegir una u otra de las dos canastas de bienes y lo representamos matemáticamente como \\((x_1,x_2)\\sim (y_1,y_2)\\).\n\\(\\succeq\\) Para indicar si el individuo prefiere una de las dos canastas o es indiferente entre ellas, decimos que prefiere debilmente la canasta \\((x_1,x_2)\\) a la \\((y_1,y_2)\\) y escribimos \\((x_1,x_2)\\succeq (y_1,y_2)\\).\n\n\n\nCon base en lo anterior, ya estamos preparados para conocer los tres axiomas de la teoría del consumidor. Decimos que las preferencias son:\n\nCompletas: suponemos que es posible comprar dos canastas cualesquiera, es decir, dada cualquier canasta \\(\\textbf{X}\\) y cualquier canasrta \\(\\textbf{Y}\\), suponemos que \\((x_1,x_2)\\succeq (y_1,y_2)\\) o \\((y_1,y_2) \\succeq (x_1,x_2)\\) o las dos cosas, en cuyo caso el consumidor es indiferente entre las dos canastas.\nReflexivas: suponemos que cualquier canasta es al menos tan buena como ella misma: \\((x_1,x_2)\\succeq (y_1,y_2)\\).\nTransitiva: si \\((x_1,x_2)\\succeq (y_1,y_2)\\) y \\((y_1,y_2)\\succeq (z_1,z_2) \\Longrightarrow (x_1,x_2)\\succeq (z_1,z_2)\\). Es decir, si el consumidor piensa que la canasta \\(\\textbf{X}\\) es al menos tan buena como la \\(\\textbf{Y}\\) y que la \\(\\textbf{Y}\\) es al menos tan buena como la \\(\\textbf{Z}\\), piensa que la \\(\\textbf{X}\\) es al menos tan buena como la \\(\\textbf{Z}\\).\n\nConsidere que cuando nos referimos a las canastas \\(\\textbf{X}, \\textbf{Y}\\) o \\(\\textbf{Z}\\) estamos haciendo referencia a:\n\n\\(\\textbf{X} = (x_1,x_2)\\)\n\\(\\textbf{Y} = (y_1.y_2)\\)\n\\(\\textbf{Z} = (z_1,z_2)\\)\n\nSi las preferencias no fueran transitivas, podría muy bien haber un conjunto de canastas tal que ninguna de las elecciones fuera la mejor. Sin embargo, en el curso de microeconomía II estamos trabajando bajo el modelo tradicional, donde asumimos que el individuo es razonal, tomando en cuenta que siempre va a preferir mas que menos.\n\n\n\nEl primer axioma, la completitud, es dificilmente criticable, al menos en el caso de los tipos de elecciones que suelen analizar los economistas. Decir que pueden compararse dos canastas cualesquiera es decir simplemente que el consumidor es capaz de elegir entre dos canasas cualesquiera.\nEl segundo axioma, la reflexividad, plantea más problemas. Una canasta cualquiera es ciertamente tan buena como una canasta idéntica.\nEl tercer axioma, la transitividad, plantea más problemas. No esta claro que las preferencias deban tener necesariamente esta propiedad. El supuesto de que son transitivas no parece evidente desde un punto de vista puramente lógico, y, de hecho, no lo es. La transitividad es una hipótesis sobre la conducta de los individuos en sus elecciones y no una afirmación lógica. Sin embargo, no importa que sea o no un hecho lógico básico; lo que importa es que sea o no una descripción razonablemente exacta del comportamiento de los individuos.\n¿Qué pensarías de una persona que dijera que prefiere la canasta \\(\\textbf{X}\\) a la \\(\\textbf{Y}\\) y la \\(\\textbf{Y}\\) a la \\(\\textbf{Z}\\), pero que también dijera que prefiere la \\(\\textbf{Z}\\) a la \\(\\textbf{X}\\)? Desde luego, lo consideraríamos como prueba de una conducta particular. Y lo que es más importante, ¿Cómo se comportaría este consumidor si tuviera que elegir entre las tres canastas \\(\\textbf{X}, \\textbf{Y}\\) y \\(\\textbf{Z}\\)?"
  },
  {
    "objectID": "posts/post-with-code/index.html#curvas-de-indiferencia",
    "href": "posts/post-with-code/index.html#curvas-de-indiferencia",
    "title": "Microeconomía Intermedia con R",
    "section": "Curvas de Indiferencia",
    "text": "Curvas de Indiferencia\nCon base en la definición previa de utilidad, podemos concluir, una función de utilidad es la que explica la cantidad de utilidad que posee un consumidor dado su consumo de dos bienes diferentes. \\(x, y\\). Una curva de indiferencia es solo una rebanada infenitesimal de esa función que describe todas las diferentes combinaciones entre dos bienes que producen la misma cantidad de utilidad (es decir, a la que una persona sería indiferente).\nSupongamos que una persona clasifica las hamburguesas \\((y)\\) y las bebidas \\((x)\\) de acuerdo con la función de utilidad\n\\[\nU(x,y) = \\sqrt{xy}\n\\]\nEn el caso de esta función, obtenemos la curva de indiferencia identificando un conjunto de combinaciones de \\(x,y\\) en el cual la utilidad tiene el mismo valor. Suponga que arbitrariamente decimos que la utilidad tiene un valor de 10. Entonces, la ecuación de esta curva sera:\n\\[\nU(x,y) = 10 = \\sqrt{xy}\n\\]Note que si elevamos esta función al cuadrado se mantiene el mismo orden, por lo cual también podemos representar esta curva de indiferencia como\n\\[\n100 = xy\n\\]\nEs importante siempre despejar este tipo de ecuaciones para \\(y\\) la importancia esta en que será mucho más facil posteriormente encontrar su tasa marginal de sustitución ( en otra sección de esta publicación estudiaremos a detalle esto), entonces, al despejar obtenemos:\n\\[\ny = \\frac{100}{x}\n\\]\nPara trazar su curva de indiferencia, lo haremos en R , a continuación les muestro como hacerlo. Puedes realizar este ejercicio en tu PC tu mismo.\n\n# 1. Primero cargamos las librerias que utilizaremos, en caso que nos las tengas \n#    instaladas sugiero lo hagas usando install.package(\"libreria\") en su consola\n#    de Rstudio.\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(tidyverse)\nlibrary(plotly)\n\n# 2. Creamos la función de utilidad del ejemplo \nutilidad <- function(x,y){\n  sqrt(x*y) \n}\n\n# 3. Creamos una matriz para hacer un bucle en la función de utilidad\nvalores_matriz <- matrix(0,nrow = 200, ncol = 200)\n\n# 3.1 Llenamos la matriz con usando la función de utilidad \nfor(fila in 1:nrow(valores_matriz)){\n  for(columna in 1:ncol(valores_matriz)){\n    valores_matriz[fila,columna] <- utilidad(fila,columna)\n  }\n}\n\n# 4. Función que nos permitira graficar las curvas de indiferencia \n\nC_indiferencia <- function(entrada_utilidad){\n  y <- c()\n  \n  for(i in 1:50){\n    y_coord <- entrada_utilidad^2/i\n    y       <- c(y,y_coord)\n  }\n  \n  data <- data.frame(\n    x = 1:50,\n    y = y,\n    z = rep(entrada_utilidad,50)\n  )\n  \n  return(data)\n}\n\n\n# 4.1 Resultado de utilidades obtenidas \nlista_utilidades <- lapply(10, C_indiferencia)\n\nfull_df <- do.call(rbind, lista_utilidades)\n\nAhora si ya estamos preparados para graficar nuestras curvas de indiferencia para \\(10 = \\sqrt{xy}\\)\n\n# 5. Gráfico\n\nggplot() + \n  geom_point(data = full_df, aes(x = x, y = y, color = z)) + \n  geom_path(data = full_df, aes(x = x, y = y, color = z)) +\n  theme_minimal()+\n  ylim(0,100) + \n  labs(x = \"Bebidad\", y = \"Hamburguesas\") + \n  scale_color_continuous(name = \"Utilidad\")\n\n\n\n\nNote que la curva previa representa una utilidad = 10.\nA continuación te muestro un grafico animado de la curva de indiferencia previa. Para generar el gráfico presiona el boton PLAY.\n\n\n\n\n\n\nVeamos que sucede cuando tenemos diferentes niveles de utilidad, en base al resultado usted puede deducir su propio análisis.\n\nutilidad <- function(x,y){\n  sqrt(x*y) \n}\n\nvalores_matriz <- matrix(0,nrow = 200, ncol = 200)\n\nfor(fila in 1:nrow(valores_matriz)){\n  for(columna in 1:ncol(valores_matriz)){\n    valores_matriz[fila,columna] <- utilidad(fila,columna)\n  }\n}\n\nC_indiferencia <- function(entrada_utilidad){\n  y <- c()\n  \n  for(i in 1:100){\n    y_coord <- entrada_utilidad^2/i\n    y       <- c(y,y_coord)\n  }\n  \n  data <- data.frame(\n    x = 1:100,\n    y = y,\n    z = rep(entrada_utilidad,100)\n  )\n  \n  return(data)\n}\n\nlista_utilidades <- lapply(seq(from =10, to = 60, by = 10), C_indiferencia)\n\nfull_df <- do.call(rbind, lista_utilidades)\n\n\nggplot() +\n  geom_point(data = full_df, aes(x = x, y = y, color = z)) +\n  geom_path(data = full_df, aes(x = x, y = y, color = z)) +\n  theme_minimal() +\n  ylim(0,200) +\n  labs(x = \"Bebidas\", y = \"Hamburguesas\") +\n  scale_color_continuous(name = \"Utilidad\")\n\n\n\n\nAquí podemos señalar lo siguiente:\n\nA medida que aumenta la utilidad, las curvas se desplazan hacia la derecha y hacia la izquierda a medida que disminuye la utilidad.\nObserve que las curvas se inclinan hacia abajo, esto debe ser necesariamente el caso; a medida que uno aumenta su consumo de bebidas renuncia al otro bien que les era indiferente, hamburguesa.\nTodo lo que está debajo de la curva representa paquetes con menos utilidad. La teoría de la utilidad asume que un consumidor siempre buscará maximizar la utilidad.\nComprende que la pendiente no es lineal. En genera, cuanto más se tiene de algo, menos utilidad se obtendrá de otra unidad y, por el contrario, más se renunciaría a adquirir el otro bien. Esta pendiente tiene un nombre oficial: Tasa Marginal de Sustitución o TMS hablaremos de esto en una sección posterior.\n\nPero esas son solo algunas rebanadas que ya he señalado como infinitesimalmente pequeñas.\nPara concluir esta sección te dejo un gráfico animado de los diferentes niveles de utilidad, por favor presiona el boton PLAY para que logres verlo."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Modelo Prophet de Facebook",
    "section": "",
    "text": "En este post, te presento la implementación de Facebook Prophet, así como sus principales hiperparámetros ajustados para generar el modelo predictivo, dicho modelo lo implementaremos para predecir el tipo de cambio de Honduras versus el dólar EE:UU (USD/HNL), considerando que esto será unicamente para conocer el funcionamiento del modelo, no para justificar que es el mejor modelo para realizar la actividad descrita previamente."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Perfil",
    "section": "",
    "text": "Licenciado en Matemáticas con orientación en Estadística, Data Scientist y candidato a economista en UNAH; trabajo en el modelado predictivo y visualización con un enfoque en teoría economica, soy un amante de los modelos predictivos de Machine Learning y Deep Learnig. Mi trabajo actual se centra en el uso del servicio de analisis de datos de Microsoft Power BI y lenguajes de programación como R y Python para el tratamiento de datos, uso de modelos actuariales para estimación de Balances Actuariales, Reservas Técnicas, seguimiento de Indicadores Actuariales y Revalorización de Pensiones en el Instituto Hondureño de Seguridad Social.\n\nEn este blog comparto y enseño todo lo que aprendo.\n\nApp Shiny/Dashboards\nGeoRGe\nEs una App que elabore en el lenguaje de programación R, utilizando los paquetes shiny | shinydashboard | DT | tidyverse | shinyWidgets | fresh. En la actualidad es utilizada en el Instituto Hondureño de Seguridad Social (IHSS).\nIA-JI\nApp que ayuda con el computo de algunos indicadores actuariales primarios y secundarios del IHSS, correspondientes al Régimen del Seguro de Previsión Social (RSPS).\n\n\nCampos de Interés y Trabajos Realizados\nBlack box models for forecasting financial time series\nBLiTZ-Bayesian LSTM for Uncertainty Quantification.\nIntermediate Microeconomics with R\nFacebook Prophet Model (Forecast Aplied to the USD/HNL exchange rate)\nMichine Learning in Tidyverse (Multiple Modules with broom)\nMachine Learning in Tidyverse (regression model and random forest model)\nActuarial Science"
  },
  {
    "objectID": "about.html#campos-de-interés-y-trabajos-realizados",
    "href": "about.html#campos-de-interés-y-trabajos-realizados",
    "title": "Perfil",
    "section": "Campos de Interés y Trabajos Realizados",
    "text": "Campos de Interés y Trabajos Realizados\n\nBlack box models for forecasting financial time series\nBLiTZ-Bayesian LSTM for Uncertainty Quantification.\nIntermediate Microeconomics with R\nFacebook Prophet Model (Forecast Aplied to the USD/HNL exchange rate)\nMichine Learning in Tidyverse (Multiple Modules with broom)\nMachine Learning in Tidyverse (regression model and random forest model)\nActuarial Science"
  },
  {
    "objectID": "about.html#paquetes-r-y-python-que-más-utilizo",
    "href": "about.html#paquetes-r-y-python-que-más-utilizo",
    "title": "CV",
    "section": "Paquetes R y Python que más utilizo",
    "text": "Paquetes R y Python que más utilizo\nTidyverse | Coleccion de paquetes orientados a manipulación, importación, exploración y visualización de datos.\nPyTorch | Biblioteca de Deep Learning con aplicaciones para redes neuronales.\nShiny | Paquete de R que facilita la creación de aplicaciones Web interactivas directamente desde R.\nlifecontingencies | Permite al usuario crear y manejar tablas de mortalidad, tablas actuariales (también tablas de decrementos múltiples). Además, contiene funciones para realizar facilmente matemáticas demográficas, financieras y actuariales en los cálculos de seguros de contingencias de vida.\nPerformanceAnalytics | Colección de funciones econométricas para el análisis de desempeño y riesg"
  },
  {
    "objectID": "about.html#paquetes-de-r-y-python-que-más-utilizo",
    "href": "about.html#paquetes-de-r-y-python-que-más-utilizo",
    "title": "Perfil",
    "section": "Paquetes de R y Python que más utilizo",
    "text": "Paquetes de R y Python que más utilizo\nTidyverse | Coleccion de paquetes orientados a manipulación, importación, exploración y visualización de datos.\nPyTorch | Biblioteca de Deep Learning con aplicaciones para redes neuronales.\nShiny | Paquete de R que facilita la creación de aplicaciones Web interactivas directamente desde R.\nlifecontingencies | Permite al usuario crear y manejar tablas de mortalidad, tablas actuariales (también tablas de decrementos múltiples). Además, contiene funciones para realizar facilmente matemáticas demográficas, financieras y actuariales en los cálculos de seguros de contingencias de vida.\nPerformanceAnalytics | Colección de funciones econométricas para el análisis de desempeño y riesg"
  },
  {
    "objectID": "posts/welcome/index.html#descripción-general-del-modelo",
    "href": "posts/welcome/index.html#descripción-general-del-modelo",
    "title": "Modelo Prophet de Facebook",
    "section": "Descripción General del Modelo",
    "text": "Descripción General del Modelo\nFacebook Prophet es un modelo y una biblioteca que proporciona características tanto de modelos lineales generalizados (MLG) como de modelos aditivos (MA), principalmente extendiendo el MLG mediante el uso de funciones de suavizado no lineal. Fue especificado por Taylor y Letham en 2017.\nProphet es un software de código abierto lanzado por el equipo Core Data Science de Facebook. Está disponible para su descarga en CRAN y PyPI. En esta ocasión usaremos el lenguaje R para implementar el modelo, sin embargo, tu puedes hacerlo en Python si es de tu preferencia.\nProphet funciona mejor con series temporales que tienen fuertes efectos estacionales y varias temporadas de datos históricos. Prophet es resistente a los datos faltantes y los cambios en la tendencia, y por lo general maneja bien los valores atípicos. Prophet esta diseñado especificamente para la predicción de series temporales de negocios.\nSu modelo aditivo que consta de cuatro componentes, esta dado por:\n\\[\ny(t) = g(t) + s(t) + h(t) + \\epsilon_{t}\n\\]\ndonde,\n\n\\(g(t)\\): Representa la tendencia y el objetivo es capturar la tendencia de la serie. Por ejemplo, es probable que la cantidad de vistas de anuncios de Facebook aumente con el tiempo a medida que más personas se unen a la red. Pero, ¿cuál sería la función exacta del aumento?\n\\(s(t)\\): Es el componente de Estacionalidad. El número de anuncios también puede depender de la temporada. Por ejemplo, en el hemisferio norte durante los meses de verano, es probable que las personas pasen más tiempo al aire libre y menos tiempo frente a sus computadoras. Tales fluctuaciones pueden ser muy diferentes para diferentes series temporales de negocios. El segundo componente es, por lo tanto, una función que modela las tendencias estacionales.\n\\(h(t)\\): Representa los efectos de las vaciones. Usamos la información para días festivos que tienen claro impacto en la mayoria de las series temporales comerciales. Tenga en cuenta que las vaciones varían entre años, países, etc. Y, por lo tanto, la información debe proporcionarse explícitamente al modelo.\n\\(\\epsilon_{t}\\): Es el término de error. Representa fluctuaciones aleatorias que el modelo no puede explicar. Como de costumbre, se supone que \\(\\epsilon_{t}\\) sigue una distribución \\(N(0,1)\\) con media cero y varianza desconocida \\(\\sigma\\) que debe derivarse de los datos ."
  },
  {
    "objectID": "posts/welcome/index.html#hiperparámetros",
    "href": "posts/welcome/index.html#hiperparámetros",
    "title": "Modelo Prophet de Facebook",
    "section": "Hiperparámetros",
    "text": "Hiperparámetros\nHay varios parámetros personalizables en la implementación de Facebook Prophet (revisar), siendo los principales:\n\nPuntos de cambio: definen los cambios de tendencia. Estos pueden ser encontrados por el propio algoritmo o también pueden ser definidos y ajustados por el analista.\nEstacionalidad: define las funciones periódicas que pueden afectar a la serie temporal. De forma predeterminada, Prophet considera la estacionalidad anual, semanal y diaria e intenta encontrar tendencias que representan esos efectos periódicos en los datos.\nDías festivos: los días especiales (días festivos o cualquier otro evento recurrente) también pueden ser modelados por el modelo aditivo.\n\nEn R, se usa la API de ajuste de modelo normal. Proporcionamos una función prophet que realiza el ajuste y devuelve un objeto de modelo. Posteriormeente usted puede llamar a la función predict y plot en este objeto modelo."
  },
  {
    "objectID": "posts/welcome/index.html#datos-y-preparación",
    "href": "posts/welcome/index.html#datos-y-preparación",
    "title": "Modelo Prophet de Facebook",
    "section": "Datos y Preparación",
    "text": "Datos y Preparación\nLos datos que utilizaremos los encontramos en Yahoo! Finance. Así como Python tiene un paquete para importar datos directamente de Yahoo Finance, R también cuenta con sus paquetes particular que nos permiten realizar una tarea similar. Necesitamos los siguiente paquetes:\n\nlibrary(TTR)\nlibrary(quantmod)\n\nLoading required package: xts\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nSi aún no los tienes instalados sugiero los instales usando install.packages(\"name paquete\"). Muy bien, ahora si estamos listos para poder extraer nuestros datos de yahoo finance y para ello usaremos la funcion getSymbols del paquete quantmod. Veamos,\n\ndf <- getSymbols('HNL=X',src = 'yahoo',\n                 from = \"2010-01-01\",\n                 to = \"2022-12-20\",\n                 auto.assign = FALSE)\n\nTenga en cuenta que from =  \"2010-01-01\" y to = \"2022-12-20\" nos ayudan a indicar desde que fecha quiero comenzar a tomar mis datos y hasta que fecha quiero tomarlos. Además, auto.assign = FALSE indica a getSymbols que devuelva los datos.\nAhora, conozcamos nuestros datos\n\nhead(df)\n\n           HNL=X.Open HNL=X.High HNL=X.Low HNL=X.Close HNL=X.Volume\n2010-01-04     18.690     18.691    18.517      18.518            0\n2010-01-05     18.550     18.550    18.550      18.550            0\n2010-01-06     18.572     18.645    18.544      18.545            0\n2010-01-07     18.451     18.550    18.451      18.539            0\n2010-01-08     18.556     18.556    18.556      18.556            0\n2010-01-11     18.550     18.550    18.550      18.550            0\n           HNL=X.Adjusted\n2010-01-04         18.518\n2010-01-05         18.550\n2010-01-06         18.545\n2010-01-07         18.539\n2010-01-08         18.556\n2010-01-11         18.550\n\n\nDe estos datos únicamente usaremos el valor de cierre (HNL=X.Close) de manera diaria del lempira hondureño contra el dólar, para enfocarnos solo en esos datos, primero convertiremos nuestro conjunto de datos df en un dataframe, dado que inicialmente es un objeto de tipo xts,\n\nclass(df)\n\n[1] \"xts\" \"zoo\"\n\n\npara realizar el cambio a un dataframe, considere la siguiente función\n\nxts_to_datframe<-function(data_xts){\n  df_t<-data.frame(fecha=(index(data_xts)),\n                   value=coredata(data_xts))\n  colnames(df_t)<-c(\"ds\", \"y\")\n  df_t\n}\n\nTiene que tener cuidado con el nombramiento de sus columnas, dado que prophet reconoce unicamente marcos de datos con columnas nombras como ds y y, qu contienen la fecha y el valor numérico de sus observaciones respectivamente. Con esto en mente, pasemos a transformar df a un objeto de clase dataframe por medio de la función que construimos previamente:\n\nHNL <- xts_to_datframe(df$`HNL=X.Close`) \nclass(HNL)\n\n[1] \"data.frame\"\n\n\nPuede apreciar que ya tenemos nuestro marco de datos como un dataframe, y estamos listos para comenzar a crear nuestro modelo."
  },
  {
    "objectID": "posts/welcome/index.html#implementación-del-modelo",
    "href": "posts/welcome/index.html#implementación-del-modelo",
    "title": "Modelo Prophet de Facebook",
    "section": "Implementación del Modelo",
    "text": "Implementación del Modelo\nPrimero visualicemos nuestros datos\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.5.0 \n✔ readr   2.1.2      ✔ forcats 0.5.1 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::first()  masks xts::first()\n✖ dplyr::lag()    masks stats::lag()\n✖ dplyr::last()   masks xts::last()\n\nlibrary(ggplot2)\n\nHNL %>% ggplot(aes(x = ds, y = y))+\n  geom_line()+\n  theme_minimal()+\n   labs(title = 'Datos Historicos del Tipo de Cambio del USD/HNL',\n       subtitle = '2010 - 2022',\n       x = 'Fecha',\n       y = 'HNL',\n       caption = 'Elaboracion propia con datos de yahoo finance')\n\n\n\n\n\nlibrary(prophet)\n\nLoading required package: Rcpp\n\n\nLoading required package: rlang\n\n\n\nAttaching package: 'rlang'\n\n\nThe following objects are masked from 'package:purrr':\n\n    %@%, as_function, flatten, flatten_chr, flatten_dbl, flatten_int,\n    flatten_lgl, flatten_raw, invoke, splice\n\nm <- prophet(HNL,daily.seasonality = TRUE)\n\nfuture <- make_future_dataframe(m,periods = 3,freq = 'day')\ntail(future)\n\n             ds\n3380 2022-12-16\n3381 2022-12-19\n3382 2022-12-20\n3383 2022-12-21\n3384 2022-12-22\n3385 2022-12-23\n\n\n\nforecast <- predict(m, future)\n\ndyplot.prophet(m, forecast)\n\n\n\n\n\nDe la figura previa,\n\nLos puntos negros representan medidas reales\nLa linea azul el pronóstico de Prophet\nLa banda azul representa el intervalo de incertidumbre"
  },
  {
    "objectID": "posts/welcome/index.html#desglose-del-pronóstico",
    "href": "posts/welcome/index.html#desglose-del-pronóstico",
    "title": "Modelo Prophet de Facebook",
    "section": "Desglose del Pronóstico",
    "text": "Desglose del Pronóstico\nSi bien el pronóstico arroja muchas cosas, podemos centrarnos en algunas como:\n\nds fecha que se pronostica\nyhat predicción para el valor y (tipo de cambio) ese día en particular.\nyhat_lower valor esperado más bajo para el rango del valor y previsto ese día\nyhat_upper valor esperado más alto para el rango de valor y previsto de ese día\n\nCon tail() podemos ver la salida de los últimos días pronosticados los cuales son 21, 22 y 23 de diciembre 2022.\n\ntail(forecast[c('ds', 'yhat', 'yhat_lower', 'yhat_upper')])\n\n             ds     yhat yhat_lower yhat_upper\n3380 2022-12-16 24.10924   23.40298   24.86902\n3381 2022-12-19 24.04473   23.33234   24.78901\n3382 2022-12-20 24.11075   23.32914   24.83456\n3383 2022-12-21 24.08755   23.29702   24.83339\n3384 2022-12-22 24.12633   23.38198   24.85544\n3385 2022-12-23 24.13436   23.40071   24.89330\n\n\nSegun nuestros resultados, nuestro modelo nos ve obteniendo para el día 21 de diciembre entre 23.35901 (yhat_lower) y 24.83438 (yhat_upper) lempiras por un dolar de EE.UU.\nPara entender el pronóstico más a detalle, podemos gráficar sus componentes con:\n\nprophet_plot_components(m,forecast)\n\n\n\n\nRecuerde que el fin de este post, no es abogar por el uso indiscriminado de Prophet como el mejor modelo para pronosticar el tipo de cambio hondureño vs el dólar. Espero hayas conocido las generalidades de este modelo y su utilidad en el ambito predictivo."
  },
  {
    "objectID": "posts/Machinne Learnig - Tidyverse/index.html",
    "href": "posts/Machinne Learnig - Tidyverse/index.html",
    "title": "Machinne Learning en Tidyverse",
    "section": "",
    "text": "Asumire que el lector tiene cierto conocimiento de la teoría de modelos lineales, en caso de no ser así, no te preocupes visita este link para que puedas ir a leer las generalidades de estos modelos y su uso en R, principalmente los tres paquetes de broom que le permiten explorar estos modelos. En este post trataremos de combinar estas técnica para aprender más sobre estos modelos y sus datos."
  },
  {
    "objectID": "posts/Machinne Learnig-Tidyverse/index.html",
    "href": "posts/Machinne Learnig-Tidyverse/index.html",
    "title": "Machinne Learning en Tidyverse",
    "section": "",
    "text": "Asumire que el lector tiene cierto conocimiento de la teoría de modelos lineales, en caso de no ser así, no te preocupes visita este link para que puedas ir a leer las generalidades de estos modelos y su uso en R, principalmente los tres paquetes de broom que le permiten explorar estos modelos. En este post trataremos de combinar estas técnica para aprender más sobre estos modelos y sus datos."
  },
  {
    "objectID": "posts/tidyverse/index.html",
    "href": "posts/tidyverse/index.html",
    "title": "Machine Learning en Tidyverse",
    "section": "",
    "text": "Asumire que el lector tiene cierto conocimiento de la teoría de modelos lineales, en caso de no ser así, no te preocupes visita este link para que puedas ir a leer las generalidades de estos modelos y su uso en R, principalmente los tres paquetes de broom que le permiten explorar estos modelos. En este post trataremos de combinar estas técnica para aprender más sobre estos modelos y sus datos.\nA continuación cargaremos algunos de los paquetes que nos ayudaran para poder realizar nuestra tarea,\n\nlibrary(tidyverse) # para manipulación de datos\nlibrary(gapminder) # marco de datos que utilizaremos \nlibrary(dslabs)    # conjunto de datos y funciones para analisis de datos\nlibrary(broom)     # Resumen informacion sobre objetos estadisticos en tibbles\n\nRecuerde que el marco de gapminder contiene informacion sobbre cada país desde 1960 hasta 2016. Crearemos una variable que llamaremos gap_anidado para obtener que las características de cada país este anidadas como un tibble. La ventaja de usar estos tibble es que podemos construir modelos lineales simples que predicen la esperanza de vida por año para cada país. Nos centraremos en aprender a usar los coeficientes de estos modelos para obtener nuevos conocimientos sobre los datos de gapminder.\n\ngap_anidado <- gapminder %>% group_by(country) %>% nest()\n\nhead(gap_anidado)\n\n# A tibble: 6 × 2\n# Groups:   country [6]\n  country             data             \n  <fct>               <list>           \n1 Albania             <tibble [57 × 8]>\n2 Algeria             <tibble [57 × 8]>\n3 Angola              <tibble [57 × 8]>\n4 Antigua and Barbuda <tibble [57 × 8]>\n5 Argentina           <tibble [57 × 8]>\n6 Armenia             <tibble [57 × 8]>\n\n\nTal como lo mencionamos previamente, gap_anidado contiene las características de cada país anidadas como un tibble. Con esto hecho, procederemos a construir modelos lineales para cada país, para ello usaremos la función map() del paquete purrr\n\ngap_models <- gap_anidado %>% \n  mutate(model = map(data, ~lm(life_expectancy~year,data = .x)))\n\ngap_models\n\n# A tibble: 185 × 3\n# Groups:   country [185]\n   country             data              model \n   <fct>               <list>            <list>\n 1 Albania             <tibble [57 × 8]> <lm>  \n 2 Algeria             <tibble [57 × 8]> <lm>  \n 3 Angola              <tibble [57 × 8]> <lm>  \n 4 Antigua and Barbuda <tibble [57 × 8]> <lm>  \n 5 Argentina           <tibble [57 × 8]> <lm>  \n 6 Armenia             <tibble [57 × 8]> <lm>  \n 7 Aruba               <tibble [57 × 8]> <lm>  \n 8 Australia           <tibble [57 × 8]> <lm>  \n 9 Austria             <tibble [57 × 8]> <lm>  \n10 Azerbaijan          <tibble [57 × 8]> <lm>  \n# … with 175 more rows\n\n\n\n\n\\[y = \\alpha + \\beta x\\]\nRepasemos brevemente cómo interpretar los coeficientes para un modelo de regresión lineal simple. Recuerda que esto implica calcular dos términos de coeficientes que relacionan la variable dependiente con la variable independiente \\(x\\).\nPara nuestros modelos, las variales:\n\n\\(y\\): Representa la esperanza de vida en relación con el año (variable \\(x\\)).\n\\(\\alpha\\): Representa el coeficiente del intercepto, nos dice la esperanza en el año 0. Esto no es significativo para nuestros datos, por lo que lo pasaremos por alto.\n\\(\\beta\\): Es el coeficiente del año (variable \\(x\\)), que para un modelo de regresión lineal simple corresponde directamente a la pendiente del mismo.\n\nUsando la función tidy() del paquete broom en el primer modelo, aprenderemos que con cada año que pasa la esperanza de vida promedio de la población de este país en particular aumenta aproximadamente 0.23 años. Este enfoque puede brindarle información sobre el crecimiento o la falta de crecimiento en la esperanza de vida a lo largo del tiempo para los países que esta modelando.\n\ntidy(gap_models$model[[1]])\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept) -397.     12.4         -32.1 2.48e-37\n2 year           0.236   0.00622      38.0 3.72e-41\n\n\n\n\n\nPuede generar estos coeficientes mapeando la funcíon tidy() para cada uno de nuestros modelos y luego simplificando el nuevo marco de datos usando la función unnest(). Esto da como resultado un tibble que contiene la estimación para cada coeficiente de cada país.\n\ngap_models %>% \n  mutate(coef = map(model, ~tidy(.x))) %>% \n  unnest(coef)\n\n# A tibble: 370 × 8\n# Groups:   country [185]\n   country             data     model  term    estimate std.e…¹ stati…²  p.value\n   <fct>               <list>   <list> <chr>      <dbl>   <dbl>   <dbl>    <dbl>\n 1 Albania             <tibble> <lm>   (Inter… -3.97e+2 1.24e+1   -32.1 2.48e-37\n 2 Albania             <tibble> <lm>   year     2.36e-1 6.22e-3    38.0 3.72e-41\n 3 Algeria             <tibble> <lm>   (Inter… -1.10e+3 4.05e+1   -27.2 1.51e-33\n 4 Algeria             <tibble> <lm>   year     5.86e-1 2.04e-2    28.8 7.84e-35\n 5 Angola              <tibble> <lm>   (Inter… -7.48e+2 1.12e+1   -67.0 2.03e-54\n 6 Angola              <tibble> <lm>   year     4.01e-1 5.62e-3    71.4 6.69e-56\n 7 Antigua and Barbuda <tibble> <lm>   (Inter… -3.79e+2 1.56e+1   -24.2 5.19e-31\n 8 Antigua and Barbuda <tibble> <lm>   year     2.26e-1 7.87e-3    28.8 7.64e-35\n 9 Argentina           <tibble> <lm>   (Inter… -3.56e+2 7.67e+0   -46.4 8.83e-46\n10 Argentina           <tibble> <lm>   year     2.15e-1 3.86e-3    55.7 4.58e-50\n# … with 360 more rows, and abbreviated variable names ¹​std.error, ²​statistic\n\n\n\n\n\nAnteriormente aprovechamos la función tidy() de broom para explorar los coeficientes de nuestros modelos. Al hacerlo, obtuvimos información sobre cómo cambió la esperanza de vida con el tiempo para cada uno de los países en nuestro conjunto de datos. Ahora, aprenderá a usar la función glance() de broom para medir que tan bien se ajusta cada uno de estos modelos a sus datos subyacentes.\nUna forma de medir el ajuste de un modelo de regresión lineal es calcular su métrica \\(R^2\\)\n\\[\nR^2 = \\frac{\\%~variación~explicada~por~el~modelo}{\\%~variación~total~de~los~datos}\n\\]\nLa métrica \\(R^2\\) mide la relación entre la variación explicada por el modelo de regresión y la variación total de los datos. Toma valores entre 0 y 1.\nEn la siguiente figura, le muestro dos ejemplos, el primero con un valor alto y el segundo con un valor bajo de su \\(R^2\\) respectivamente. Note que en el caso donde el \\(R^2 = 0.009\\) es bajo o cercano a cero, esto nos indica que un modelo lineal esta capturando una cantidad proporcionalmente pequeña de la variación en los datos y. por lo tanto, no se ajusta bien. Por el contrario el modelo con \\(R^2 = 0.965\\) valor que es más cercano a 1, lo que indica que este modelo lineal se ajusta bien a los datos. Puede evaluar el ajuste de los modelos midiendo el valor del \\(R^2\\) para cada modelo.\n\nMuy bien, con el conocimiento previo, hechemos un vistazo a nuestros modelos. Para ello usamos map() y glance() para crear un marco de datos de estadísticas de resumen para cada modelo almacenado como la columna coef. Luego, puede simplificar estos marcos de datos usando la función unnest(). Esto nos dará como resultado un tibble que contendrá las estadisticas del modelo para cada modelo de país.\n\nmodel_perf <- gap_models %>% \n  mutate(coef = map(model,~glance(.x))) %>% \n  unnest(coef)\n\nmodel_perf\n\n# A tibble: 185 × 15\n# Groups:   country [185]\n   country    data     model r.squ…¹ adj.r…² sigma stati…³  p.value    df logLik\n   <fct>      <list>   <lis>   <dbl>   <dbl> <dbl>   <dbl>    <dbl> <dbl>  <dbl>\n 1 Albania    <tibble> <lm>    0.963   0.963 0.772  1443.  3.72e-41     1  -65.1\n 2 Algeria    <tibble> <lm>    0.938   0.937 2.53    828.  7.84e-35     1 -133. \n 3 Angola     <tibble> <lm>    0.989   0.989 0.698  5091.  6.69e-56     1  -59.3\n 4 Antigua a… <tibble> <lm>    0.938   0.937 0.977   828.  7.64e-35     1  -78.6\n 5 Argentina  <tibble> <lm>    0.983   0.982 0.479  3103.  4.58e-50     1  -37.9\n 6 Armenia    <tibble> <lm>    0.288   0.275 1.57     22.2 1.70e- 5     1 -106. \n 7 Aruba      <tibble> <lm>    0.882   0.880 0.964   412.  3.28e-27     1  -77.8\n 8 Australia  <tibble> <lm>    0.983   0.983 0.540  3240.  1.42e-50     1  -44.7\n 9 Austria    <tibble> <lm>    0.989   0.989 0.430  4949.  1.45e-55     1  -31.7\n10 Azerbaijan <tibble> <lm>    0.679   0.673 1.54    116.  3.48e-15     1 -105. \n# … with 175 more rows, 5 more variables: AIC <dbl>, BIC <dbl>, deviance <dbl>,\n#   df.residual <int>, nobs <int>, and abbreviated variable names ¹​r.squared,\n#   ²​adj.r.squared, ³​statistic\n\n\nSi observamos los valores de \\(R^2\\) de los primeros 5 modelos notamos que tienen un \\(R^2\\) alto, lo que nos dice que los modelos para estos países se han ajustado bien a los datos de esos países en particular.\n\n\n\nSiendo un poco más curiosos, tratemos de explorar el ajuste de los modelos. Para ver esto, podemos filtrar los valores más alto de r.squared, tomaremos como un r.squared alto 0.995 en adelante.\nPor ejemplo, podemos usar la función slice_max() de dplyr para encontrar los modelos que mejor se ajustan. Asimismo, podemos encontrar los modelos con el peor ajuste utilizando la función slice_min(). Hechemos un vistazo al código y los resultados generados,\n\nmejores_models <- model_perf %>% filter(r.squared > 0.995)\nmejores_models\n\n# A tibble: 3 × 15\n# Groups:   country [3]\n  country     data     model r.squ…¹ adj.r…² sigma stati…³  p.value    df logLik\n  <fct>       <list>   <lis>   <dbl>   <dbl> <dbl>   <dbl>    <dbl> <dbl>  <dbl>\n1 Bahamas     <tibble> <lm>    0.995   0.995 0.235  11428. 1.74e-65     1  2.67 \n2 Israel      <tibble> <lm>    0.996   0.996 0.250  15626. 3.29e-69     1 -0.826\n3 Switzerland <tibble> <lm>    0.996   0.995 0.244  12349. 2.08e-66     1  0.508\n# … with 5 more variables: AIC <dbl>, BIC <dbl>, deviance <dbl>,\n#   df.residual <int>, nobs <int>, and abbreviated variable names ¹​r.squared,\n#   ²​adj.r.squared, ³​statistic\n\n\ny para los peores filtremos los países que tienen un modelo con un r.squared menor a 0.3\n\npeores_modelos <- model_perf %>% filter(r.squared < 0.3) \npeores_modelos\n\n# A tibble: 12 × 15\n# Groups:   country [12]\n   country    data     model r.squ…¹ adj.r.…² sigma stati…³ p.value    df logLik\n   <fct>      <list>   <lis>   <dbl>    <dbl> <dbl>   <dbl>   <dbl> <dbl>  <dbl>\n 1 Armenia    <tibble> <lm>  2.88e-1  0.275    1.57 2.22e+1 1.70e-5     1 -106. \n 2 Botswana   <tibble> <lm>  8.21e-4 -0.0173   4.98 4.52e-2 8.32e-1     1 -171. \n 3 Central A… <tibble> <lm>  2.76e-1  0.262    3.13 2.09e+1 2.76e-5     1 -145. \n 4 Latvia     <tibble> <lm>  1.92e-1  0.177    1.88 1.31e+1 6.49e-4     1 -116. \n 5 Lesotho    <tibble> <lm>  3.46e-2  0.0170   5.23 1.97e+0 1.66e-1     1 -174. \n 6 Lithuania  <tibble> <lm>  2.94e-1  0.281    1.24 2.29e+1 1.32e-5     1  -92.0\n 7 Russia     <tibble> <lm>  2.63e-2  0.00856  1.80 1.48e+0 2.28e-1     1 -113. \n 8 South Afr… <tibble> <lm>  2.69e-1  0.256    3.57 2.03e+1 3.54e-5     1 -152. \n 9 Swaziland  <tibble> <lm>  6.92e-5 -0.0181   5.83 3.80e-3 9.51e-1     1 -180. \n10 Ukraine    <tibble> <lm>  1.73e-1  0.158    1.41 1.15e+1 1.30e-3     1  -99.4\n11 Zambia     <tibble> <lm>  4.13e-2  0.0239   4.13 2.37e+0 1.30e-1     1 -161. \n12 Zimbabwe   <tibble> <lm>  1.37e-1  0.122    5.75 8.75e+0 4.55e-3     1 -180. \n# … with 5 more variables: AIC <dbl>, BIC <dbl>, deviance <dbl>,\n#   df.residual <int>, nobs <int>, and abbreviated variable names ¹​r.squared,\n#   ²​adj.r.squared, ³​statistic\n\n\n\n\n\nPara hacer esto, primero debe crear un marco de datos que contenga tanto los valores predichos como los originales. Esto requiere primero usar map() y augment() para trabajar en la columna de la lista que contiene los modelos para crear marcos de datos anidados que contengan tanto los valores originales como los predichos. Luego, puede usar unnest() en esta nueva columna para simplificar estos marcos de datos y permitir una mayor exploración.\n\naugment_models <- gap_models %>% \n  mutate(augmented = map(model,~augment(.x))) %>% \n  unnest(augmented)\n\naugment_models\n\n# A tibble: 10,545 × 11\n# Groups:   country [185]\n   country data     model  life_exp…¹  year .fitted .resid   .hat .sigma .cooksd\n   <fct>   <list>   <list>      <dbl> <int>   <dbl>  <dbl>  <dbl>  <dbl>   <dbl>\n 1 Albania <tibble> <lm>         62.9  1960    65.7 -2.80  0.0684  0.672 0.517  \n 2 Albania <tibble> <lm>         63.9  1961    65.9 -1.99  0.0648  0.728 0.245  \n 3 Albania <tibble> <lm>         64.8  1962    66.1 -1.30  0.0614  0.758 0.0989 \n 4 Albania <tibble> <lm>         65.6  1963    66.4 -0.778 0.0581  0.772 0.0332 \n 5 Albania <tibble> <lm>         66.2  1964    66.6 -0.434 0.0549  0.777 0.00970\n 6 Albania <tibble> <lm>         66.6  1965    66.9 -0.260 0.0518  0.779 0.00327\n 7 Albania <tibble> <lm>         66.9  1966    67.1 -0.206 0.0489  0.779 0.00193\n 8 Albania <tibble> <lm>         67.1  1967    67.3 -0.213 0.0461  0.779 0.00192\n 9 Albania <tibble> <lm>         67.3  1968    67.6 -0.239 0.0435  0.779 0.00227\n10 Albania <tibble> <lm>         67.6  1969    67.8 -0.245 0.0409  0.779 0.00224\n# … with 10,535 more rows, 1 more variable: .std.resid <dbl>, and abbreviated\n#   variable name ¹​life_expectancy\n\n\nAhora, visualizaremos algunos de estos modelos.\n\n\n\nNote que dado que su \\(R^2\\) es bastante alto, podemos asumir que el modelo lineal se ajusta bien a los datos. Puede comparar el ajuste del modelo con los datos originales trazando ambos en el mismo gráfico. En este ejemplo, usaremos ggplot2 para trazar los valores originales de la esperanza de vida como un diagrama de dispensión usando geom_point() y agregué el ajuste del modelo lineal como una línea roja usando geom_line()\n\naugment_models %>% filter(country == \"Bahamas\") %>% \n  ggplot(aes(x = year, y = life_expectancy)) + \n  geom_point() + \n  geom_line(aes(y = .fitted), color = \"red\") + \n  labs(title = \"Modelo Regresión Lineal para Bahamas\",\n       x = \"Año\",\n       y = \"Esperanza de Vida\") + \n  theme_minimal()\n\n\n\n\nSi observa el gráfico, podemos pensar que un modelo de regresión lineal se va ajustando bien a los datos de este país en particular.\n\n\n\nAhora veamos el modelo correspondiente al país Ukraine, que tiene un valor de \\(R^2\\) super más bajo que el de Bahamas. Claramente, esperariamos encontrarnos con un modelo que no se ajuste bien a los datos dado el antecedente del \\(R^2\\)\n\naugment_models %>% filter(country == \"Ukraine\") %>% \n  ggplot(aes(x = year, y = life_expectancy)) + \n  geom_point() + \n  geom_line(aes(y = .fitted), color = \"red\") + \n  labs(title = \"Modelo de Regresión Lineal para Ukraine\", \n       x = \"Año\", \n       y = \"Esperanza de  Vida\") + \n  theme_minimal()\n\n\n\n\nComo pudo ver en estos dos ejemplos, augment() y ggplot() facilitan la exploración visual del ajuste de un modelo.\n\n\n\nEn este caso, prepararemos los cuatro mejores modelos que consideramos anteriormente y los peores y los visualizaremos,\n\nmejores_augment <- mejores_models %>% \n  mutate(augmented = map(model, ~augment(.x))) %>% \n  unnest(augmented)\n\npeores_augment <- peores_modelos %>% \n  mutate(augmented = map(model, ~augment(.x))) %>% \n  unnest(augmented)\n\nBien, ahora visualizamos los modelos\n\nmejores_augment %>% \n  ggplot(aes(x = year)) + \n  geom_point(aes(y = life_expectancy)) + \n  geom_line(aes(y = .fitted), color = \"red\") + \n  facet_wrap(~country, scales = \"free_y\") + \n  theme_minimal()\n\n\n\n\n\npeores_augment %>% \n  ggplot(aes(x = year)) + \n  geom_point(aes(y = life_expectancy)) + \n  geom_line(aes(y = .fitted), color = \"red\") + \n  facet_wrap(~country, scales = \"free_y\") + \n  theme_minimal()\n\n\n\n\nParcelas geniales! Puede ver que un modelo lineal hace un gran trabajo para los mejores 3 modelos de ajuste, pero los peores modelos de ajuste no parecen tener una relación lineal. Trabajaremos para mejorar este ajuste en la proxima serie de ejercicios mediante la incorporación de funciones adicionales.\n\n\n\nCon la información que reunimos con Augment() y glance(), aprendimos que algunos de los modelos de regresión lineal simple no se ajustan adecuadamente a las tendencias subyacentes de nuestros datos. Para separar esto emplearemos un modelo de regresión múltiple.\n\n\n\\[Y = \\alpha + \\beta_1x_1 9 \\beta_2x_2 + . . . \\]\nEste modelo es una extensión natural del modelo de regresión lineal simple. La diferencia clave es que usa más variables explicativas para explicar el resultados, lo que significa que, en lugar de ajustar una linea de mejor ajuste, estamos ajustando un plano multidimensional. En el conjunto de datos gapminder, podemos usar características adicionales de nuestras observaciones para modelr la esperanza de vida. Entonces, vamos a usarlo,\nLa elección de que características usar se puede controlar en el campo de fórmula de la función lm(). Recuerde que para un modelo simple usamos la fórmula de la esperanza de vida explicada por año. De manera similar para un modelo de regresión múltiple, puede definir explícitamente la fórmula incluyendo el nombre de cada característica separada por un signo + o si sabe que desa incluir todas las características, puede capturarlas usando un punto,como veremos posteriormente.\n\n\n\nEl comportamiento de las funciones de broom sigue siendo el mismo. tidy() devuelve las estimaciones de los coeficientes de los modelos, esto ahora incluye estimaciones para las cuatro características adicionales. Lo mismo ocurre con augment(), además, de los valores ajustados para cada observación, se devuelven los valores de cuatro caracteristicas nuevas. y aunque la salida esperada de glance() sigue siendo la misma, tenemos que cambiar nuestro enfoque del valor de r cuadrado al valor de r cuadrado ajustado al evaluar el ajuste de nuestros modelos o comparar modelos de regresión lineal simple y múltiple.\n\n\n\nRecuerde que r.squared mide la variación explicada por el modelo. Agregar cualquier característica nueva a un modelo, independientemente de su relación con la variable dependiente, siempre aumentará el valor de r.squared del modelo. Esto se vuelve problemático cuando se compara el ajuste de modelos con diferente número de características explicativas utilizadas. Para compensar esto, en su lugar, utilizará el valor adj.r.squared (r cuadrado ajustado) esta es una métrica r cuadrada modificada cuyo cálculo tiene en cuenta la cantidad de características utilizadas en el modelo.\nLa interpretación del adj.r.squared es muy similar al r.squared y lo usaremos para evaluar el ajuste de nuestros modelos y compararlos con los modelos lineales simples creados anteriormente.\n\n\n\n\nAnteriormente, creamos una colección de modelos simples para ajustarse a la expectativa de vida usando la característica de año. Su análisis anterior mostro que algunos de estos modelos no encajaban muy bien.\nEn esta sección, construiremos modelos de regresión múltiple para cada país utilizando todas las funciones disponibles. Puede que le interese comparar el rendimiento de los 12 modelos con el peor ajuste\n\n\n\nPaís\nAdj.r.squared\n\n\n\n\nArmenia\n0.274831633\n\n\nBotswana\n-0.017346290\n\n\nCentral African Republic\n0.262392009\n\n\nLatvia\n0.177428933\n\n\nLesotho\n0.017078583\n\n\nLithuania\n0.281255888\n\n\nRussia\n0.008564872\n\n\nSouth Africa\n0.255968853\n\n\nSwaziland\n-0.018111402\n\n\nUkraine\n0.157855451\n\n\nZambia\n0.023859596\n\n\nZimbabwe\n0.1216212616\n\n\n\nAhora si, apliquemos un modelo lineal generalizado para ver si mejorar estos datos\n\n# Creamos un modelo lineal para cada país\ngap_fullmodel <- gap_anidado %>% \n  mutate(model = map(data, \n                     ~lm(life_expectancy~year+population+fertility+gdp, data = .x)))\n\nfullmodel_perf <- gap_fullmodel %>% \n  # Extraigaimos las estadísticas de ajuste de cada modelo en marcos de datos\n  mutate(fit = map(model, ~glance(.x))) %>% \n  # Simplifiquemos los marcos de datos de ajuste para cada modelo\n  unnest(fit)\n\n# Vea el rendimiento de los 12 países con el peor ajuste, es decir, \n# los dos modelos simples que viste antes\nfullmodel_perf %>% \n  filter(country %in% peores_modelos$country) %>% \n  select(country, adj.r.squared)\n\n# A tibble: 12 × 2\n# Groups:   country [12]\n   country                  adj.r.squared\n   <fct>                            <dbl>\n 1 Armenia                          0.923\n 2 Botswana                         0.736\n 3 Central African Republic         0.931\n 4 Latvia                           0.687\n 5 Lesotho                          0.855\n 6 Lithuania                        0.893\n 7 Russia                           0.652\n 8 South Africa                     0.896\n 9 Swaziland                        0.905\n10 Ukraine                          0.692\n11 Zambia                           0.872\n12 Zimbabwe                         0.978\n\n\nNote que los valores para adj.r.squared mejoraron considerablemente. Si bien adj.r.squared nos dice qué tan bien se ajusta el modelo a nuestros datos, no da ninguna indicación sobre cómo se desempeñaria con nuevos datos. En otro post, les mostraré como estimar el rendimiento del modelo utilizando los datos retenidos de la construcción del modelo."
  },
  {
    "objectID": "posts/tidyverse/index.html#descripción-general-del-modelo",
    "href": "posts/tidyverse/index.html#descripción-general-del-modelo",
    "title": "Machine Learning en Tidyverse",
    "section": "Descripción General del Modelo",
    "text": "Descripción General del Modelo\nFacebook Prophet es un modelo y una biblioteca que proporciona características tanto de modelos lineales generalizados (MLG) como de modelos aditivos (MA), principalmente extendiendo el MLG mediante el uso de funciones de suavizado no lineal. Fue especificado por Taylor y Letham en 2017.\nProphet es un software de código abierto lanzado por el equipo Core Data Science de Facebook. Está disponible para su descarga en CRAN y PyPI. En esta ocasión usaremos el lenguaje R para implementar el modelo, sin embargo, tu puedes hacerlo en Python si es de tu preferencia.\nProphet funciona mejor con series temporales que tienen fuertes efectos estacionales y varias temporadas de datos históricos. Prophet es resistente a los datos faltantes y los cambios en la tendencia, y por lo general maneja bien los valores atípicos. Prophet esta diseñado especificamente para la predicción de series temporales de negocios.\nSu modelo aditivo que consta de cuatro componentes, esta dado por:\n\\[\ny(t) = g(t) + s(t) + h(t) + \\epsilon_{t}\n\\]\ndonde,\n\n\\(g(t)\\): Representa la tendencia y el objetivo es capturar la tendencia de la serie. Por ejemplo, es probable que la cantidad de vistas de anuncios de Facebook aumente con el tiempo a medida que más personas se unen a la red. Pero, ¿cuál sería la función exacta del aumento?\n\\(s(t)\\): Es el componente de Estacionalidad. El número de anuncios también puede depender de la temporada. Por ejemplo, en el hemisferio norte durante los meses de verano, es probable que las personas pasen más tiempo al aire libre y menos tiempo frente a sus computadoras. Tales fluctuaciones pueden ser muy diferentes para diferentes series temporales de negocios. El segundo componente es, por lo tanto, una función que modela las tendencias estacionales.\n\\(h(t)\\): Representa los efectos de las vaciones. Usamos la información para días festivos que tienen claro impacto en la mayoria de las series temporales comerciales. Tenga en cuenta que las vaciones varían entre años, países, etc. Y, por lo tanto, la información debe proporcionarse explícitamente al modelo.\n\\(\\epsilon_{t}\\): Es el término de error. Representa fluctuaciones aleatorias que el modelo no puede explicar. Como de costumbre, se supone que \\(\\epsilon_{t}\\) sigue una distribución \\(N(0,1)\\) con media cero y varianza desconocida \\(\\sigma\\) que debe derivarse de los datos ."
  },
  {
    "objectID": "posts/tidyverse/index.html#hiperparámetros",
    "href": "posts/tidyverse/index.html#hiperparámetros",
    "title": "Machine Learning en Tidyverse",
    "section": "Hiperparámetros",
    "text": "Hiperparámetros\nHay varios parámetros personalizables en la implementación de Facebook Prophet (revisar), siendo los principales:\n\nPuntos de cambio: definen los cambios de tendencia. Estos pueden ser encontrados por el propio algoritmo o también pueden ser definidos y ajustados por el analista.\nEstacionalidad: define las funciones periódicas que pueden afectar a la serie temporal. De forma predeterminada, Prophet considera la estacionalidad anual, semanal y diaria e intenta encontrar tendencias que representan esos efectos periódicos en los datos.\nDías festivos: los días especiales (días festivos o cualquier otro evento recurrente) también pueden ser modelados por el modelo aditivo.\n\nEn R, se usa la API de ajuste de modelo normal. Proporcionamos una función prophet que realiza el ajuste y devuelve un objeto de modelo. Posteriormeente usted puede llamar a la función predict y plot en este objeto modelo."
  },
  {
    "objectID": "posts/tidyverse/index.html#datos-y-preparación",
    "href": "posts/tidyverse/index.html#datos-y-preparación",
    "title": "Machine Learning en Tidyverse",
    "section": "Datos y Preparación",
    "text": "Datos y Preparación\nLos datos que utilizaremos los encontramos en Yahoo! Finance. Así como Python tiene un paquete para importar datos directamente de Yahoo Finance, R también cuenta con sus paquetes particular que nos permiten realizar una tarea similar. Necesitamos los siguiente paquetes:\n\nlibrary(TTR)\nlibrary(quantmod)\n\nLoading required package: xts\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nSi aún no los tienes instalados sugiero los instales usando install.packages(\"name paquete\"). Muy bien, ahora si estamos listos para poder extraer nuestros datos de yahoo finance y para ello usaremos la funcion getSymbols del paquete quantmod. Veamos,\n\ndf <- getSymbols('HNL=X',src = 'yahoo',\n                 from = \"2010-01-01\",\n                 to = \"2022-12-20\",\n                 auto.assign = FALSE)\n\nTenga en cuenta que from =  \"2010-01-01\" y to = \"2022-12-20\" nos ayudan a indicar desde que fecha quiero comenzar a tomar mis datos y hasta que fecha quiero tomarlos. Además, auto.assign = FALSE indica a getSymbols que devuelva los datos.\nAhora, conozcamos nuestros datos\n\nhead(df)\n\n           HNL=X.Open HNL=X.High HNL=X.Low HNL=X.Close HNL=X.Volume\n2010-01-04     18.690     18.691    18.517      18.518            0\n2010-01-05     18.550     18.550    18.550      18.550            0\n2010-01-06     18.572     18.645    18.544      18.545            0\n2010-01-07     18.451     18.550    18.451      18.539            0\n2010-01-08     18.556     18.556    18.556      18.556            0\n2010-01-11     18.550     18.550    18.550      18.550            0\n           HNL=X.Adjusted\n2010-01-04         18.518\n2010-01-05         18.550\n2010-01-06         18.545\n2010-01-07         18.539\n2010-01-08         18.556\n2010-01-11         18.550\n\n\nDe estos datos únicamente usaremos el valor de cierre (HNL=X.Close) de manera diaria del lempira hondureño contra el dólar, para enfocarnos solo en esos datos, primero convertiremos nuestro conjunto de datos df en un dataframe, dado que inicialmente es un objeto de tipo xts,\n\nclass(df)\n\n[1] \"xts\" \"zoo\"\n\n\npara realizar el cambio a un dataframe, considere la siguiente función\n\nxts_to_datframe<-function(data_xts){\n  df_t<-data.frame(fecha=(index(data_xts)),\n                   value=coredata(data_xts))\n  colnames(df_t)<-c(\"ds\", \"y\")\n  df_t\n}\n\nTiene que tener cuidado con el nombramiento de sus columnas, dado que prophet reconoce unicamente marcos de datos con columnas nombras como ds y y, qu contienen la fecha y el valor numérico de sus observaciones respectivamente. Con esto en mente, pasemos a transformar df a un objeto de clase dataframe por medio de la función que construimos previamente:\n\nHNL <- xts_to_datframe(df$`HNL=X.Close`) \nclass(HNL)\n\n[1] \"data.frame\"\n\n\nPuede apreciar que ya tenemos nuestro marco de datos como un dataframe, y estamos listos para comenzar a crear nuestro modelo."
  },
  {
    "objectID": "posts/tidyverse/index.html#implementación-del-modelo",
    "href": "posts/tidyverse/index.html#implementación-del-modelo",
    "title": "Machine Learning en Tidyverse",
    "section": "Implementación del Modelo",
    "text": "Implementación del Modelo\nPrimero visualicemos nuestros datos\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.5.0 \n✔ readr   2.1.2      ✔ forcats 0.5.1 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::first()  masks xts::first()\n✖ dplyr::lag()    masks stats::lag()\n✖ dplyr::last()   masks xts::last()\n\nlibrary(ggplot2)\n\nHNL %>% ggplot(aes(x = ds, y = y))+\n  geom_line()+\n  theme_minimal()+\n   labs(title = 'Datos Historicos del Tipo de Cambio del USD/HNL',\n       subtitle = '2010 - 2022',\n       x = 'Fecha',\n       y = 'HNL',\n       caption = 'Elaboracion propia con datos de yahoo finance')\n\n\n\n\n\nlibrary(prophet)\n\nLoading required package: Rcpp\n\n\nLoading required package: rlang\n\n\n\nAttaching package: 'rlang'\n\n\nThe following objects are masked from 'package:purrr':\n\n    %@%, as_function, flatten, flatten_chr, flatten_dbl, flatten_int,\n    flatten_lgl, flatten_raw, invoke, splice\n\nm <- prophet(HNL,daily.seasonality = TRUE)\n\nfuture <- make_future_dataframe(m,periods = 3,freq = 'day')\ntail(future)\n\n             ds\n3380 2022-12-16\n3381 2022-12-19\n3382 2022-12-20\n3383 2022-12-21\n3384 2022-12-22\n3385 2022-12-23\n\n\n\nforecast <- predict(m, future)\n\ndyplot.prophet(m, forecast)\n\n\n\n\n\nDe la figura previa,\n\nLos puntos negros representan medidas reales\nLa linea azul el pronóstico de Prophet\nLa banda azul representa el intervalo de incertidumbre"
  },
  {
    "objectID": "posts/tidyverse/index.html#desglose-del-pronóstico",
    "href": "posts/tidyverse/index.html#desglose-del-pronóstico",
    "title": "Machine Learning en Tidyverse",
    "section": "Desglose del Pronóstico",
    "text": "Desglose del Pronóstico\nSi bien el pronóstico arroja muchas cosas, podemos centrarnos en algunas como:\n\nds fecha que se pronostica\nyhat predicción para el valor y (tipo de cambio) ese día en particular.\nyhat_lower valor esperado más bajo para el rango del valor y previsto ese día\nyhat_upper valor esperado más alto para el rango de valor y previsto de ese día\n\nCon tail() podemos ver la salida de los últimos días pronosticados los cuales son 21, 22 y 23 de diciembre 2022.\n\ntail(forecast[c('ds', 'yhat', 'yhat_lower', 'yhat_upper')])\n\n             ds     yhat yhat_lower yhat_upper\n3380 2022-12-16 24.10924   23.38237   24.77015\n3381 2022-12-19 24.04473   23.34807   24.83821\n3382 2022-12-20 24.11075   23.42157   24.87120\n3383 2022-12-21 24.08755   23.35328   24.79132\n3384 2022-12-22 24.12633   23.40594   24.81080\n3385 2022-12-23 24.13436   23.37964   24.81741\n\n\nSegun nuestros resultados, nuestro modelo nos ve obteniendo para el día 21 de diciembre entre 23.35901 (yhat_lower) y 24.83438 (yhat_upper) lempiras por un dolar de EE.UU.\nPara entender el pronóstico más a detalle, podemos gráficar sus componentes con:\n\nprophet_plot_components(m,forecast)\n\n\n\n\nRecuerde que el fin de este post, no es abogar por el uso indiscriminado de Prophet como el mejor modelo para pronosticar el tipo de cambio hondureño vs el dólar. Espero hayas conocido las generalidades de este modelo y su utilidad en el ambito predictivo."
  },
  {
    "objectID": "posts/arima/index.html",
    "href": "posts/arima/index.html",
    "title": "Series de Tiempo",
    "section": "",
    "text": "Una serie temporal es una colección de observaciones indexadas por la fecha de cada observación, denotada por \\(y_t\\)\n\\[\n\\{y_1, y_2, . . . . , y_T\\}\n\\]\nEn la práctica se asume que lo anterior es sólo una muestra, pero que la serie pudo haber sido observada en más periodos.\n\\[\n\\{y_t\\}_{t = -\\infty}^\\infty = \\{. . . , y_{-1}, y_0, y_1, y_2, . . . , y_T,y_{T+1},y_{T+2}, . . .\\}\n\\]\nEn el análisis de series temporales el objetivo es extraer parámetros relevantes o características de ellas. Estas características pueden ser luego utilizadas para generar un modelo matemático que describa la serie y pueda ser utilizado para realizar predicciones.\nDe acuerdo a la cantidad de variables variables o características que la serie temporal contenga se considera univariada para el caso de una variable, o multivariada para el caso de multiples variables. De esta fundamental característica depende los pasos a seguir para su análisis y prediccón.\n\n\nUn paquete que utilizaremos mucho durante este post es astsa, que significa Análisis de series de tiempo estadístico aplicado.\nAhora, para comenzar, exploremos la naturaleza de los datos de series de tiempo. Aquí tenemos la serie de ganancias trimestrales por acción de Johnson & Johnson.\n\nlibrary(astsa)\n\nplot(jj, main = \"Ganancias Trimestrales por Acción de Johnson & Johnson\",type = \"c\")\ntext(jj, labels = 1:4, col = 1:4)\n\n\n\n\nTiene algunas características comunes de los datos de series de tiempo, tendencia al alza, estacionalidad en el sentido de que el seguendo y el tercer trimestre suelen subir, mientras que el cuarto trimestre suele bajar. Además existe heterosticidad porque, a medida que crece el valor del activo, los pequeños cambios porcentuales se convierten en grandes cambios absolutos.\nMuy bien previamente mencionamos dos palabras importantes en el análisis de series temporales, las cuales son heterosticidad y estacionariedad, antes de continuar definiremos esta terminología:\n\n\nLa base del análisis de series de tiempo es la estacionariedad. Se dice que una serie de tiempo \\(\\{y_t\\}\\) es estrictamente estacionaria si la distribución conjunta \\((y_{t_1}, . . . , y_{t_k})\\) es idéntica a la de \\((y_{t_1+t}, . . . , y_{t_k+t})\\), para todo \\(t\\), donde \\(k\\) es un entero positivo arbitrario y \\((t_1, . . . , t_k)\\) es una colección de \\(k\\) enteros positivos. En otras palabras la estacionariedad estricta requiere que la distribución conjunta de \\((y_{t_1}, . . . , y_{t_k})\\) sea invariante bajo el cambio de tiempo. Esta es una condición muy fuere que es dificil de verificar empíricamente. A menudo se asume una versión más débil de la estacionariedad. Una serie de tiempo \\(\\{y_t\\}\\) es debilmente estacionaria si tanto la media de \\(y_t\\) como la varianza entre \\(y_t\\) y \\(y_{t-\\ell}\\) son invariantes en el tiempo, donde \\(\\ell\\) es un número entero arbitrario. Más específicamente \\(\\{y_t\\}\\) es débilmente estacionaria si:\n\\[\n\\begin{eqnarray}\nE(y_t) &=& \\mu\\\\[0.2cm]\nCov(y_t, y_{t-\\ell}) &=& \\gamma_t\n\\end{eqnarray}\n\\]\nLa covarianza \\(\\gamma_t\\) se llama autocovarianza lag(rezago)-\\(\\ell\\) de \\(y_t\\). Tiene dos propiedades importantes:\n\n\\(\\gamma_0 = Var(y_t)\\)\n\\(\\gamma_{-\\ell} = \\gamma_t\\)\n\nLa segunda propiedad se mantiene, ya que\n\\[\nCov(y_t, y_{t - (-\\ell)}) = Cov(y_{t-(-\\ell)},y_t) = Cov(y_{t+\\ell},y_t) = Cov(y_{t_1},y_{t_1-1})\n\\]\ndonde \\(t_1 = t + \\ell\\).\nObservación: Supongamos que \\(y_t \\sim N(\\mu_t, \\sigma_t^2)\\), decimos que es estacionario si \\(\\mu_t\\) y \\(\\sigma_t^2\\) son constantes, entonces:\n\nNo estacionaria si \\(\\mu_t\\) está cambiado con el tiempo.\nNo estacionaria si \\(\\sigma_t^2\\) está cambiando con el tiempo.\n\nEn las aplicaciones, la estacionariedad débil le permite a uno hacer inferencias con respecto a observaciones futuras.\n\n\n\nEn estadística se dice que un modelo de regresión presenta heterocedasticidad cuando la varianza de los errores no es constante en todas las observaciones realizadas.\nExisten diferentes razones o situaciones en las que cabe encontrarse con perturbaciones heteroscedásticas. La situación más frecuente es en el análisis de datos de corte transversal, ya que los individuos o empresas o unidades económicas no suelen tener un comportamiento homogéneo.\nOtra situación en la que se presenta hereroscedasticidad es en muestras cuyos datos son valores que se han obtenido agregando o promediando datos individuales.\nCon esto en mente, veamos nuestra segunda seria, la cual presenta las desviaciones anuales de temperatura global. Los datos son desviaciones de la temperatura promedio entre 1960 y 1980. Notará que los datos tienen una tendencia generalmente positiva, pero la tendencia no siempre es positiva. A diferencia de los datos de Johnson y Johnson, esta serie no tiene un componente estacional y es homocedástica\n\nplot(globtemp, main = \"Desviaciones de Temperatura Global\",type = \"o\")\n\n\n\n\nLa tercera serie son los rendimientos semanales del S&P 500. El S&P 500 es un índice bursátil estadounidense basado en 500 grandes corporaciones. Los rendimientos son el cambio porcentual por periodos de tiempo. A diferencia de las otras series, esta no tiene ninguna tendencia o estacionalidad. De hecho, parece que no hay ningún patrón en la serie (excepto que, de vez en cuando, la variación es grande). Este es un ejemplo de un tipo particular de proceso llamado ruido blanco.\n\n\n\nCuando se estiman modelos de series de tiempo, es importante evaluar si los residuos de la estimación correspoonden a un ruido blanco.\nSea \\(\\epsilon_t\\) una sucesión cuyos elementos tiene media cero y varianza \\(\\sigma^2\\)\n\\[\n\\begin{eqnarray}\nE(\\epsilon_t) &=& 0\\hspace{2.5cm} (media\\hspace{0.1cm}cero)\\\\[0.2cm]\nE(\\epsilon_t^2) &=& \\sigma^2 \\hspace{2.3cm} (varianza\\hspace{0.1cm} constante)\\\\[0.2cm]\nE(\\epsilon_t\\epsilon_\\tau) &=& 0\\hspace{0.2cm}para\\hspace{0.1cm} t\\neq \\tau\\hspace{0.4cm}(terminos\\hspace{0.1cm}no\\hspace{0.1cm}correlacionados)\n\\end{eqnarray}\n\\]\nSi los términos están normalmente distribuidos, es decir:\n\\[\n\\epsilon_t \\sim N(0,\\sigma^2)\n\\]\nentonces diremos que \\(\\epsilon_t\\) es ruido blanco gaussiano. Una forma de evaluar si los residuos son ruido blanco es determinar si las autocorrelaciones\n\\[\n\\rho_1 = \\rho_2 = . . . = \\rho_\\tau = 0\n\\]\npara todo \\(\\tau\\geq 1\\).\n\n\n\n\n\n\n¿Es esta serie un caso de ruido blanco?\n\\[\nH_0: \\rho_1 = \\rho_2 = . . . = \\rho_m = 0\\hspace{0.5cm} \\fbox{si es ruido blanco}\n\\]\n\\[\nQ^* = T\\sum_{j = 1}^m \\hat{\\rho}^2\\sim \\chi_{m-k}^2\n\\]\nSi \\(Q^* > \\chi_{m-k}(1-\\alpha)\\), rechazar \\(H_0\\) con \\(100\\alpha\\%\\) de significancia: la serie no es ruido blanco.\nLa intuición es que si la serie no es ruido blanco, algunos \\(\\hat{\\rho}_j\\) serán muy grandes, y entonces \\(Q^*\\) también lo será.\n\n\n\n¿Es esta serie un caso de ruido blanco?\n\\[\nH_0: \\rho_1 = \\rho_2 = . . . = \\rho_m = 0\\hspace{0.5cm} \\fbox{si es ruido blanco}\n\\]\n\\[\nQ = T(T+2)\\sum_{j=1}^m \\frac{\\hat{\\rho}_j^2}{T - j}\\sim \\chi_{m-k}^2\n\\]\nSi \\(Q > \\chi_{m-k}(1-\\alpha)\\), rechazar \\(H_0\\) con \\(100\\alpha\\%\\) de significancia: la serie no es ruido blanco. Este test es similar al de Box-Pierce, peero ajustada para muestras pequeñas.\n\nlibrary(xts)\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\nplot(sp500w, main = \"S&P 500 Rendimientos Semanales\")\n\n\n\n\n\n\n\n\nEn este modelo, influye los rezagos previos (es decir, observaciones pasadas). Consideremos el ruido blanco \\(\\epsilon_t\\). El modelo \\(AR(P)\\) es:\n\\[\ny_t = c + \\phi y_{t-1} + . . . + \\phi_p y_{t-p} + \\epsilon_t\n\\]\nNote que la ecuación previa la podemos escribir como:\n\\[\n\\begin{eqnarray}\ny_t - \\phi_1 y_{t-1} - . . . - \\phi_p y_{t-p} &=& c + \\epsilon_t\\\\[0.2cm]\n\\underbrace{(1 + \\phi_1 L^1 - . . . - \\phi_p L^p)}_{\\Phi(L)} &=& c + \\epsilon_t\n\\end{eqnarray}\n\\]\nEl proceso \\(AR(p)\\) es una ecuación en diferencia de orden \\(p\\). Esta ecuación es estable si y solo si las raíces del polinomio \\(1 - \\phi_1 z^1 - . . . - \\phi_p z^p\\) están todas fuera del círculo unitario.\nSi el proceso es estable, resolvemos para \\(y_t\\),\n\\[\n\\begin{eqnarray}\ny_t &=& \\Phi^{-1}(L)(c+\\epsilon_t)\\\\[0.2cm]\n    &=& \\Phi^{-1}(1)c + \\Phi^{-1}(L)\\epsilon_t\\\\[0.2cm]\n    &=& \\frac{c}{1 - \\phi_1 - . . . - \\phi_p} + \\Phi^{-1}(L)\\epsilon_t\n\\end{eqnarray}\n\\]\nSu valor esperado es:\n\\[E(y_t) = \\frac{c}{1 - \\phi_1 - . . . - \\phi_p}\\]\nPodemos escribir el proceso \\(AR(p)\\) en términos de desviación de la media: \\(\\widetilde{y} = y - \\mu\\)\n\\[\\widetilde{y} = \\phi_1 \\widetilde{y}_{t-1} + . . . + \\phi_p \\widetilde{y}_{t-p} + \\epsilon_{t}\\]\nPara obtener su varianza y autocovarianza multiplicamos la expresion anterior por \\(\\widetilde{y}_{t-j}\\) con \\(j \\geq 0\\), y calculamos el valor esperado\n\\[\n\\begin{eqnarray}\nE[\\widetilde{y}\\widetilde{y}_{t-j}]&=& E[\\phi_1 \\widetilde{y}_{t-1}\\widetilde{y}_{t-j} + . . . + \\phi_p \\widetilde{y}_{t-p}\\widetilde{y}_{t-j} + \\epsilon_{t}\\widetilde{y}_{t-j}]\\\\[0.2cm]\n\\gamma_{j} &=&  \\left\\{\\begin{array}{c}\\phi_{1}\\gamma_{1} + . . . + \\phi_{p}\\gamma_{p} + \\sigma^2, \\hspace{0.5cm}j=0\\\\\\phi_{1}\\gamma_{j-1} + . . . + \\phi_{p}\\gamma_{j-p},\\hspace{0.7cm}j>0\\end{array}\\right.\n\\end{eqnarray}\n\\]\n\n\nLa autocorrelación parcial mide la correlación restante entre \\(y_t\\) y \\(y_{t-1}\\) una vez que se ha eliminado la influencia de \\(y_{t-1}, y_{t-2}, . . . , y_{t-k+1}\\),\n\\[\ny_t = a_1^{(1)}y_{t-1} + a_2^{(2)}y_{t-2} + . . . + a_{k-1}^{(k)}y_{t-k+1} + a_k^{(k)}y_{t-k}\n\\]\nEs decir, las primeras \\(m\\) autocorrelaciones parciales, vienen de\n\\[\n\\begin{eqnarray*}y_{t} &=& a_{(1)}^{1}y_{t-1}:\\hspace{2.9cm} a_{1}^{(1)}\\mbox{ Autocorrelación parcial de un rezago}\\\\[0.1cm]y_{t} &=& a_{1}^{(2)}y_{t-1} + a_{2}^{(2)}y_{t-2}:\\hspace{1cm}a_{2}^{(2)}\\mbox{ Segunda autocorrelación parcial}.\\\\[0.1cm]&\\vdots&\\\\[0.1cm]y_{t} &=& a_{1}^{(m-1)}y_{t-1} + a_{2}^{(m-2)}y_{t-2} + . . . + a_{m-1}^{(m-1)}y_{t-m+1}\\\\[0.1cm]y_{t} &=& a_{1}^{(m)}y_{t-1} + a_{2}^{(m)}y_{t-2} + . . . + a_{m-1}^{(m)}y_{t-m+1} + a_{m}^{(m)}y_{t-m}\\end{eqnarray*}\n\\]\nPara encontrar el valor de \\(a_k^{(k)}\\) basta con resolver:\n\\[\n\\left[\\begin{array}{ccccc}1 & \\rho_{1} & \\rho_{2} & \\cdots & \\rho_{k-1} \\\\\\rho_{1} & 1 & \\rho_{1} & \\cdots & \\rho_{k-2} \\\\\\rho_{2} & \\rho_{1} & 1 & \\cdots & \\rho_{k-3} \\\\\\vdots & \\vdots & \\vdots & \\ddots & \\cdots \\\\\\rho_{k-1} & \\rho_{k-2} & \\rho_{k-3} & \\cdots & 1\\end{array}\\right]\\left[\\begin{array}{c}a_{1}^{(1)} \\\\a_{2}^{(2)} \\\\a_{3}^{(3)} \\\\\\vdots \\\\a_{k}^{(k)}\\end{array}\\right] = \\left[\\begin{array}{c}\\rho_{1} \\\\\\rho_{2} \\\\\\rho_{3} \\\\\\vdots \\\\\\rho_{k}\\end{array}\\right]\n\\]\nDenotaremos la \\(k\\)-ésima correlación parcial \\(\\varphi(k)=a_{k}^{(k)}\\)\nComparando las ecuaciones del proceso \\(AR(p)\\) y de la autocorrelación parcial \\(k\\):\n\\[\n\\begin{eqnarray*}y_{t} &=& \\phi_{1}y_{t-1} + \\phi_{2}y_{t-2} + . . . + \\phi_{p}y_{t-p} + \\epsilon_{t}\\\\[0.2cm]y_{t} &=& a_{1}^{(k)}y_{t-1} + a_{2}^{(k)}y_{t-2}+ . . . + a_{k-1}^{(k)}y_{t-k+1} + a_{k}^{(k)}y_{t-k}\\end{eqnarray*}\n\\]\nVemos que si:\n\nSi \\(k = p\\), entonces \\(\\varphi_{k} = \\phi_{p}\\)\nSi \\(k > p\\), entonces \\(\\varphi_{k}=0\\)\nSi \\(k = 1\\), entonces \\(\\varphi_{1}=\\rho_{1}\\)"
  },
  {
    "objectID": "documentos.html",
    "href": "documentos.html",
    "title": "Cursos",
    "section": "",
    "text": "Bienvenidos a esta sección de mi blog, en este apartado trataré de publicar cada uno de los trabajos asignados a diferentes cursos."
  },
  {
    "objectID": "posts/r/index.html",
    "href": "posts/r/index.html",
    "title": "Introducción a R",
    "section": "",
    "text": "R es un lenguaje y un ambiente para el manejo de datos, cálculos, y gráficos en código libre. Dada estas características los desarrollos que se han realizado en R son abiertos y están disponibles gratuitamente, por lo cual su uso se ha difundido ampliamente. R es difundido libremente por una gran diversidad de sitios espejo del CRAN (The comprehensive R Archive Network: red de servidores en todo el mundo que almacenan versiones id’enticas y actualizadas de código y documentación para R). Además, de ser gratuitos, los desarrollos en R se actualizan más rápido que cualquier otro de los costosos softwares comerciales que se encuentran en el mercado. Esto es así debido a que los usuarios hacen desarrollos, los documentan y los difunden en su red especializada de manera cotidiana (Quintana y Mendoza, 2016,p.23).\nAntes de comenzar a programar es bueno conocer los aspectos básicos del software que se esta utilizando como son: el ambiente, el funcionamiento de las herramientas de ayuda y la sintaxis básica, necesaria para el desarrollo de cualquier proyecto. En la práctica, la programación en R no es dificil solo hace falta acostumbrarse al ambiente y familiarizarse a la sintaxis, la cual trataremos en este material.\n\n\n\nEs software libre y por tanto su costo es nulo. \nEs multiplataforma: existen versiones para LinuX, Mac y Windows. Los procedimientos y análisis desarrollados en una plataforma son perfectamente desarrollables en otra. \nImplementa una enorme cantidad de métodos estadísticos, desde los más clasicos a los más modernos. Los métodos se organizan en librerías cuyo número se encuentra en constante crecimiento.\n\nCapacidad para acceder a datos en múltiples formatos. Dispone de librerías para leer datos desdes SPSS,SAS,Access, MySQL,Excel, etc. A si mismo permite también la generació de informes de resultados en diversos formatos.\n\nEnorme capacidad para manipular y modificar datos y funciones.\n\nGeneración de gráficos de alta calidad.\n\nExistencia de una comunidad de usuarios muy activa, en la que participan estadísticos de renombre.\n\nAmplia disponibilidad de documentación, tanto en internet como en libros publicados por editoriales de prestigio. \nFacilidad de integración con actividad de formación en técnicas y métodos estadísticos en todos los ámbitos del conocimiento.\n\nExistencia de extensiones específicas para nuevas áreas como modelos gráficos o análisis de mercados financieros.\n\nTodos los algoritmos implementados en R pueden ser vistos e interpretados por cualquier usuario, por lo que este puede saber exactamente que es lo que hace el ordenador cuando ejecuta un comando.\n\n\n\n\n\nHay empresas que por políticas no pueden instalar software libre en sus maquinas cada una tiene su politica, sus software de preferencia, sus necesidades, etc.\n\nAlgunas de las instituciones del sector público y privado tienen un dilema. por parte necesitan ahorrar recursos y por otra parte tienen que contar con soporte técnico por el que pagan fortunas. La idea del soporte es tener el apoyo y mantenimiento por si algo sale mal tanto en la aplicación del software como en la administración de los sistemas. Por eso pagan licencias costosas por SAS, STATA y otros paquetes.\n\nUna de las principales desventajas es que hasta hace poco el uso de R estaba limitado a entornos universitarios y de usuarios con gran conocimiento de la estadística y la programación. Junto a esto, su primera impresión entre los usuarios principiantes, es de dureza y poca amigabilidad, aunque esto queda superado con el uso.\n\nNo hay nadie a quien reclamar si algo falla, ni hay un departamento de atención al cliente que nos diga qué podemos hacer si algo va mal, si alguién procedimiento nos da un error, o simplemente si no sabemos qué sintaxis utilizar. Pero a cambio existe una comunidad de usuarios organizada en foros y dispuesta a colaborar desinteresadamente en la resolución de problemas.\n\nA todos los puntos anteriores podemos añadir el siguiente, que será considerado por unos una ventaja y por otros un inconveniente: Para hacer un buen uso de R hay que tener un buen conocimiento de los métodos estadísticos. En realidad esta afirmación es cierta no sólo para R, sino para cualquier paquete estadístico.\n\n\n\n\nPara realizar la instalación de R y RStudio en Windows,Mac, Ubuntu o Linux se debe ingresar a los siguientes sitios web:\n\nInstalación de R\nInstalación de RStudio\n\n\n\n\nRPermite obtener ayuda para conocer toda la información (qué hace, cuál es la sintaxis correcta, qué parámetros tiene, algunos ejemplos de uso, etcétera) sobre una función, objeto o librería.\nExisten cinco funciones para obtener ayuda las cuales son:\n\nhelt.start()\n\n\nUtilizando esta función se encuentra un menú de recursos, entre los cuales existen manuales, referencias y demás material para comenzar a aprender R.\n\nescribe en tu consola de RStudio help.start()\n\nhelp(¨nombre del objeto¨)\n\n\nEsta función facilita obtener información acerca de las funciones de los paquetes ya instalados en R. Si se desea obtener información acerca de una función, por ejemplo de la función plot(), se debe escribir help(“plot”) o ?plot en la línea de comandos.\n\nexample(\"nombre de la función\")\n\n\nPara obtener ejemplos del uso de funciones, se utiliza la función example (). Porejemplo, escribeexample(“array”).\n\nexample(\"array\")\n\n\narray> dim(as.array(letters))\n[1] 26\n\narray> array(1:3, c(2,4)) # recycle 1:3 \"2 2/3 times\"\n     [,1] [,2] [,3] [,4]\n[1,]    1    3    2    1\n[2,]    2    1    3    2\n\narray> #     [,1] [,2] [,3] [,4]\narray> #[1,]    1    3    2    1\narray> #[2,]    2    1    3    2\narray> \narray> \narray> \n\n\n\nlibrary(help = \"nombre\")\n\n\nOtra manera de obtener información de ayuda sobre un paquete es usar la opción help para el comando library(), con lo cual tendrás información más completa. Un ejemplo es library(help=“stats”).\n\nlibrary(help=\"stats\")\n\n\nvignette(“nombre de la librer ́ıa”)\n\n\nAlgunos paquetes ya instalados en R incluyen viñetas dentro del ordenador. Una viñeta es un documento corto que describe como se usa un paquete. Se puede ver una viñeta usando la función vignette(). Escribe vignette(“Sweave”) en la línea de comandos.\n\nvignette(\"Sweave\")\n\n\n\n\nLa forma correcta de almacenar valores, es a través de una asignación la cual se realiza especificando el símbolo <-. Del lado izquierdo del símbolo se especifica el nombre de la variable y del lado derecho se introduce el valor u operación.\n\nSe puede trabajar con una gran cantidad de operadores matemáticos que utiliza R y que permite realizar cálculos matemáticos, por mencionar algunos, se pueden observar en el siguiente cuadro\n\n\n\nOperador Matemático\nFunción en R\n\n\n\n\n\\(\\sqrt{x}\\)\nsqrt()\n\n\n\\(e^x\\)\nexp(x)\n\n\n\\(x!\\)\nfactorial(x)\n\n\n\\(logaritmo(x)\\)\nlog(x)\n\n\n\\(\\pi\\)\nPi\n\n\n\\(|x|\\)\nabs(x)\n\n\n\\(seno(x)\\)\nsin(x)\n\n\n\\(coseno(x)\\)\ncos(x)\n\n\n\\(tangente(x)\\)\ntan(x)\n\n\n\\(cos^{-1}(x)\\)\nacos(x)\n\n\n\\(sen^{-1}(x)\\)\nasin(x)\n\n\n\\(tan^{-1}(x)\\)\natan(x)\n\n\n\nAsignar un valor a cierta cantidad de variables por ejemplo: a una variable \\(w\\) el valor 3, a la variable \\(y\\) el valor 7 y a la variable \\(z\\) el valor 90, a una variable \\(suma\\) la adición de las variables anteriores y finalmente obtendremos la raíz cuadrada de la variable \\(suma\\) guardándola en una variable con el nombre raíz.\nA continuació le muestro el ejemplo en R\n\nw <- 3   # Para evaluar la instrucción se debe presionar la tecla Control + ENTER.\nw        # Para observar el valor de la variable nombra la variable.\n\n[1] 3\n\ny <- 7\ny\n\n[1] 7\n\nz <- 90 \nz\n\n[1] 90\n\nsuma <- w + y + z\nsuma\n\n[1] 100\n\nraiz <- sqrt(suma)\nraiz\n\n[1] 10\n\n\nEn la primera línea se observa el simbolo (#), el cual permite comentar el código, para tomar notas de interés.\nEn R tamién se puede almacenar cadenas de caracteres como se muestra en el siguiente ejemplo:\n\na <- \"Cálculo\"\na\n\n[1] \"Cálculo\"\n\nb <- \"Microeconomía\"\nb\n\n[1] \"Microeconomía\"\n\n\nPara obtener un listado o desplegado de las variables que han sido definidas en la sesio ́n se debe de escribir el comando ls().\n\nls()\n\n[1] \"a\"    \"b\"    \"raiz\" \"suma\" \"w\"    \"y\"    \"z\"   \n\n\n\n\n\nUn vector es una secuencia ordenada de datos, los cuales han de ser del mismo tipo, es decir, todos deben de ser números, caracteres, cadenas de caracteres, valores lógicos, etc. Los tipos de datos que se pueden almacenar en un vector se destacan los siguientes:\n\nlogical (lógicos: TRUE, verdadero, o FALSE, falso)\ninteger (números enteros)\nnumeric (números reales)\ncharacter (palabras)\n\n\n\nLa forma correcta de almacenar un conjunto de datos, es a través de una asignación utilizando el comando c, donde dicha lista de números se almacenan bajo nombre, y así mismo este se utiliza para referirse a los datos que almacena, la asignación se realiza especificando el símbolo <-.\n\nPara generar un vector utilizamos la función c separado cada uno de los elementos por medio de una coma (,) por ejemplo si se quisiera almacenar la secuencia \\(0,1,2,3,4,5,6,7,8,9\\) dentro de un vector llamado \\(vector\\)\n\nvector <- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\nvector\n\n [1] 0 1 2 3 4 5 6 7 8 9\n\n\nSi se desea crear un vector de letras, palabras o cadenas de caracteres llamadas string, se tiene que nombrar cada cadena de caracteres entre comillas de manera obligatoria\n\nvectorletra <- c(\"a\", \"b\", \"c\", \"d\", \"e\")\nvectorletra\n\n[1] \"a\" \"b\" \"c\" \"d\" \"e\"\n\nvectorpalabra <- c(\"Micro\", \"Economía\", \"en\", \"R\")\nvectorpalabra\n\n[1] \"Micro\"    \"Economía\" \"en\"       \"R\"       \n\n\nSe puede facilitar la creación de vectores podemos utilizar c(a:b) para datos de manera consecutiva, el comando seq(a, b, by = p) de manera aritmética, donde \\(a\\) es el primer elemento, \\(b\\) es el último elemento y \\(p\\) es la diferencia de cada elemento.\n\nw <- c(0:10)\nw\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\ny <- seq(0, 100, by = 10)\ny\n\n [1]   0  10  20  30  40  50  60  70  80  90 100\n\n\n\n\n\nSe pueden realizar operaciones como suma, resta, producto de vectores, se utilizaran los vectores \\(w\\) e \\(y\\) para ejemplificar las operaciones.\n\nsuma <- w + y\nsuma \n\n [1]   0  11  22  33  44  55  66  77  88  99 110\n\nresta <- w - y\nresta\n\n [1]   0  -9 -18 -27 -36 -45 -54 -63 -72 -81 -90\n\nproducto <- w*y\nproducto\n\n [1]    0   10   40   90  160  250  360  490  640  810 1000\n\n\nEl manejo de vectores en R tiene una propiedad muy útil: podemos aplicar una función a todos los elementos de un vector en un solo paso.\n\nw + 5\n\n [1]  5  6  7  8  9 10 11 12 13 14 15\n\nw - 2\n\n [1] -2 -1  0  1  2  3  4  5  6  7  8\n\n10*w\n\n [1]   0  10  20  30  40  50  60  70  80  90 100\n\nsqrt(w)\n\n [1] 0.000000 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751\n [9] 2.828427 3.000000 3.162278\n\nw^2\n\n [1]   0   1   4   9  16  25  36  49  64  81 100\n\n\nEntre otras funciones para aplicar a vectores, y de gran importancia son las relacionadas principalmente con la estadística. Por ejemplo\n\nmax y min calculan sus valores maximos y minimos respectivamente\nsum calcula la suma\nprod calcula el producto\nmean calcula la media\ndiff calcula el vector formado por las diferencias sucesivas entre entradas del vector original.\nsort ordena los elementos del vector en el orden natural creciente del tipo de datos que lo forman, se puede incluir en su argumento el parámetro decreasing = TRUE.\n\n\nw\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nmax(w)\n\n[1] 10\n\nmin(w)\n\n[1] 0\n\nsum(w)\n\n[1] 55\n\nprod(w)\n\n[1] 0\n\nmean(w)\n\n[1] 5\n\ndiff(w)\n\n [1] 1 1 1 1 1 1 1 1 1 1\n\nsort(w)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nsort(w, decreasing = TRUE)\n\n [1] 10  9  8  7  6  5  4  3  2  1  0\n\n\n\n\n\n\nLas matrices son un tipo de vector particular, es un vector con un atributo especial, llamado dimensión. La dimensión establece el número de renglones y el número de columnas que tendrá una matriz, se debe recordar que una matriz no es más que un arreglo de números en \\(m\\) renglones y \\(n\\) columnas.\nPor ejemplo una matriz de 3 renglones y 3 columnas\n\\[\\left[\\begin{array}{ccc}1 & 2 & 3 \\\\2 & 4 & 5 \\\\3 & 5 & 6\\end{array}\\right]\\] Se dispone de dos maneras básicas de definir una matriz en R. En primer lugar, la instrucción:\n\\[matrix(vector,nrow = n, byrow = valorlogico)\\]\nDefine una matriz de \\(n\\) filas (rows) formada por las entradas del vector. Si se captura byrow = TRUE, la matriz se construye por filas, mientras que con byrow = FALSE se construye por columnas; este último es el valor por defecto, por lo que no hace falta especificarlo. En vez de emplear nrow, se puede indicar el número de columnas con ncol. Veamos algunos ejemplos:\n\nmatrix(1:6,nrow = 2)\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\nmatrix(1:6, nrow = 3)\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\nmatrix(1:6, nrow = 2, byrow = TRUE)\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n\nmatrix(1:6, nrow = 3, byrow = TRUE)\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n[3,]    5    6\n\n\nObserve cómo muestra R las matrices: indica las filas con \\([i,]\\), donde \\(i\\) es el índice de la fila, y las columnas con \\([,j]\\), donde \\(j\\) es el índice de la columna. Otra posible manera de definir matrices es combinando filas o columnas. La instrucción:\n\\[rbind(vector1,vector2, vector3)\\] construya la matriz de filas \\(vector1, vector2, . . . , vector N\\) que han de tener la misma longitud en este orden. Si en lugar de rbind se usa cbind, se obtiene la matriz cuyas columnas son los vectores a los que se aplica.\n\nrbind(c(1, 0, 2), c(2, 3, 6), c(1, 2, 0))\n\n     [,1] [,2] [,3]\n[1,]    1    0    2\n[2,]    2    3    6\n[3,]    1    2    0\n\ncbind(c(1, 0, 2), c(2, 3, 6), c(1, 2, 0))\n\n     [,1] [,2] [,3]\n[1,]    1    2    1\n[2,]    0    3    2\n[3,]    2    6    0\n\n\n\n\n\nLa manera más conveniente de guardar una tabla de datos en R es en forma de \\(dataframe\\). En concreto, un \\(data\\) \\(frame\\) es una tabla de doble entrada, formada por variables en las columnas y observaciones de estas variables en las filas, de manera que cada fila contiene los valores de las variables para un mismo caso o individuo. En ese sentido, un \\(data\\) \\(frame\\) tiene la apariencia de una matriz, pero con la diferencia de que cada columna de un \\(data\\) \\(frame\\) puede contener datos de un tipo diferente siempre que todos los datos de una misma columna sean del mismo tipo porque corresponden a observaciones de una misma propiedad: así, una columna puede estar formada por números, por palabras, por valores lógicos, etcétera. De esta manera, las columnas de un data frame son vectores, mientras que las filas son listas.\n\n\nPara construir un \\(data\\) \\(frame\\) a partir de unos vectores, se usa la función data.frame aplicada a los vectores en el orden en el que queramos disponer las columnas de la tabla; de esta manera, las variables tomarán los nombres de los vectores. Estos nombres también se pueden especificar en el argumento de la función data.frame, entrando cada columna con una construcción de la forma:\n\\[Nombre~variable = vector~con~el~contenido~de~la~variable\\]\nPara ilustrar esta función usemos un ejemplo sencillo:\n\nUna compañía de seguros desea crear una base de datos para la gestión de las pólizas de sus asegurados. Para ello, los datos de los que dispone son los siguientes:\n\nDe cada póliza se guarda el número de póliza.\nEl tipo que puede ser “Hogar” o “Auto”.\nLa fecha de creación de la póliza.\ny el conjunto de coberturas incluidas en la póliza ( a elegir entre Incendio, Robo, Terceros y Responsabilidad Civil).\nPara cada póliza guardamos los atos de sus titulares, y sabemos que cada poliza tiene un único titular.\nDe los titulares guardamos nombre, sexo, edad y estado de providencia.\n\n\nPoliza <- c(1:9)\n\nTipo <- c(\"Hogar\", \"Auto\", \"Auto\", \"Auto\", \"Hogar\", \"Hogar\", \"Auto\",\n           \"Auto\", \"Hogar\")\n\nFecha <- c(\"12/12/2016\", \"08/02/2014\", \"10/08/2012\", \"01/01/2015\",\n           \"21/11/2011\", \"18/01/2016\", \"12/04/2005\", \"29/03/2007\",\n           \"18/02/2009\")\n\nCoberturas <- c(\"Incendio\", \"Robo\", \"Terceros\", \"Robo\", \"Robo\",\n                \"Incendio\", \"Terceros\", \"R. Civil\", \"Incendio\")\n\nNombre <- c(\"Carlos\", \"Nancy\", \"Pedro\", \"Cecilia\", \"Ricardo\", \"Sofia\",\n            \"Armando\", \"Vicente\", \"Fernando\")\n\nSexo <- c(\"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"M\", \"M\")\n\nEdad <- c(25, 35, 45, 47, 24, 43, 33, 31, 40)\n\nEstado <- c(\"Campeche\", \"Chiapas\", \"Ciudad de M ́exico\", \"Coahuila\",\n            \"Durango\", \"Guanajuato\", \"Guerrero\", \"Hidalgo\", \"Jalisco\")\n\ndataframe= data.frame(Poliza, Tipo, Fecha, Coberturas, Nombre, Sexo, Edad)\n\ndataframe\n\n  Poliza  Tipo      Fecha Coberturas   Nombre Sexo Edad\n1      1 Hogar 12/12/2016   Incendio   Carlos    M   25\n2      2  Auto 08/02/2014       Robo    Nancy    F   35\n3      3  Auto 10/08/2012   Terceros    Pedro    M   45\n4      4  Auto 01/01/2015       Robo  Cecilia    F   47\n5      5 Hogar 21/11/2011       Robo  Ricardo    M   24\n6      6 Hogar 18/01/2016   Incendio    Sofia    F   43\n7      7  Auto 12/04/2005   Terceros  Armando    M   33\n8      8  Auto 29/03/2007   R. Civil  Vicente    M   31\n9      9 Hogar 18/02/2009   Incendio Fernando    M   40\n\n\n\n\n\n\nR es un lenguaje que permite la implementación de paquetes adicionales que le dan una capacidad de gestión de datos más amplia y permiten la implementación de nuevas funciones que harán de R un programa que se adapte a las necesidades.\n\nEl procedimiento para instalar un paquete depende del sistema operativo usado y de la manera como se instalo R: ya sea desde el código fuente o desde o por medio de archivos binarios pre-compilados. Existen varias funciones para manejar paquetes tales como:\n\ninstalled.packages()\nCRAN.package()\ndownload.packages()\n\nPara verificar la versión de paquetes ya instalados en el sistema y actualizarlos a la versión más reciente utilizamos la siguiente función:\n\nupdate.packages()"
  },
  {
    "objectID": "documentos.html#repaso-sobre-matematicas-de-la-optimización",
    "href": "documentos.html#repaso-sobre-matematicas-de-la-optimización",
    "title": "Cursos",
    "section": "Repaso sobre Matematicas de la Optimización",
    "text": "Repaso sobre Matematicas de la Optimización\nEl objetivo de este repaso se centra en fundamentar las bases para la temática que conlleva el curso de microeconomia intermedia. Trataremos de recordar algunos conceptos importantes sobre matemáticas de la optimización .\n\nPara conocer el contendio del repaso ingresa al siguiente link Matemáticas de la Optimización\nEjercicios de repaso sobre derivadas\nFuncion de utilidad indirecta y función del gasto"
  },
  {
    "objectID": "posts/actuarial/index.html",
    "href": "posts/actuarial/index.html",
    "title": "Tópicos Actuariales con R",
    "section": "",
    "text": "Si te dedicas a trabajar en el ambito de Ciencias Actuariales o Matemáticas Financiera, en este post, te comparto una de las librerias que fue publicada recientemente por Giorgio Alfredo Spedicato, la cual te ayudará mucho si quieres introducir tus computos o estimaciones al ecosistema de R y RStudio. Su autor se otorgo el nombre de lifecontingencies. A continuación conozcamos un poco de ella."
  },
  {
    "objectID": "posts/actuarial/index.html#tipos-de-anualidades",
    "href": "posts/actuarial/index.html#tipos-de-anualidades",
    "title": "Tópicos Actuariales con R",
    "section": "Tipos de Anualidades",
    "text": "Tipos de Anualidades\nLos factores que intervienen en las anualidades y su forma de pago hacen que se puedan clasificar de diferente forma, sin embargo, eso no significa que sean mutuamente excluyentes. Las anualidades se pueden clasificar bajo cuatro criterios importantes; tiempo, intereses, pago o iniciación.\n\nAnualidades Vencidas\nUna anualidad vencida es una serie de pagos iguales realizados al final de cada periodo de pago, un ejemplo de ellas es cuando hacemos el pago mensual de alguna tarjeta de crédito o el pago mensual de una cuenta de ahorro.\n\nValor Presente de una anualidad Vencida\nA continuación se muestra la fórmula para el cálculo del valor presente de una anualidad vencida.\nSe supone una anualidad vencidad donde \\(R\\) es el pago de la anualidad al final de cada periodo de pago en un plazo de \\(n\\) periodos.\n\nla fecha focal se localiza en el momento actual, y la letra \\(A\\) representa el valor actual de la anualidad. La expresión es la siguiente:\n\\[A = R(1+i)^{-1} + R(1+i)^{-2} + . . . + R(1+i)^{-(n-2)} + R(1+i)^{-(n-1)} + R(1+i)^{-n}\\]\nhaciendo \\((1+i)^{-1} = v\\)\n\\[\n\\begin{eqnarray}\nA &=& Rv + Rv^2 + . . . + R^{n-2} + Rv^{n-1} + Rv^n\\\\[0.2cm]\nA &=& R(v + v^2 + . . . + v^{n-2} + v^{n-1} + v^n)\n\\end{eqnarray}\n\\]\nClaramente es una suma de progresión geométrica decreciente, entonces\n\\[\nA = R\\frac{v(1-v^n)}{1-v}\n\\]\nEl denominador es igual a:\n\\[\n1 - v = 1 - \\frac{1}{1+i} = \\frac{1+i-1}{1+i} = i\\frac{1}{1+i} = iv\n\\]\npor tanto,\n\\[\nA = R\\frac{1-(1+i)^{-n}}{i}\n\\]"
  },
  {
    "objectID": "posts/Top_actuariales/index.html",
    "href": "posts/Top_actuariales/index.html",
    "title": "Tópicos Actuariales con R",
    "section": "",
    "text": "Si te dedicas a trabajar en el ambito de Ciencias Actuariales o Matemáticas Financiera, en este post, te comparto una de las librerias que fue publicada recientemente por Giorgio Alfredo Spedicato, la cual te ayudará mucho si quieres introducir tus computos o estimaciones al ecosistema de R y RStudio. Su autor se otorgo el nombre de lifecontingencies. A continuación conozcamos un poco de ella."
  },
  {
    "objectID": "posts/Top_actuariales/index.html#tipos-de-anualidades",
    "href": "posts/Top_actuariales/index.html#tipos-de-anualidades",
    "title": "Tópicos Actuariales con R",
    "section": "Tipos de Anualidades",
    "text": "Tipos de Anualidades\nLos factores que intervienen en las anualidades y su forma de pago hacen que se puedan clasificar de diferente forma, sin embargo, eso no significa que sean mutuamente excluyentes. Las anualidades se pueden clasificar bajo cuatro criterios importantes; tiempo, intereses, pago o iniciación.\n\nAnualidades Vencidas\nUna anualidad vencida es una serie de pagos iguales realizados al final de cada periodo de pago, un ejemplo de ellas es cuando hacemos el pago mensual de alguna tarjeta de crédito o el pago mensual de una cuenta de ahorro.\n\nValor Presente de una anualidad Vencida\nA continuación se muestra la fórmula para el cálculo del valor presente de una anualidad vencida.\nSe supone una anualidad vencidad donde \\(R\\) es el pago de la anualidad al final de cada periodo de pago en un plazo de \\(n\\) periodos.\n\nla fecha focal se localiza en el momento actual, y la letra \\(A\\) representa el valor actual de la anualidad. La expresión es la siguiente:\n\\[A = R(1+i)^{-1} + R(1+i)^{-2} + . . . + R(1+i)^{-(n-2)} + R(1+i)^{-(n-1)} + R(1+i)^{-n}\\]\nhaciendo \\((1+i)^{-1} = v\\)\n\\[\n\\begin{eqnarray}\nA &=& Rv + Rv^2 + . . . + R^{n-2} + Rv^{n-1} + Rv^n\\\\[0.2cm]\nA &=& R(v + v^2 + . . . + v^{n-2} + v^{n-1} + v^n)\n\\end{eqnarray}\n\\]\nClaramente es una suma de progresión geométrica decreciente, entonces\n\\[\nA = R\\frac{v(1-v^n)}{1-v}\n\\]\nEl denominador es igual a:\n\\[\n1 - v = 1 - \\frac{1}{1+i} = \\frac{1+i-1}{1+i} = i\\frac{1}{1+i} = iv\n\\]\npor tanto,\n\\[\nA = R\\frac{1-(1+i)^{-n}}{i}\n\\]"
  },
  {
    "objectID": "posts/top_act/index.html",
    "href": "posts/top_act/index.html",
    "title": "Tópicos Actuariales con R",
    "section": "",
    "text": "Si te dedicas a trabajar en el ambito de Ciencias Actuariales o Matemáticas Financiera, en este post, te comparto una de las librerias que fue publicada recientemente por Giorgio Alfredo Spedicato, la cual te ayudará mucho si quieres introducir tus computos o estimaciones al ecosistema de R y RStudio. Su autor se otorgo el nombre de lifecontingencies. A continuación conozcamos un poco de ella.\n\nLibrería lifecontingencies\nEn la actualidad el conocimiento sobre el uso de R, es muy demandado en los profesionales que requieren las empresas, siendo este un software libre especializado en estadística, con gran capacidad gracias al uso de complementos adicionalesm llamadas librerías, que al ser instaladas potencian las capacidades para desarrollar procedimientos especializados y que hacen de R Project un potente programa para el uso de diferentes ramas de la ciencia actuarial.\nComo ya he mencionado es esencial la descarga de librerías que incrementan las funciones de R, en el caso de Cálculo Actuarial, la librería utilizada se llama lifecontingencies(Spedicato 2013).\nGracias a lo investigado por Giorgio Spedicato creador de la librería lifecontingencies y presentado en el paper “The lifecontingencies Package: Performing financial and Actuarial Mathematics Calculations in R” (Spedicato, 2013, p.1-2), encontramos lo siguiente.\nEl entorno de programación estadística en R se ha convertido en el principal software de referencia para académicos, incluso en los negocios, R ahora se considera una alternativa válida a los paquetes estadísticos comerciales más importantes como por ejemplo:\n\nSAS (SAS Institute Inc., 2011)\nMATLA (The MathWorks, Inc., 2011)\nSPSS (IBM Corp, 2012)\n\nAlgunos paquetes para aplicaciones actuariales se han desarrollado dentro de R. Sin embargo, la mayoría de ellos se centran principalmente en seguros de no vida, los principales son:\n\nactuar (Dutang, Goulet, y Pigeon, 2008): este paquete representa el lado computacional de la metodología actuarial clásica sobre la distribución de pérdidas.\nChainLadder (Gesmann y Zhang, 2011): proporciona funciones que son capaces de estimar reservas de pérdidas para el seguro de no vida y de modelos lineales generalizados (GLM), ampliamente utilizados en las decisiones para la tasa del seguro, por funciones agrupadas dentro de la base de distribuciones de R.\n\nEl trabajo actuarial sobre seguros de vida se ocupa principalmente de datos demográficos y financieros.\nEl CRAN enumera varios paquetes especializados para el análisis financiero entre los que encontramos YielCurve (Guirreri, 2010) y termstrc (Ferstl y Hayden, 2010) los cuales son capaces de realizar modelos financieros con tasas de interés. Entre los pocos paquetes que manejan datos demográficos, estan demografy (Hyndman, Booth, Ticke y Maindonald, 2011) y LifeTables (Riffe, 2011) pueden utilizarse para gestionar las proyecciones demográficas.\nPor otra parte, muchos paquetes de software comerciales adaptados especificamente para el análisis de los seguros de vida ya están disponibles son: MoSes (Tower Watson,2011) y Prophet (SunGard, 2012) son actualmente los principales paquetes de software actuarial para el modelado de los seguros de vida.\nEl paquete lifecontingencies aparece como el primer paquete de R, para realizar cálculos de matemáticas contingentes de vida. Apunta a representar al compañero computacional para resoler conceptos teóricos expuestos en libros de texto como el clásico Bowser (Bowers, Jones, Gerber, Nesbitt, y Hickman, 1997), para la evaluación de matemáticas actuariales y Broverman (Broverman, 2008) para las matemáticas financieras.\nEl uso de la librería lifecontingencies en este post, se utilizara para temas planteados con contingencias relacionadas a una sola persona, sin embargo, el lector ya con una idea más clara y con conocimientos sobre esta librería, podrá abordar las funciones para resolver problemas de contingencias para el caso de N personas los cuales posiblemente la oborde en otro post sobre Calculo Actuarial Avanzado.\nNota: En todo problema que realizaremos es muy importante que realices tus propios calculos para que compruebes cómo se llegó al resultado.\n\n\nAnualidades\nLas anualidades representan el grupo más importante de aplicaciones de las matemáticas financieras, ya que la gran mayoría de las operaciones de crédito, tanto comerciales como puramente financieras, se pactan estableciendo una serie de pagos periódicos que habrán de realizarse durante su vigencia.\nUna anualidad es una serie de pagos iguales realizados en intervalos de tiempo regualares durante un tiempo determinado. El término de anualidad no se refiere específicamente a periodos anuales. En matemáticas financieras el término anualidad tiene un significado mucho más general. Los pagos podrían ser semanales, quincenales, mensuales, trimestrales, semestrales, etcétera.\nTrataremos de simular algunos tipos de anualidades en R.\n\nAnualidades Vencidas\nUna anualidad vencida es una serie de pagos iguales realizados al final de cada periodo de pago, un ejemplo de ellas es cuando hacemos el pago mensual de alguna tarjeta de crédito o el pago mensual de una cuenta de ahorro.\nA continuación se muestra el diagrama de tiempo de dichas anualidades.\n\nEl número cero representa el momento actual o el tiempo presente. El número uno representa el final del primer periodo y coincide con el inicio del segundo periodo. La letra \\(R\\) representa la anualidad y los intereses que pagan son intereses compuestos por lo tanto son capitalizable.\n\nValor presente de una anualidad vencida\nSe supone una anualidad vencida donde \\(R\\) es el pago de la anualidad al final de cada periodo de pago en un plazo de \\(n\\) periodos\n\nLa fecha focal se localiza en el momento actual, y la letra \\(A\\) representa el valor actual de la anualidad. La expresión es la siguiente\n\\[\nA = R(1+i)^{-1} + R(1+i)^{-2} + . . . + R(1+i)^{-(n-2)} + R(1+i)^{-(n-1)} + R(1+i)^{-n}\\hspace{1cm} (1)\n\\]\nhaciendo \\((1+i)^{-1} = v\\) entonces podemos escribir (1) de la siguiente manera\n\\[\n\\begin{eqnarray}\nA &=& Rv + Rv^2 + . . . + Rv^{n-2} + Rv^{n-1} + Rv^n\\\\[0.2cm]\n  &=& R(v + v^2 + . . . + v^{n-2} + v^{n-1} + Rv^n)\\hspace{1cm} (2)\n\\end{eqnarray}\n\\]\nClaramente (2) representa una suma de progresión geométrica decreciente.\n\\[\nA = R\\frac{v(1-v^n)}{1-v}\n\\]\ndonde el denominador es iguala a:\n\\[\n\\begin{eqnarray}\n1 - v = 1 - \\frac{1}{1+i} &=& \\frac{1+i-1}{1+i} = i\\frac{1}{1+i} = iv\\\\[0.2cm]\n                        A &=& R\\frac{v(1-v^n)}{iv}\\\\[0.2cm]\n                        A &=& R\\frac{1 - (1+i)^{-n}}{i}\n\\end{eqnarray}\n\\]\n\n\nValor futuro de una anualidad vencida\nEl valor futuro de una anualidad es cuando la fecha se localiza al final de último periodo y es la suma de los pagos periódicos junto con su interés compuesto acumulado.\nSe supone una anualidad vencidad donde \\(A\\) es el pago de la anualidad al final de cada periodo de pago en un plazo de \\(n\\) periodos. La letra \\(i\\) representa la tasa de interés compuesta por periodo.\n\nLa fecha focal coincide con el final del último periodo. La expresión es la siguiente:\n\\[\nS = R(1+i)^{n-1} + R(1 + i)^{n-2} + . . . + R(1+i)^{2} + R(1+i)^{1} + R\n\\]\nhaciendo \\((1+i) = r\\), podemos escribir la ecuación anterior de la siguiente manera:\n\\[\nS = R(r^{n-1} + r^{n-2} + . . . + r^2 + r + 1)\n\\]\nentonces\n\\[\n\\begin{eqnarray}\nS = R\\frac{r^n - 1}{r - 1} &=& R\\frac{(1+i)^n - 1}{1 + i -1}\\\\[0.2cm]\n                         S &=& R\\frac{(1+i)^n-1}{i}\n\\end{eqnarray}\n\\]\n\n\n\nAnualidades anticipadas\nEn las anualidades anticipadas se hacen los pagos al inicio de cada periodo. Una anualidad anticipada es una serie de pagos iguales realizados al inicio del periodo de pago.\n\n\n\nDiagrama de flujo de dichas anualidades\n\n\nEl tiempo cero representa el tiempo presente y coincide con el primer pago de la anualidad. El número uno representa el final del primer periodo y coincide con el deposito del segundo periodo y así sucesivamente.\n\nValor Presente de una anualidad anticipada\nEs la cantidad de dinero en el tiempo presente que tenemos que invertir para hacer cierto número de retiros esperados en el futuro.\nPara desarrollar la fórmula del valor presente de una anualidad anticipada se expone el siguiente diagrama:\n\nSi la fecha focal se localiza al inicio del primer periodo de pago, entonces:\n\\[\n\\ddot{A} = R\\frac{1 - (1+i)^{-(n-1)}}{i} + R\n\\]\n\n\nValor futuro de una anualidad anticipada\nPara deducir la fórmula del valor futuro de una anualidad anticipada, se expone el siguiente diagrama de tiempo\n\nEl monto final del valor futuro de la anualidad anticipada se expresa de la siguiente manera:\n\\[\n\\ddot{S} = R\\frac{(1+i)^n - 1}{i}\\cdot (1+i)\n\\]\n\nFunción annuity\nEn R la función annuity calcula el valor presente de una anualidad.\n\nannuity(i, n, m = 0, k = 1, type = \"inmediate\")\n\ndonde los parámetros:\n\ni interés efectivos expresado en forma decimal.\nn Períodos de pago. Si \\(n\\) es infinito entonces la anualidad devuelve el valor de una perpetuidad.\nm Periodo de diferimiento, cuyo valor predeterminado es cero.\nk Frecuencia anual de pagos\ntype Una cadena, ya sea, “immediate” o “due”. Si los pagos se realizan al final de cada período de \\(n\\) períodos, tene,mos una “annuity-immediate”. De lo contrario , si los pagos se realizan al comienzo de cada período, tenemos una “annuity-due”.\n\n\n\nFunción accumulatedValue\nEn R la función accumulatedValue calcule el valor futuro de una anualidad.\n\naccumulatedValue(i, n, m = 0, k, type = \"immediate\")\n\ndonde,\n\ni Interées efectivo expresado en forma decimal.\nn Períodos de pago. Si \\(n\\) es infinito entonces la anualidad devuelve el valor de una perpetuidad.\nm Periodo de diferimiento, cuyo valor predeterminado es cero.\nk Frecuencia anual de pagos\ntype Una cadena, ya sea, “inmediate” o “due”. Si los pagos se realizan al final de cada período de \\(n\\) períodos tenemos una “annuity-immediate”. De lo contrario, si los pagos se realizan al comienzo de cada periodo, tenemos una “annuity-due”.\n\n\n\n\n\nEjemplos\nCalcular el valor presente de cuatro pagos anuales de \\(\\$500.00\\), el primero de ellos se efectua un año después de este momento y la tasa es del \\(8\\%\\) anual efectiva.\n\\[\n\\mbox{Solución}\n\\]\nMétodo manual:\n\\[\n\\begin{eqnarray}\nA &=& R\\frac{1 - (1+i)^{-n}}{i}\\\\[0.2cm]\n  &=& 500\\frac{1 - (1+0.08)^{-4}}{0.08}\\\\[0.2cm]\n  &=& \\fbox{1656.063}\n\\end{eqnarray}\n\\]\nUsando R\n\nlibrary(lifecontingencies)\n\nA <- 500*annuity(i = 0.08, n = 4, type = \"immediate\")\nA\n\n[1] 1656.063\n\n\nCalcular el valor presente de una anualidad de una cantidad de \\(\\$100\\) pagaderos al año durante 5 años a una tasa de interés del 9%.\n\\[\n\\mbox{Solución}\n\\]\n\\[\n\\begin{eqnarray}\nA &=& R\\frac{1 - (1+i)^{-n}}{i}\\\\[0.2cm]\n  &=& 100\\frac{1 - (1+0.09)^{-5}}{0.09}\\\\[0.2cm]\n  &=& \\fbox{388.9651}\n\\end{eqnarray}\n\\]\nahora, resolvamos con R\n\nA <- 100*annuity(i = 0.09, n = 5, type = \"immediate\")\nA\n\n[1] 388.9651\n\n\n¿Qué cantidad debe invertir hoy en la tasa de interés del 15% anual compuesto de manera que e desea retirar 8000 al comienzo de cada año, durante los proximos 5 años?\n\\[\n\\mbox{Solución}\n\\]\n\\[\nA = 8000\\frac{1 - (1+0.15)^{-4}}{0.15} + 8000 = \\fbox{30839.83}\n\\]\nahora usando R obtenemos:\n\n8000*annuity(i = 0.15, n = 5, type = \"due\")\n\n[1] 30839.83\n\n\n¿Qué cantidad se acumulara si depositamos $1200 al comienzo de cada año durante los próximos 10 años? Asumir un interés del 5% anual?\n\\[\n\\mbox{solución}\n\\]\n\\[\n\\ddot{S} = 1200\\frac{(1+0.05)^{10} - 1}{0.05}\\cdot(1+0.05) = \\fbox{15848.14}\n\\]\nEn R esto sería\n\n1200*accumulatedValue(i = 0.05, n = 10, type = \"due\")\n\n[1] 15848.14\n\n\nUn hombre quiere ahorrar $180,000 para pagar por la educación de su hijo dentro de 12 años. Un fondo de eduación obliga a los inversionistas a depositar cuotas iguales al final de cada año. Si el tipo de interés garantizado es del 5%, ¿Cuánto necesita ahorrar cada año con el fin de cumplir su objetivo?\n\\[\n\\mbox{Solución}\n\\]\n\\[\n\\begin{eqnarray}\nS &=& R\\frac{(1+i)^n -1}{i}\\\\[0.2cm]\nR &=& \\frac{S}{\\frac{(1+i)^n - 1}{i}} \\\\[0.2cm]\n  &=& \\frac{180000}{\\frac{(1+0.05)^{12} -1}{0.05}}\\\\[0.2cm]\n&=& \\fbox{11308.57}\n\\end{eqnarray}\n\\]\nEn R\n\n180000/accumulatedValue(i = 0.05, n = 12, type = \"immediate\")\n\n[1] 11308.57\n\n\nUna persona solicita un crédito para rehabilitar las recamaras y baños de su casa. El banco se lo autoriza y otorga cuatro meses de plazo para empezar a pagar su credito en forma vencida, es decir, que deberá hacer su primer pago al final del quinto mes. El credito se deberá amortizar pagando 24 mensualidades de $4,240. ¿Cuál será el valor del crédito?\n\\[\n\\mbox{Solución}\n\\]\n\n4240*annuity(i = 0.015, n = 24, m = 4,  type = \"immediate\")\n\n[1] 80018.69"
  },
  {
    "objectID": "documentos.html#ejercicios-a-resolver-del-primer-modulo",
    "href": "documentos.html#ejercicios-a-resolver-del-primer-modulo",
    "title": "Cursos",
    "section": "Ejercicios a resolver del primer modulo",
    "text": "Ejercicios a resolver del primer modulo\n\nGuia de ejercicios # 1"
  },
  {
    "objectID": "posts/post-with-code/index.html#tasa-marginal-de-sustitución-tms",
    "href": "posts/post-with-code/index.html#tasa-marginal-de-sustitución-tms",
    "title": "Microeconomía Intermedia con R",
    "section": "Tasa Marginal de Sustitución (TMS)",
    "text": "Tasa Marginal de Sustitución (TMS)\nOtro concepto importante en la teoría del consumidor es la Tasa Marginal de Sustitución (TMS). Matemáticamente esto es la pendiente de la curva de indiferencia, sin embargo, en términos microecnómicos esta pendiente se refiere a la relación de cambio entre un bien \\(x\\) y el bien \\(y\\), es decir, cuanto del bien x se tiene que sacrificar (aumentar) para aumentar (disminuir) el consumo del bien y para aumentarse en el mismo nivel de utilidad.\nEn términos matemáticos la TMS se define como:\n\\[\nTMS = -\\left.\\begin{array}{c}\\frac{dy}{dx} \\end{array}\\right|_{U = U_1}\n\\]\ndonde la notación indica que la pendiente se debe calcular a lo largo de la cuva de indiferencia \\(U_1\\).\nUn ejercicio interesante para el lector, seria intentar probar la identidad de \\(TMS\\) que acabamos de definir.\n\nMúltiples Curvas de Indiferencia\nHay una curva de indiferencia que pasa por cada punto del plano \\(xy\\). Cada una de estas curvas muestra combinaciones de \\(x\\) y \\(y\\) que proporcionan al individuo determinado nivel de satisfación como se vio en graficos anteriores. Los movimientos en dirección noreste representan movimientos hacia niveles más altos de satisfación.\n\n\n\nEl cambio de la pendiente a lo largo de U1 muestra que la canasta de consumo disponible afecta los intercambios que esta persona realizará libremente\n\n\nDado que ya conocemos en que consiste la TMS, y a este punto asumo que el lector ya tiene idea de como realizar el computo manual de la TMS para una función de utilidad dada. Entonces, procederemos a realizar el computo de la TMS en R, para el computo se procederá a crear una función que resuelva el problema más rapidamente, ya que como usted se ha podido dar cuenta se necesita y usar calculo diferencial (derivadas).\nLa función que crearemos para realizar el computo de la TMS la llamaremos TMS, veamos como hacerlo en R.\n\nTMS <- function(fun.utilidad, bien_x) {\n  U  <- parse(text = fun.utilidad)\n  v1 <- D(U, \"x\")                       # D() función que realiza la derivada de U\n  print(paste(\"TMS = \", \n              eval(v1, envir = list(x = bien_x)), \"considerando\", \n              bien_x, \"unidades del bien x\"))\n}\n\nDel bloque de código previo:\n\nTMS: función que calcula la tasa marginal de sustitución.\nfun.utilidad: función de la curva de indiferencia (y en función de x). Tiene que especificarse en caracteres.\nbien_x: unidades del bien x en donde se evaluara la TMS.\n\n\n\nEjemplo\nconsideremos la siguiente función de utilidad con su respectivo nivel de utilidad\n\\[\nU(x,y) = 10 = \\sqrt{xy}\n\\]\nSi calculamos la TMS de esta curva de indiferencia de manera manual tendremos:\n\\[\nTMS = -\\frac{\\frac{\\partial U}{\\partial x}}{\\frac{\\partial U}{\\partial y}} = -\\frac{100}{x^2}\n\\]\nComo se puede dar cuenta la TMS depende de “x”, lo que indica que tenemos que variar “x” positiva o negativamente , con el fin de obtener menos o más de “y” y mantenernos en la misma utilidad de 10.\nSi evaluamos la TMS cuando el bien “x” es igual a 5, entonces, la TMS sera de\n\\[\nTMS = -\\frac{100}{5^2} = -4\n\\]\nEsto implica, que si aumentamos el consumo del bien “x” en 1 tendremos que disminuir el consumo del bien y en 4. Veamos este ejemplo en R.\n\n# bien_x = 5\n# Utilizamos la función TMS que creamos previamente \n\nTMS(fun.utilidad = \"100/x\", 5)\n\n[1] \"TMS =  -4 considerando 5 unidades del bien x\"\n\n\nNote que el resultado es el deseado. Pero si queremos ver como varía la TMS para distintas cantidades del bien “x”, podemos hacer pequeñas variaciones a la función (TMS) que definimos en el primer bloque de código de esta sección.\n\nVar_TMS <- function(fun.utilidad, bien_x){\n  U  <- parse(text = fun.utilidad)\n  v1 <- D(U, \"x\")\n  eval(v1, envir = list(x = bien_x))\n}\n\n\n# Veamos el comportamiento de la TMS cuando variamos el bien x\n\nw <- c()\nfor (i in seq(60, 10, -10)){\n  t <- Var_TMS(fun.utilidad = \"100/x\",i)\n  w <- c(w,t)\n}\n\nw\n\n[1] -0.02777778 -0.04000000 -0.06250000 -0.11111111 -0.25000000 -1.00000000\n\n\nVeamos que a medida que el bien x pasa de ser abundante a ser un bien escazo cada vez le resulta al consumidor más relevante y si desea obtener una unidad adicional del bien x tendrá que renunciar a más cantidad del bien y. Es así que si el consumidor tiene solo un bien, cambiará este bien siempre y cuando reciba cien unidades del bien y.\nEn la siguiente sección de este post verá el tema de maximización de la utilidad dado una restricción presupuestaria. Es decir, desarrollamaremos el cálculo óptimo de los bienes, que maximizan la función de utilidad."
  },
  {
    "objectID": "documentos.html#videos-sobre-r",
    "href": "documentos.html#videos-sobre-r",
    "title": "Cursos",
    "section": "Videos Sobre R",
    "text": "Videos Sobre R\n\nIntroducción a R\nCreación y Operaciones con Vectores en R\nMatrices y DataFrame en R\nCreación de Funciones en R\nIntroducción a Teoría del Productor"
  },
  {
    "objectID": "posts/portafolio/index.html",
    "href": "posts/portafolio/index.html",
    "title": "Portfolio management",
    "section": "",
    "text": "La teoría de la fijación de precios de derivados es una teoría de rendimientos deterministas: cubrimos nuestros derivados con el subyacente para eliminar el riesgo, y nuestra cartera libre de riesgo resultante gana la tasa de interés libre de riesgo. Los bancos ganan dinero con este proceso de cobertura; venden algo por un poco más de lo que vale y cubrir el riesgo para obtener una ganancia garantizada. Los gestores de fondos compran y venden activos (incluidos los derivados) con el objetivo de superar la tasa de rendimiento del banco. Al hacerlo, se arriesgan. En este artículo explico algunas de la teorías detrás del riesgo y la recompensa de la inversión y, como optimizar una cartera para obtener el mejor valor por dinero."
  },
  {
    "objectID": "posts/portafolio/index.html#diversificación",
    "href": "posts/portafolio/index.html#diversificación",
    "title": "Portfolio management",
    "section": "Diversificación",
    "text": "Diversificación\nIntroduciremos algo de notación y muestro el efecto de la diversificación sobre la rentabilidad de la cartera. Supongamos que tenemos una cartera de \\(N\\) activos. El valor hoy del i-ésimo activo es \\(S_i\\) y su rendimiento aleatorio es \\(R_i\\) sobre nuestro horizonte de tiempo \\(T\\). Las \\(R_i \\sim N(\\mu_iT, \\sigma_i\\sqrt{T})\\). La correlación entre los rendimientos de la i-ésima y j-ésimo activo es \\(\\rho_{ij}\\) (con \\(\\rho_{ii} = 1\\)).\nLos parámetros \\(\\mu, \\sigma\\) y \\(\\rho\\) corresponden a la media, volatilidad y correlación a la que estamos acostumbrados. Tenga en cuenta la escala con el horizonte de tiempo.\nSi tenemos \\(w_i\\) del i-ésimo activo, entonces nuestra cartera tiene valor\n\\[\n\\Pi = \\sum_{i=1}^{N} w_iS_i\n\\]\nAl final de nuestro horizonte temporal, el valor es\n\\[\\Pi + \\delta\\Pi = \\sum_{i=1}^{N} w_iS_i(1+R_i)\\]\nPodemos escribir el cambio relativo en el valor de la cartera como\n\\[\n\\frac{\\delta\\Pi}{\\Pi} = \\sum_{i=1}^N W_iR_i\\hspace{1.5cm} (1)\n\\]\ndonde\n\\[\nW_i = \\frac{w_iS_i}{\\sum_{i=1}^N w_iS_i}\n\\]\nLos pesos \\(W_i\\) suman uno.\nA partir de (1) es sencillo calcular el rendimiento esperado de la cartera\n\\[\n\\mu_{\\Pi} = \\frac{1}{T}E\\left[\\begin{array}{c}\\frac{\\delta\\Pi}{\\Pi}\\end{array}\\right] = \\sum_{i=1}^{N}W_i \\mu_i\\hspace{6cm} (2)\n\\]\nY la desviación estándar de los retornos son\n\\[\n\\sigma_{\\Pi} = \\frac{1}{\\sqrt{T}}\\sqrt{var\\left[\\begin{array}{0} \\frac{\\delta \\Pi}{\\Pi}\\end{array}\\right]} = \\sqrt{\\sum_{i=1}^{N}\\sum_{j=1}^N W_iW_j \\rho_{ij}\\sigma_i\\sigma_j}\\hspace{1.5cm} (3)\n\\]\nEn ellos hemos relacionado los parámetros de los activos individuales con la rentabilidad esperada y la desviación estándar de toda la cartera.\nSupongamos que tenemos activos en nuestra cartera que no están correlacionados, es decir, \\(\\rho_{ij} = 0\\), \\(i = j\\). Para simplificar las cosas, suponga que tienen el mismo peso, de modo que \\(W_i = \\frac{1}{N}\\). El rendimiento esperado de la cartera está representado por\n\\[\n\\mu_{\\Pi} = \\frac{1}{N}\\sum_{i=1}^N \\mu_i\n\\]\nEl promedio de los rendimientos esperados de todos los activos, y la volatilidad se convierte en\n\\[\n\\sigma_{\\Pi} = \\sqrt{\\frac{1}{N^2}\\sum_{i=1}^N \\sigma_i^2}\n\\]\nEsta volatilidad es \\(O(N^{-1/2})\\) ya que hay \\(N\\) términos en la suma. A medida que aumentamos el número de activos en cartera, la desviación estándar de los rendimientos tiende a cero.\nSupongamos que todos los activos no están correlacionados, pero veremos algo similar cuando describa el Modelo de fijación de precios de activos de capital; la diversificación reduce la volatilidad sin perjudicar las expectativas de rendimientos.\nAhora me voy a referir a la volatilidad o desviación estándar como riesgo, algo malo que debe evitarse (dentro de lo razonable), y el rendimiento esperado como recompensa, algo bueno que queremos tanto como sea posible."
  },
  {
    "objectID": "posts/portafolio/index.html#teoría-moderna-del-portafolio",
    "href": "posts/portafolio/index.html#teoría-moderna-del-portafolio",
    "title": "Portfolio management",
    "section": "Teoría Moderna del Portafolio",
    "text": "Teoría Moderna del Portafolio\nPödemos usar el marco anterior para discutir la “mejor” cartera. La definición de “mejor” fue abordada con mucho éxito por el Premio Nobel Harry Markowitz. Su modelo proporciona una manera de definir carteras que sean eficientes.\nUna cartera eficiente es aquella que tiene la recompensa más alta para un nivel de riesgo, o el riesgo más bajo para una recompensa dada. Para ver cómo funciona esto imagina que hay cuatro activos en el mundo \\(A, B, C\\) y \\(D\\) con recompensa y riesgo como se muestra en la figura 1 (ignore E por el momento). Si pudieras comprar alguno de estos (pero de momentos no te permiten más de uno), ¿cuál comprarías? eliges D? No, porque tiene el mismo riesgo que B pero menos recompensa, tiene la misma recompensa que como C pero pun mayor riesgo. Entonces, podemos descartar \\(D\\). ¿Qué pasa con B o C? Ambos son atractivos cuando se comparan con D, pero entre si no estan claro, B tiene un mayor riesgo, pero obtiene una mayor recompensa. Sin embargo, comparándolos a ambos con A vemos que no hay competencia, ya que A es la elección preferida. Si introducimos el activo E con el mismo riesgo que B y una recompensa mayor que A, entonces no podemos decir objetivamente cuál de A y E es mejor; esta es una elección subjetiva y depende de las preferencias de riesgo de un inversor.\n\n\n\nFigura 1: Riesgo y recompensa de cinco activos\n\n\nAhora suponga que tengo los dos activos A y E de la figura 2, y puedo combinar en mi cartera, ¿qué efecto tiene esto en mi riesgo/recompensa?\n\n\n\nFigura 2: Dos activos y cualquier combinación\n\n\nDe (2) y (3) tenemos\n\\[\\mu_{\\Pi} = W\\mu_{A} + (1-W)\\mu_{E}\\]\ny\n\\[\n\\sigma_{\\Pi}^2 = W^2\\sigma_{A}^2 + 2W(1-W)\\rho\\sigma_{A}\\sigma_{E} + (1-W)^2\\sigma_{E}^2\n\\]\nAquí \\(w\\) es el peso del activo A y, recordando que los pesos deben sumar uno, el peso del activo E es \\(1 - E\\).\nA medida que variamos W, también cambian el riesgo y la recompensa. La linea en el espacio de riesgo/recompensa que es parametrizada por W es una hipérbola, como se muestra en la figura 2. La parte de esta curva en negrita es eficiente, y es preferible al resto de la curva. Una ves más, las preferencias de riesgo de un individuo dirá dónde quiere estar en la curva audaz. Cuando una de las volatilidades es cero la línea se vuelvve recta. en cualquier lugar de la curva entre los dos puntos se requiere una posición larga en cada activo. Fuera de esta región, uno de los activos se vende al descubierto para financiar la compra del otro. Todo lo que sigue asume que podemos vender al descubierto tanto activo como queramos. Los resultados cambian ligeramente cuando hay restricciones.\nSi tenemos muchos activos en nuestra cartera, ya no tenemos una simple hipérbola para nuestros posibles perfiles de riesgo/recompensa; en cambio obtenemos algo como lo que se muestra en la Figura 3.\n\n\n\nFigura 3: Posibilidades de cartera y la frontera eficiente\n\n\nEsta figura ahora usa todo A, B, C, D y E, no solo A y E. Aunque B, C y D no son individualmente atractivos, bien pueden ser útiles en un portafolio, dependiendo de como se correlacionen, o no, con otras inversiones. En esta figura podemos ver la frontera eficiente marcada en negrita. Dado cualquier elección de cartera elegiríamos tener una que se encuentre en esta frontera eficiente."
  },
  {
    "objectID": "posts/portafolio/index.html#incluir-una-inversión-sin-riesgo",
    "href": "posts/portafolio/index.html#incluir-una-inversión-sin-riesgo",
    "title": "Portfolio management",
    "section": "Incluir una inversión sin riesgo",
    "text": "Incluir una inversión sin riesgo\nUna inversión sin riesgo que gana una tasa de rendimiento garantizada \\(r\\) sería el punto F en la Figura 3. Si se nos permite mantener este activo en nuestra cartera, dado que la volatilidad de este activo es cero, obtenemos la nueva frontera eficiente que es la línea recta en la Figura 3. El portafolio para el que la línea recta toca la frontera eficiente original se denomina cartera de mercado. La linea recta en sí misma se llama la línea del mercado de capitales.\n\nDonde quiero estar en la frontera eficiente?\nHabiendo encontrado la frontera eficiente, queremos aber dónde debemos estar. Esta es una elección personal, la frontera eficiente es objetiva, dados los datos, pero la “mejor” posición en ella es subjetiva.\nLa siguiente es una forma de interpretar el diagrama de riesgo/recompensa que puede ser útil en la elección de la mejor cartera.\nEl rendimiento de la cartera se distribuye normalmente porque está compuesto por activos que se distribuyen normalmente. Tiene media \\(\\mu\\) y desviación estándar \\(\\sigma\\) (he ignorado la dependencia del horizonte T). La pendiente de la línea que une la cartera con el activo libre de riesgo es\n\\[\ns = \\frac{\\mu_{\\Pi} - r}{\\sigma_{\\Pi}}\n\\]\nEsta es una cantidad importante; es una medida de la probabilidad de tenter un rendimiento que exceda r. Si \\(C(.)\\) es la función acumulada para la distribución normal estandarizada, entonces \\(C(s)\\) es la probabilidad de que el rendimiento en \\(\\Pi\\) sea al menos q \\(r\\). Mas generalmente\n\\[\nC\\left(\\begin{array}{0}\\frac{\\mu_{\\Pi} - r^*}{\\sigma_{\\Pi}}\\end{array}\\right)\n\\]\nes la probabilidad de que el rendimiento exceda \\(r^*\\). Esto sugiere que si queremos minimizar la posibilidad de una rentabilidad inferior a \\(r^*\\) debemos elegir la cartera del conjunto de fronteras eficientes, \\(\\Pi_{eff}\\) con el mayor valor de la pendiente\n\\[\n\\frac{\\mu_{\\Pi_{eff}} - r^*}{\\sigma_{\\Pi_{eff}}}\n\\]\nPor el contrario, si mantenemos la pendiente de esta línea fija en \\(s\\), entonces podemos decir que con una confianza de \\(C(s)\\) no perderemos más que\n\\[\n\\mu_{\\Pi_{eff}} - s\\sigma_{\\Pi_{eff}}\n\\]\nNuestra elección de cartera podría determinarse maximizando esta cantidad. Estas dos estrategías se muestran esquemáticamente en la Figura 5.\n\n\n\nFigura 5: Dos sencillas formas de elegir la mejor cartera eficiente\n\n\nNinguno de estos métodos da resultados satisfactorios cuando existe inversión libre de riesgo entre los activos y hay ventas cortas sin restricciones, ya que dan como resultado un endeudamiento infinito.\nOtra forma de elegir la cartera óptima es con la ayuda de una función de utilidad. Este enfoque es popular entre los economistas. En la Figura 6 muestro las curvas de indiferencia y la frontera eficiente.\n\n\n\nFigura 6: Frontera eficiente y las curvas de indiferencia\n\n\nLas curvas reciben este nombre porque representan lineas a las cual el inversionista es indiferente al trade-off riesgo/recompensa. Un inversionista quiere un alto rendimiento y riesgo bajo. Frente a las carteras A y B en la Figura, ve a A con bajo rendimiento y bajo riesgo, pero B tiene una mejor recompensa a costa de un mayor riesgo. El inversor es indiferente entre estos dos. Sin embargo, C es mejor que ambos, estando en una curva preferida."
  },
  {
    "objectID": "documentos.html#libros-recomendados",
    "href": "documentos.html#libros-recomendados",
    "title": "Cursos",
    "section": "Libros Recomendados",
    "text": "Libros Recomendados\n\nAdvanced Microeconomic Theory, Geoffrey A. Jehle Philip J.Reny\nTeoría Microeconómica (Principios básicos y ampliaciones)"
  },
  {
    "objectID": "posts/finanzas/index.html",
    "href": "posts/finanzas/index.html",
    "title": "Portfolio management",
    "section": "",
    "text": "La teoría de la fijación de precios de derivados es una teoría de rendimientos deterministas: cubrimos nuestros derivados con el subyacente para eliminar el riesgo, y nuestra cartera libre de riesgo resultante gana la tasa de interés libre de riesgo. Los bancos ganan dinero con este proceso de cobertura; venden algo por un poco más de lo que vale y cubrir el riesgo para obtener una ganancia garantizada. Los gestores de fondos compran y venden activos (incluidos los derivados) con el objetivo de superar la tasa de rendimiento del banco. Al hacerlo, se arriesgan. En este artículo explico algunas de la teorías detrás del riesgo y la recompensa de la inversión y, como optimizar una cartera para obtener el mejor valor por dinero."
  },
  {
    "objectID": "posts/finanzas/index.html#diversificación",
    "href": "posts/finanzas/index.html#diversificación",
    "title": "Portfolio management",
    "section": "Diversificación",
    "text": "Diversificación\nIntroduciremos algo de notación y muestro el efecto de la diversificación sobre la rentabilidad de la cartera. Supongamos que tenemos una cartera de \\(N\\) activos. El valor hoy del i-ésimo activo es \\(S_i\\) y su rendimiento aleatorio es \\(R_i\\) sobre nuestro horizonte de tiempo \\(T\\). Las \\(R_i \\sim N(\\mu_iT, \\sigma_i\\sqrt{T})\\). La correlación entre los rendimientos de la i-ésima y j-ésimo activo es \\(\\rho_{ij}\\) (con \\(\\rho_{ii} = 1\\)).\nLos parámetros \\(\\mu, \\sigma\\) y \\(\\rho\\) corresponden a la media, volatilidad y correlación a la que estamos acostumbrados. Tenga en cuenta la escala con el horizonte de tiempo.\nSi tenemos \\(w_i\\) del i-ésimo activo, entonces nuestra cartera tiene valor\n\\[\n\\Pi = \\sum_{i=1}^{N} w_iS_i\n\\]\nAl final de nuestro horizonte temporal, el valor es\n\\[\\Pi + \\delta\\Pi = \\sum_{i=1}^{N} w_iS_i(1+R_i)\\]\nPodemos escribir el cambio relativo en el valor de la cartera como\n\\[\n\\frac{\\delta\\Pi}{\\Pi} = \\sum_{i=1}^N W_iR_i\\hspace{1.5cm} (1)\n\\]\ndonde\n\\[\nW_i = \\frac{w_iS_i}{\\sum_{i=1}^N w_iS_i}\n\\]\nLos pesos \\(W_i\\) suman uno.\nA partir de (1) es sencillo calcular el rendimiento esperado de la cartera\n\\[\n\\mu_{\\Pi} = \\frac{1}{T}E\\left[\\begin{array}{c}\\frac{\\delta\\Pi}{\\Pi}\\end{array}\\right] = \\sum_{i=1}^{N}W_i \\mu_i\\hspace{6cm} (2)\n\\]\nY la desviación estándar de los retornos son\n\\[\n\\sigma_{\\Pi} = \\frac{1}{\\sqrt{T}}\\sqrt{var\\left[\\begin{array}{0} \\frac{\\delta \\Pi}{\\Pi}\\end{array}\\right]} = \\sqrt{\\sum_{i=1}^{N}\\sum_{j=1}^N W_iW_j \\rho_{ij}\\sigma_i\\sigma_j}\\hspace{1.5cm} (3)\n\\]\nEn ellos hemos relacionado los parámetros de los activos individuales con la rentabilidad esperada y la desviación estándar de toda la cartera.\nSupongamos que tenemos activos en nuestra cartera que no están correlacionados, es decir, \\(\\rho_{ij} = 0\\), \\(i = j\\). Para simplificar las cosas, suponga que tienen el mismo peso, de modo que \\(W_i = \\frac{1}{N}\\). El rendimiento esperado de la cartera está representado por\n\\[\n\\mu_{\\Pi} = \\frac{1}{N}\\sum_{i=1}^N \\mu_i\n\\]\nEl promedio de los rendimientos esperados de todos los activos, y la volatilidad se convierte en\n\\[\n\\sigma_{\\Pi} = \\sqrt{\\frac{1}{N^2}\\sum_{i=1}^N \\sigma_i^2}\n\\]\nEsta volatilidad es \\(O(N^{-1/2})\\) ya que hay \\(N\\) términos en la suma. A medida que aumentamos el número de activos en cartera, la desviación estándar de los rendimientos tiende a cero.\nSupongamos que todos los activos no están correlacionados, pero veremos algo similar cuando describa el Modelo de fijación de precios de activos de capital; la diversificación reduce la volatilidad sin perjudicar las expectativas de rendimientos.\nAhora me voy a referir a la volatilidad o desviación estándar como riesgo, algo malo que debe evitarse (dentro de lo razonable), y el rendimiento esperado como recompensa, algo bueno que queremos tanto como sea posible."
  },
  {
    "objectID": "posts/finanzas/index.html#teoría-moderna-del-portafolio",
    "href": "posts/finanzas/index.html#teoría-moderna-del-portafolio",
    "title": "Portfolio management",
    "section": "Teoría Moderna del Portafolio",
    "text": "Teoría Moderna del Portafolio\nPödemos usar el marco anterior para discutir la “mejor” cartera. La definición de “mejor” fue abordada con mucho éxito por el Premio Nobel Harry Markowitz. Su modelo proporciona una manera de definir carteras que sean eficientes.\nUna cartera eficiente es aquella que tiene la recompensa más alta para un nivel de riesgo, o el riesgo más bajo para una recompensa dada. Para ver cómo funciona esto imagina que hay cuatro activos en el mundo \\(A, B, C\\) y \\(D\\) con recompensa y riesgo como se muestra en la figura 1 (ignore E por el momento). Si pudieras comprar alguno de estos (pero de momentos no te permiten más de uno), ¿cuál comprarías? eliges D? No, porque tiene el mismo riesgo que B pero menos recompensa, tiene la misma recompensa que como C pero pun mayor riesgo. Entonces, podemos descartar \\(D\\). ¿Qué pasa con B o C? Ambos son atractivos cuando se comparan con D, pero entre si no estan claro, B tiene un mayor riesgo, pero obtiene una mayor recompensa. Sin embargo, comparándolos a ambos con A vemos que no hay competencia, ya que A es la elección preferida. Si introducimos el activo E con el mismo riesgo que B y una recompensa mayor que A, entonces no podemos decir objetivamente cuál de A y E es mejor; esta es una elección subjetiva y depende de las preferencias de riesgo de un inversor.\n\n\n\nFigura 1: Riesgo y recompensa de cinco activos\n\n\nAhora suponga que tengo los dos activos A y E de la figura 2, y puedo combinar en mi cartera, ¿qué efecto tiene esto en mi riesgo/recompensa?\n\n\n\nFigura 2: Dos activos y cualquier combinación\n\n\nDe (2) y (3) tenemos\n\\[\\mu_{\\Pi} = W\\mu_{A} + (1-W)\\mu_{E}\\]\ny\n\\[\n\\sigma_{\\Pi}^2 = W^2\\sigma_{A}^2 + 2W(1-W)\\rho\\sigma_{A}\\sigma_{E} + (1-W)^2\\sigma_{E}^2\n\\]\nAquí \\(w\\) es el peso del activo A y, recordando que los pesos deben sumar uno, el peso del activo E es \\(1 - E\\).\nA medida que variamos W, también cambian el riesgo y la recompensa. La linea en el espacio de riesgo/recompensa que es parametrizada por W es una hipérbola, como se muestra en la figura 2. La parte de esta curva en negrita es eficiente, y es preferible al resto de la curva. Una ves más, las preferencias de riesgo de un individuo dirá dónde quiere estar en la curva audaz. Cuando una de las volatilidades es cero la línea se vuelvve recta. en cualquier lugar de la curva entre los dos puntos se requiere una posición larga en cada activo. Fuera de esta región, uno de los activos se vende al descubierto para financiar la compra del otro. Todo lo que sigue asume que podemos vender al descubierto tanto activo como queramos. Los resultados cambian ligeramente cuando hay restricciones.\nSi tenemos muchos activos en nuestra cartera, ya no tenemos una simple hipérbola para nuestros posibles perfiles de riesgo/recompensa; en cambio obtenemos algo como lo que se muestra en la Figura 3.\n\n\n\nFigura 3: Posibilidades de cartera y la frontera eficiente\n\n\nEsta figura ahora usa todo A, B, C, D y E, no solo A y E. Aunque B, C y D no son individualmente atractivos, bien pueden ser útiles en un portafolio, dependiendo de como se correlacionen, o no, con otras inversiones. En esta figura podemos ver la frontera eficiente marcada en negrita. Dado cualquier elección de cartera elegiríamos tener una que se encuentre en esta frontera eficiente."
  },
  {
    "objectID": "posts/finanzas/index.html#incluir-una-inversión-sin-riesgo",
    "href": "posts/finanzas/index.html#incluir-una-inversión-sin-riesgo",
    "title": "Portfolio management",
    "section": "Incluir una inversión sin riesgo",
    "text": "Incluir una inversión sin riesgo\nUna inversión sin riesgo que gana una tasa de rendimiento garantizada \\(r\\) sería el punto F en la Figura 3. Si se nos permite mantener este activo en nuestra cartera, dado que la volatilidad de este activo es cero, obtenemos la nueva frontera eficiente que es la línea recta en la Figura 3. El portafolio para el que la línea recta toca la frontera eficiente original se denomina cartera de mercado. La linea recta en sí misma se llama la línea del mercado de capitales.\n\nDonde quiero estar en la frontera eficiente?\nHabiendo encontrado la frontera eficiente, queremos aber dónde debemos estar. Esta es una elección personal, la frontera eficiente es objetiva, dados los datos, pero la “mejor” posición en ella es subjetiva.\nLa siguiente es una forma de interpretar el diagrama de riesgo/recompensa que puede ser útil en la elección de la mejor cartera.\nEl rendimiento de la cartera se distribuye normalmente porque está compuesto por activos que se distribuyen normalmente. Tiene media \\(\\mu\\) y desviación estándar \\(\\sigma\\) (he ignorado la dependencia del horizonte T). La pendiente de la línea que une la cartera con el activo libre de riesgo es\n\\[\ns = \\frac{\\mu_{\\Pi} - r}{\\sigma_{\\Pi}}\n\\]\nEsta es una cantidad importante; es una medida de la probabilidad de tenter un rendimiento que exceda r. Si \\(C(.)\\) es la función acumulada para la distribución normal estandarizada, entonces \\(C(s)\\) es la probabilidad de que el rendimiento en \\(\\Pi\\) sea al menos q \\(r\\). Mas generalmente\n\\[\nC\\left(\\begin{array}{0}\\frac{\\mu_{\\Pi} - r^*}{\\sigma_{\\Pi}}\\end{array}\\right)\n\\]\nes la probabilidad de que el rendimiento exceda \\(r^*\\). Esto sugiere que si queremos minimizar la posibilidad de una rentabilidad inferior a \\(r^*\\) debemos elegir la cartera del conjunto de fronteras eficientes, \\(\\Pi_{eff}\\) con el mayor valor de la pendiente\n\\[\n\\frac{\\mu_{\\Pi_{eff}} - r^*}{\\sigma_{\\Pi_{eff}}}\n\\]\nPor el contrario, si mantenemos la pendiente de esta línea fija en \\(s\\), entonces podemos decir que con una confianza de \\(C(s)\\) no perderemos más que\n\\[\n\\mu_{\\Pi_{eff}} - s\\sigma_{\\Pi_{eff}}\n\\]\nNuestra elección de cartera podría determinarse maximizando esta cantidad. Estas dos estrategías se muestran esquemáticamente en la Figura 5.\n\n\n\nFigura 5: Dos sencillas formas de elegir la mejor cartera eficiente\n\n\nNinguno de estos métodos da resultados satisfactorios cuando existe inversión libre de riesgo entre los activos y hay ventas cortas sin restricciones, ya que dan como resultado un endeudamiento infinito.\nOtra forma de elegir la cartera óptima es con la ayuda de una función de utilidad. Este enfoque es popular entre los economistas. En la Figura 6 muestro las curvas de indiferencia y la frontera eficiente.\n\n\n\nFigura 6: Frontera eficiente y las curvas de indiferencia\n\n\nLas curvas reciben este nombre porque representan lineas a las cual el inversionista es indiferente al trade-off riesgo/recompensa. Un inversionista quiere un alto rendimiento y riesgo bajo. Frente a las carteras A y B en la Figura, ve a A con bajo rendimiento y bajo riesgo, pero B tiene una mejor recompensa a costa de un mayor riesgo. El inversor es indiferente entre estos dos. Sin embargo, C es mejor que ambos, estando en una curva preferida."
  },
  {
    "objectID": "posts/finanzas/index.html#markowitz-en-la-práctica",
    "href": "posts/finanzas/index.html#markowitz-en-la-práctica",
    "title": "Portfolio management",
    "section": "Markowitz en la Práctica",
    "text": "Markowitz en la Práctica\nLas entradas al modelo de Markowitz son rendimientos esperados, volatilidades y correlaciones. Con \\(N\\) activos esto significa \\(N + N + N(N-1)/2\\) parámetros. La mayoría de estos no se pueden conocer con precisión (¿existen siquiera?); sólo las volatilidades son en absoluto confiable. Habiendo ingresado estos parámetros, debemos optimizar sobre todos los pesos de los activvos en la cartera: Elija un riesgo de cartera y encuentre los pesos que haqcen que el rendimiento de la cartera sea máximo sujeto a esta volatilidad. Este es un proceso que consume mucho tiempo computacionalmente a menos que uno solo tenga una pequeña cantidad de activos.\nEl problema con la implementación práctica de este modelo lo realizaré enm otro post que publicare posterioremente, usando Python. Por los momentos es importante comprender la lógica del modelo."
  },
  {
    "objectID": "posts/finanzas/index.html#modelo-de-precios-de-activos-de-capital-capital-asset-pricing-model",
    "href": "posts/finanzas/index.html#modelo-de-precios-de-activos-de-capital-capital-asset-pricing-model",
    "title": "Portfolio management",
    "section": "Modelo de Precios de Activos de Capital (Capital Asset Pricing Model)",
    "text": "Modelo de Precios de Activos de Capital (Capital Asset Pricing Model)\nAntes de discutir el modelo de fijación de precios de activos de capital o CAPM debemos introducir la idea del valor \\(\\beta\\). El parámetro \\(\\beta_i\\), de un activo en relación con una cartera \\(M\\) es la relación de la covarianza entre el rendimiento del valor y el rendimiento de la cartera a la varianza de la cartera. Del siguiente modo\n\\[\n\\beta_i = \\frac{Cov[R_iR_M]}{Var[R_M]}\n\\]\n\nEl Modelo de Indice Unico\nAhora construire un modelo de índices único y describiré las extenciones más adelante. Voy a relacionar el rendimiento de todos los activos al rendimiento de un índice representativo, \\(M\\). Este índice suele ser tomado como un índice bursátil de amplio rango en el modelo de índice único. Nosotros escribimos el rendimiento del i-ésimo activo como\n\\[\nR_i = \\alpha_i + \\beta_iR_M + \\epsilon_i\n\\]\nUsando esta representación podemos ver que el rendimiento de un activo se puede descomponer en tres partes:\n\nUna media constante\nUna parte aleatoria común con el índice \\(M\\) y,\nuna parte aleatoria no correlacionada con el índice, \\(\\epsilon_i\\).\n\nLa parte aleatoria \\(\\epsilon_i\\) es única para el i-ésimo activo, y tiene media cero. Observe cómo todos los activos están relacionados con el índice \\(M\\) pero son de contrario completamente sin correlación.\nEn la Figura 7 se muestra un gráfico de rendimiento de las acciones de Walt Disney frente a los rendimientos del S&P 500; \\(\\alpha\\) y \\(\\beta\\) se pueden determinar a partir de un análisis de regresión lineal. Los datos utilizados en este gráfico abarcaron desde enero de 1985 hasta casi finales de 1997.\n\n\n\nFigura 7: Rentabilidad de las acciones de Walt Disney frente a la rentabilidad del S&P 500.\n\n\nEl rendimiento esperado del índice se denotará por \\(\\mu_M\\) y su desviación estándar por \\(\\sigma_M\\). El rendimiento esperado del i-ésimo activo es entonces:\n\\[\n\\mu_i = \\alpha_i + \\beta_i\\mu_M\n\\]\ny la desviación estandar\n\\[\n\\sigma_i = \\sqrt{\\beta_i^2\\sigma_M^2 + e_i^2}\n\\]\ndonde \\(e_i\\) es la desviación estándar de \\(\\epsilon_i\\).\nSi tenemos una cartera de dichos activos, el rendimiento viene dado por\n\\[\n\\begin{eqnarray}\n\\frac{\\delta \\Pi}{\\Pi} = \\sum_{i=1}^N W_iR_i = \\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\alpha_i\\end{array}\\right) + R_M\\left(\\begin{array}{0} \\sum_{i=1}^N W_i\\beta_i\\end{array}\\right) + \\sum_{i=1}^N W_i\\epsilon_i\n\\end{eqnarray}\n\\]\nDe esto se sigue que\n\\[\n\\mu_\\Pi = \\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\alpha_i\\end{array}\\right) + E[R_M]\\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\beta_i\\end{array}\\right)\n\\]\nPodemos escribir\n\\[\n\\alpha_\\Pi = \\sum_{i=1}^NW_i\\alpha_i \\hspace{1cm}y \\hspace{1cm} \\beta_\\Pi = \\sum_{i=1}^NW_i\\beta_i\n\\]\nEntonces,\n\\[\n\\mu_\\Pi = \\alpha_\\Pi + \\beta_\\Pi\nE[R_M] = \\alpha_\\Pi + \\beta_\\Pi \\mu_M\\]\nDe manera similar, el riesgo se mide por\n\\[\n\\sigma_\\Pi = \\sqrt{\\sum_{i=1}^N\\sum_{j=1}^N W_iW_j\\beta_i\\beta_j\\sigma_M^2 + \\sum_{i=1}^N W_i^2 e_i^2}\n\\]\nSi los pesos son casi iguales, \\(N^{-1}\\), entonces los términos finales dentro de la raíz cuadrada también son \\(O(N^{-1})\\). Por lo tanto, esta expresión es, al orden principal como \\(N \\longrightarrow \\infty\\),\n\\[\n\\sigma_\\Pi = \\left|\\begin{array}{0}\\sum_{i=1}^N W_i\\beta_i\\end{array}\\right|\\sigma_M = \\left|\\begin{array}{0}\\beta_\\Pi\\end{array}\\right|\\sigma_M\n\\]\nObserve que la contribución de los no correlacionados a la cartera se desvanece a medida que aumentamos le número de activos en la cartera: El riesgo asociado con el \\(\\epsilon_s\\) se llama riesgo diversificable. El riesgo restante, que esta correlacionado con el índice, se denomina riesgo sistematico.\n\n\nElegir la Cartera Optima\nEl principal es el mismo que el modelo de Markowitz para la elección óptima de cartera. La diferencia es que hay muchos menos parámetros para ingresar, y el cálculo es mucho más rapido.\nEl procedimiento es el siguiente. Elija un valor para el rendimiento de la cartera \\(\\mu_\\Pi\\). Sujeto a esta restricción, minimizar \\(\\sigma_\\Pi\\). Repita esta minimización para diferentes rendimientos de carteera para obtener la frontera eficiente. La posición es esta curva es entonces una elección subjetiva."
  },
  {
    "objectID": "posts/finanzas/index.html#medición-del-desempeño",
    "href": "posts/finanzas/index.html#medición-del-desempeño",
    "title": "Portfolio management",
    "section": "Medición del Desempeño",
    "text": "Medición del Desempeño\nSi uno ha seguido una de las estratetias de asignación de activos, o simplemente ha negociado en instinto, ¿puede uno decir qué tan bien lo ha hecho? ¿Fueron los resultados sobresalientes deido a un extraño instinto natural, o los horribles resultados fueron simplemente mala suerte?\nEl rendimiento ideal sería uno en el que los rendimientos superaran la tasa libre de riesgo, pero en una moda consistente. No solo es importante obtener un alto rendimiento de la gestión de la cartera, pero uno debe lograr esto con la menor aleatoriedad posible.\nLas dos medidas más comunes de rendimiento por unidad de riesgo son\n\nRelación de Sharpe de recompensa a variabilidad y el\níndice de Treynor de recompensa a la volatilidad.\n\nEstos se definen como\n\\[\n\\begin{eqnarray}\nratio Sharpe &=& \\frac{\\mu_\\Pi - r}{\\sigma_\\Pi}\\\\[0.2cm]\nratio Treynor &=& \\frac{\\mu_\\Pi - r}{\\beta_\\Pi}\n\\end{eqnarray}\n\\]\nEn estos \\(\\mu\\) y \\(\\sigma\\) son el rendimiento realizado y la desviación estándar de la cartera durante el período. El \\(\\beta\\) es una medida de la volatilidad de la cartera. El ratio de Sharpe generalmente se usa cuando la cartera es la totalidad de la inversión de uno y el ratio de Treynor cuando se examina el rendimiento de un componente de la cartera de toda la empresa, digamos.\nCuando la cartera baja las dos medidas son las mismas (hasta un factor del mercado Desviación Estándar)\n\n\n\nFigura 8: un buen y un gerente (manager); mismos rendimientos, distintas volatilidades\n\n\nLa Figura 8 muestra el valor de la cartera frente al tiempo para un buen administrador y un mal administrador."
  },
  {
    "objectID": "posts/finanzas/index.html#resumen",
    "href": "posts/finanzas/index.html#resumen",
    "title": "Portfolio management",
    "section": "Resumen",
    "text": "Resumen\n\nLa gestión de carteras y la asignación de activos consisten en asumir riesgos a cambio de una recompensa.\nLas preguntas son, ¿como decidir cuánto riesgo tomar? ¿cómo obtener el mejor rendimiento? Pero la teoría de los derivados se basa en no correr ningún riesgo en absoluto, por lo que he dedicado tiempo a gestión de cartera en este post.\nExiste tanta incertidumbre en el tema de las finanzas que la eliminación del riesgo es casi imposible y las ideas detrás de la gestión de carteras deben ser apreciadas por cualquier persona involucrada en derivados."
  },
  {
    "objectID": "posts/finance/index.html",
    "href": "posts/finance/index.html",
    "title": "Portfolio management",
    "section": "",
    "text": "La teoría de la fijación de precios de derivados es una teoría de rendimientos deterministas: cubrimos nuestros derivados con el subyacente para eliminar el riesgo, y nuestra cartera libre de riesgo resultante gana la tasa de interés libre de riesgo. Los bancos ganan dinero con este proceso de cobertura; venden algo por un poco más de lo que vale y cubrir el riesgo para obtener una ganancia garantizada. Los gestores de fondos compran y venden activos (incluidos los derivados) con el objetivo de superar la tasa de rendimiento del banco. Al hacerlo, se arriesgan. En este artículo explico algunas de la teorías detrás del riesgo y la recompensa de la inversión y, como optimizar una cartera para obtener el mejor valor por dinero."
  },
  {
    "objectID": "posts/finance/index.html#diversificación",
    "href": "posts/finance/index.html#diversificación",
    "title": "Portfolio management",
    "section": "Diversificación",
    "text": "Diversificación\nIntroduciremos algo de notación y muestro el efecto de la diversificación sobre la rentabilidad de la cartera. Supongamos que tenemos una cartera de \\(N\\) activos. El valor hoy del i-ésimo activo es \\(S_i\\) y su rendimiento aleatorio es \\(R_i\\) sobre nuestro horizonte de tiempo \\(T\\). Las \\(R_i \\sim N(\\mu_iT, \\sigma_i\\sqrt{T})\\). La correlación entre los rendimientos de la i-ésima y j-ésimo activo es \\(\\rho_{ij}\\) (con \\(\\rho_{ii} = 1\\)).\nLos parámetros \\(\\mu, \\sigma\\) y \\(\\rho\\) corresponden a la media, volatilidad y correlación a la que estamos acostumbrados. Tenga en cuenta la escala con el horizonte de tiempo.\nSi tenemos \\(w_i\\) del i-ésimo activo, entonces nuestra cartera tiene valor\n\\[\n\\Pi = \\sum_{i=1}^{N} w_iS_i\n\\]\nAl final de nuestro horizonte temporal, el valor es\n\\[\\Pi + \\delta\\Pi = \\sum_{i=1}^{N} w_iS_i(1+R_i)\\]\nPodemos escribir el cambio relativo en el valor de la cartera como\n\\[\n\\frac{\\delta\\Pi}{\\Pi} = \\sum_{i=1}^N W_iR_i\\hspace{1.5cm} (1)\n\\]\ndonde\n\\[\nW_i = \\frac{w_iS_i}{\\sum_{i=1}^N w_iS_i}\n\\]\nLos pesos \\(W_i\\) suman uno.\nA partir de (1) es sencillo calcular el rendimiento esperado de la cartera\n\\[\n\\mu_{\\Pi} = \\frac{1}{T}E\\left[\\begin{array}{c}\\frac{\\delta\\Pi}{\\Pi}\\end{array}\\right] = \\sum_{i=1}^{N}W_i \\mu_i\\hspace{6cm} (2)\n\\]\nY la desviación estándar de los retornos son\n\\[\n\\sigma_{\\Pi} = \\frac{1}{\\sqrt{T}}\\sqrt{var\\left[\\begin{array}{0} \\frac{\\delta \\Pi}{\\Pi}\\end{array}\\right]} = \\sqrt{\\sum_{i=1}^{N}\\sum_{j=1}^N W_iW_j \\rho_{ij}\\sigma_i\\sigma_j}\\hspace{1.5cm} (3)\n\\]\nEn ellos hemos relacionado los parámetros de los activos individuales con la rentabilidad esperada y la desviación estándar de toda la cartera.\nSupongamos que tenemos activos en nuestra cartera que no están correlacionados, es decir, \\(\\rho_{ij} = 0\\), \\(i = j\\). Para simplificar las cosas, suponga que tienen el mismo peso, de modo que \\(W_i = \\frac{1}{N}\\). El rendimiento esperado de la cartera está representado por\n\\[\n\\mu_{\\Pi} = \\frac{1}{N}\\sum_{i=1}^N \\mu_i\n\\]\nEl promedio de los rendimientos esperados de todos los activos, y la volatilidad se convierte en\n\\[\n\\sigma_{\\Pi} = \\sqrt{\\frac{1}{N^2}\\sum_{i=1}^N \\sigma_i^2}\n\\]\nEsta volatilidad es \\(O(N^{-1/2})\\) ya que hay \\(N\\) términos en la suma. A medida que aumentamos el número de activos en cartera, la desviación estándar de los rendimientos tiende a cero.\nSupongamos que todos los activos no están correlacionados, pero veremos algo similar cuando describa el Modelo de fijación de precios de activos de capital; la diversificación reduce la volatilidad sin perjudicar las expectativas de rendimientos.\nAhora me voy a referir a la volatilidad o desviación estándar como riesgo, algo malo que debe evitarse (dentro de lo razonable), y el rendimiento esperado como recompensa, algo bueno que queremos tanto como sea posible."
  },
  {
    "objectID": "posts/finance/index.html#teoría-moderna-del-portafolio",
    "href": "posts/finance/index.html#teoría-moderna-del-portafolio",
    "title": "Portfolio management",
    "section": "Teoría Moderna del Portafolio",
    "text": "Teoría Moderna del Portafolio\nPödemos usar el marco anterior para discutir la “mejor” cartera. La definición de “mejor” fue abordada con mucho éxito por el Premio Nobel Harry Markowitz. Su modelo proporciona una manera de definir carteras que sean eficientes.\nUna cartera eficiente es aquella que tiene la recompensa más alta para un nivel de riesgo, o el riesgo más bajo para una recompensa dada. Para ver cómo funciona esto imagina que hay cuatro activos en el mundo \\(A, B, C\\) y \\(D\\) con recompensa y riesgo como se muestra en la figura 1 (ignore E por el momento). Si pudieras comprar alguno de estos (pero de momentos no te permiten más de uno), ¿cuál comprarías? eliges D? No, porque tiene el mismo riesgo que B pero menos recompensa, tiene la misma recompensa que como C pero pun mayor riesgo. Entonces, podemos descartar \\(D\\). ¿Qué pasa con B o C? Ambos son atractivos cuando se comparan con D, pero entre si no estan claro, B tiene un mayor riesgo, pero obtiene una mayor recompensa. Sin embargo, comparándolos a ambos con A vemos que no hay competencia, ya que A es la elección preferida. Si introducimos el activo E con el mismo riesgo que B y una recompensa mayor que A, entonces no podemos decir objetivamente cuál de A y E es mejor; esta es una elección subjetiva y depende de las preferencias de riesgo de un inversor.\n\n\n\nFigura 1: Riesgo y recompensa de cinco activos\n\n\nAhora suponga que tengo los dos activos A y E de la figura 2, y puedo combinar en mi cartera, ¿qué efecto tiene esto en mi riesgo/recompensa?\n\n\n\nFigura 2: Dos activos y cualquier combinación\n\n\nDe (2) y (3) tenemos\n\\[\\mu_{\\Pi} = W\\mu_{A} + (1-W)\\mu_{E}\\]\ny\n\\[\n\\sigma_{\\Pi}^2 = W^2\\sigma_{A}^2 + 2W(1-W)\\rho\\sigma_{A}\\sigma_{E} + (1-W)^2\\sigma_{E}^2\n\\]\nAquí \\(w\\) es el peso del activo A y, recordando que los pesos deben sumar uno, el peso del activo E es \\(1 - E\\).\nA medida que variamos W, también cambian el riesgo y la recompensa. La linea en el espacio de riesgo/recompensa que es parametrizada por W es una hipérbola, como se muestra en la figura 2. La parte de esta curva en negrita es eficiente, y es preferible al resto de la curva. Una ves más, las preferencias de riesgo de un individuo dirá dónde quiere estar en la curva audaz. Cuando una de las volatilidades es cero la línea se vuelvve recta. en cualquier lugar de la curva entre los dos puntos se requiere una posición larga en cada activo. Fuera de esta región, uno de los activos se vende al descubierto para financiar la compra del otro. Todo lo que sigue asume que podemos vender al descubierto tanto activo como queramos. Los resultados cambian ligeramente cuando hay restricciones.\nSi tenemos muchos activos en nuestra cartera, ya no tenemos una simple hipérbola para nuestros posibles perfiles de riesgo/recompensa; en cambio obtenemos algo como lo que se muestra en la Figura 3.\n\n\n\nFigura 3: Posibilidades de cartera y la frontera eficiente\n\n\nEsta figura ahora usa todo A, B, C, D y E, no solo A y E. Aunque B, C y D no son individualmente atractivos, bien pueden ser útiles en un portafolio, dependiendo de como se correlacionen, o no, con otras inversiones. En esta figura podemos ver la frontera eficiente marcada en negrita. Dado cualquier elección de cartera elegiríamos tener una que se encuentre en esta frontera eficiente."
  },
  {
    "objectID": "posts/finance/index.html#incluir-una-inversión-sin-riesgo",
    "href": "posts/finance/index.html#incluir-una-inversión-sin-riesgo",
    "title": "Portfolio management",
    "section": "Incluir una inversión sin riesgo",
    "text": "Incluir una inversión sin riesgo\nUna inversión sin riesgo que gana una tasa de rendimiento garantizada \\(r\\) sería el punto F en la Figura 3. Si se nos permite mantener este activo en nuestra cartera, dado que la volatilidad de este activo es cero, obtenemos la nueva frontera eficiente que es la línea recta en la Figura 3. El portafolio para el que la línea recta toca la frontera eficiente original se denomina cartera de mercado. La linea recta en sí misma se llama la línea del mercado de capitales.\n\nDonde quiero estar en la frontera eficiente?\nHabiendo encontrado la frontera eficiente, queremos aber dónde debemos estar. Esta es una elección personal, la frontera eficiente es objetiva, dados los datos, pero la “mejor” posición en ella es subjetiva.\nLa siguiente es una forma de interpretar el diagrama de riesgo/recompensa que puede ser útil en la elección de la mejor cartera.\nEl rendimiento de la cartera se distribuye normalmente porque está compuesto por activos que se distribuyen normalmente. Tiene media \\(\\mu\\) y desviación estándar \\(\\sigma\\) (he ignorado la dependencia del horizonte T). La pendiente de la línea que une la cartera con el activo libre de riesgo es\n\\[\ns = \\frac{\\mu_{\\Pi} - r}{\\sigma_{\\Pi}}\n\\]\nEsta es una cantidad importante; es una medida de la probabilidad de tenter un rendimiento que exceda r. Si \\(C(.)\\) es la función acumulada para la distribución normal estandarizada, entonces \\(C(s)\\) es la probabilidad de que el rendimiento en \\(\\Pi\\) sea al menos q \\(r\\). Mas generalmente\n\\[\nC\\left(\\begin{array}{0}\\frac{\\mu_{\\Pi} - r^*}{\\sigma_{\\Pi}}\\end{array}\\right)\n\\]\nes la probabilidad de que el rendimiento exceda \\(r^*\\). Esto sugiere que si queremos minimizar la posibilidad de una rentabilidad inferior a \\(r^*\\) debemos elegir la cartera del conjunto de fronteras eficientes, \\(\\Pi_{eff}\\) con el mayor valor de la pendiente\n\\[\n\\frac{\\mu_{\\Pi_{eff}} - r^*}{\\sigma_{\\Pi_{eff}}}\n\\]\nPor el contrario, si mantenemos la pendiente de esta línea fija en \\(s\\), entonces podemos decir que con una confianza de \\(C(s)\\) no perderemos más que\n\\[\n\\mu_{\\Pi_{eff}} - s\\sigma_{\\Pi_{eff}}\n\\]\nNuestra elección de cartera podría determinarse maximizando esta cantidad. Estas dos estrategías se muestran esquemáticamente en la Figura 5.\n\n\n\nFigura 5: Dos sencillas formas de elegir la mejor cartera eficiente\n\n\nNinguno de estos métodos da resultados satisfactorios cuando existe inversión libre de riesgo entre los activos y hay ventas cortas sin restricciones, ya que dan como resultado un endeudamiento infinito.\nOtra forma de elegir la cartera óptima es con la ayuda de una función de utilidad. Este enfoque es popular entre los economistas. En la Figura 6 muestro las curvas de indiferencia y la frontera eficiente.\n\n\n\nFigura 6: Frontera eficiente y las curvas de indiferencia\n\n\nLas curvas reciben este nombre porque representan lineas a las cual el inversionista es indiferente al trade-off riesgo/recompensa. Un inversionista quiere un alto rendimiento y riesgo bajo. Frente a las carteras A y B en la Figura, ve a A con bajo rendimiento y bajo riesgo, pero B tiene una mejor recompensa a costa de un mayor riesgo. El inversor es indiferente entre estos dos. Sin embargo, C es mejor que ambos, estando en una curva preferida."
  },
  {
    "objectID": "posts/finance/index.html#markowitz-en-la-práctica",
    "href": "posts/finance/index.html#markowitz-en-la-práctica",
    "title": "Portfolio management",
    "section": "Markowitz en la Práctica",
    "text": "Markowitz en la Práctica\nLas entradas al modelo de Markowitz son rendimientos esperados, volatilidades y correlaciones. Con \\(N\\) activos esto significa \\(N + N + N(N-1)/2\\) parámetros. La mayoría de estos no se pueden conocer con precisión (¿existen siquiera?); sólo las volatilidades son en absoluto confiable. Habiendo ingresado estos parámetros, debemos optimizar sobre todos los pesos de los activvos en la cartera: Elija un riesgo de cartera y encuentre los pesos que haqcen que el rendimiento de la cartera sea máximo sujeto a esta volatilidad. Este es un proceso que consume mucho tiempo computacionalmente a menos que uno solo tenga una pequeña cantidad de activos.\nEl problema con la implementación práctica de este modelo lo realizaré enm otro post que publicare posterioremente, usando Python. Por los momentos es importante comprender la lógica del modelo."
  },
  {
    "objectID": "posts/finance/index.html#modelo-de-precios-de-activos-de-capital-capital-asset-pricing-model",
    "href": "posts/finance/index.html#modelo-de-precios-de-activos-de-capital-capital-asset-pricing-model",
    "title": "Portfolio management",
    "section": "Modelo de Precios de Activos de Capital (Capital Asset Pricing Model)",
    "text": "Modelo de Precios de Activos de Capital (Capital Asset Pricing Model)\nAntes de discutir el modelo de fijación de precios de activos de capital o CAPM debemos introducir la idea del valor \\(\\beta\\). El parámetro \\(\\beta_i\\), de un activo en relación con una cartera \\(M\\) es la relación de la covarianza entre el rendimiento del valor y el rendimiento de la cartera a la varianza de la cartera. Del siguiente modo\n\\[\n\\beta_i = \\frac{Cov[R_iR_M]}{Var[R_M]}\n\\]\n\nEl Modelo de Indice Unico\nAhora construire un modelo de índices único y describiré las extenciones más adelante. Voy a relacionar el rendimiento de todos los activos al rendimiento de un índice representativo, \\(M\\). Este índice suele ser tomado como un índice bursátil de amplio rango en el modelo de índice único. Nosotros escribimos el rendimiento del i-ésimo activo como\n\\[\nR_i = \\alpha_i + \\beta_iR_M + \\epsilon_i\n\\]\nUsando esta representación podemos ver que el rendimiento de un activo se puede descomponer en tres partes:\n\nUna media constante\nUna parte aleatoria común con el índice \\(M\\) y,\nuna parte aleatoria no correlacionada con el índice, \\(\\epsilon_i\\).\n\nLa parte aleatoria \\(\\epsilon_i\\) es única para el i-ésimo activo, y tiene media cero. Observe cómo todos los activos están relacionados con el índice \\(M\\) pero son de contrario completamente sin correlación.\nEn la Figura 7 se muestra un gráfico de rendimiento de las acciones de Walt Disney frente a los rendimientos del S&P 500; \\(\\alpha\\) y \\(\\beta\\) se pueden determinar a partir de un análisis de regresión lineal. Los datos utilizados en este gráfico abarcaron desde enero de 1985 hasta casi finales de 1997.\n\n\n\nFigura 7: Rentabilidad de las acciones de Walt Disney frente a la rentabilidad del S&P 500.\n\n\nEl rendimiento esperado del índice se denotará por \\(\\mu_M\\) y su desviación estándar por \\(\\sigma_M\\). El rendimiento esperado del i-ésimo activo es entonces:\n\\[\n\\mu_i = \\alpha_i + \\beta_i\\mu_M\n\\]\ny la desviación estandar\n\\[\n\\sigma_i = \\sqrt{\\beta_i^2\\sigma_M^2 + e_i^2}\n\\]\ndonde \\(e_i\\) es la desviación estándar de \\(\\epsilon_i\\).\nSi tenemos una cartera de dichos activos, el rendimiento viene dado por\n\\[\n\\begin{eqnarray}\n\\frac{\\delta \\Pi}{\\Pi} = \\sum_{i=1}^N W_iR_i = \\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\alpha_i\\end{array}\\right) + R_M\\left(\\begin{array}{0} \\sum_{i=1}^N W_i\\beta_i\\end{array}\\right) + \\sum_{i=1}^N W_i\\epsilon_i\n\\end{eqnarray}\n\\]\nDe esto se sigue que\n\\[\n\\mu_\\Pi = \\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\alpha_i\\end{array}\\right) + E[R_M]\\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\beta_i\\end{array}\\right)\n\\]\nPodemos escribir\n\\[\n\\alpha_\\Pi = \\sum_{i=1}^NW_i\\alpha_i \\hspace{1cm}y \\hspace{1cm} \\beta_\\Pi = \\sum_{i=1}^NW_i\\beta_i\n\\]\nEntonces,\n\\[\n\\mu_\\Pi = \\alpha_\\Pi + \\beta_\\Pi\nE[R_M] = \\alpha_\\Pi + \\beta_\\Pi \\mu_M\\]\nDe manera similar, el riesgo se mide por\n\\[\n\\sigma_\\Pi = \\sqrt{\\sum_{i=1}^N\\sum_{j=1}^N W_iW_j\\beta_i\\beta_j\\sigma_M^2 + \\sum_{i=1}^N W_i^2 e_i^2}\n\\]\nSi los pesos son casi iguales, \\(N^{-1}\\), entonces los términos finales dentro de la raíz cuadrada también son \\(O(N^{-1})\\). Por lo tanto, esta expresión es, al orden principal como \\(N \\longrightarrow \\infty\\),\n\\[\n\\sigma_\\Pi = \\left|\\begin{array}{0}\\sum_{i=1}^N W_i\\beta_i\\end{array}\\right|\\sigma_M = \\left|\\begin{array}{0}\\beta_\\Pi\\end{array}\\right|\\sigma_M\n\\]\nObserve que la contribución de los no correlacionados a la cartera se desvanece a medida que aumentamos le número de activos en la cartera: El riesgo asociado con el \\(\\epsilon_s\\) se llama riesgo diversificable. El riesgo restante, que esta correlacionado con el índice, se denomina riesgo sistematico.\n\n\nElegir la Cartera Optima\nEl principal es el mismo que el modelo de Markowitz para la elección óptima de cartera. La diferencia es que hay muchos menos parámetros para ingresar, y el cálculo es mucho más rapido.\nEl procedimiento es el siguiente. Elija un valor para el rendimiento de la cartera \\(\\mu_\\Pi\\). Sujeto a esta restricción, minimizar \\(\\sigma_\\Pi\\). Repita esta minimización para diferentes rendimientos de carteera para obtener la frontera eficiente. La posición es esta curva es entonces una elección subjetiva."
  },
  {
    "objectID": "posts/finance/index.html#medición-del-desempeño",
    "href": "posts/finance/index.html#medición-del-desempeño",
    "title": "Portfolio management",
    "section": "Medición del Desempeño",
    "text": "Medición del Desempeño\nSi uno ha seguido una de las estratetias de asignación de activos, o simplemente ha negociado en instinto, ¿puede uno decir qué tan bien lo ha hecho? ¿Fueron los resultados sobresalientes deido a un extraño instinto natural, o los horribles resultados fueron simplemente mala suerte?\nEl rendimiento ideal sería uno en el que los rendimientos superaran la tasa libre de riesgo, pero en una moda consistente. No solo es importante obtener un alto rendimiento de la gestión de la cartera, pero uno debe lograr esto con la menor aleatoriedad posible.\nLas dos medidas más comunes de rendimiento por unidad de riesgo son\n\nRelación de Sharpe de recompensa a variabilidad y el\níndice de Treynor de recompensa a la volatilidad.\n\nEstos se definen como\n\\[\n\\begin{eqnarray}\nratio Sharpe &=& \\frac{\\mu_\\Pi - r}{\\sigma_\\Pi}\\\\[0.2cm]\nratio Treynor &=& \\frac{\\mu_\\Pi - r}{\\beta_\\Pi}\n\\end{eqnarray}\n\\]\nEn estos \\(\\mu\\) y \\(\\sigma\\) son el rendimiento realizado y la desviación estándar de la cartera durante el período. El \\(\\beta\\) es una medida de la volatilidad de la cartera. El ratio de Sharpe generalmente se usa cuando la cartera es la totalidad de la inversión de uno y el ratio de Treynor cuando se examina el rendimiento de un componente de la cartera de toda la empresa, digamos.\nCuando la cartera baja las dos medidas son las mismas (hasta un factor del mercado Desviación Estándar)\n\n\n\nFigura 8: un buen y un gerente (manager); mismos rendimientos, distintas volatilidades\n\n\nLa Figura 8 muestra el valor de la cartera frente al tiempo para un buen administrador y un mal administrador."
  },
  {
    "objectID": "posts/finance/index.html#resumen",
    "href": "posts/finance/index.html#resumen",
    "title": "Portfolio management",
    "section": "Resumen",
    "text": "Resumen\n\nLa gestión de carteras y la asignación de activos consisten en asumir riesgos a cambio de una recompensa.\nLas preguntas son, ¿como decidir cuánto riesgo tomar? ¿cómo obtener el mejor rendimiento? Pero la teoría de los derivados se basa en no correr ningún riesgo en absoluto, por lo que he dedicado tiempo a gestión de cartera en este post.\nExiste tanta incertidumbre en el tema de las finanzas que la eliminación del riesgo es casi imposible y las ideas detrás de la gestión de carteras deben ser apreciadas por cualquier persona involucrada en derivados."
  },
  {
    "objectID": "posts/port/index.html",
    "href": "posts/port/index.html",
    "title": "Portfolio management",
    "section": "",
    "text": "La teoría de la fijación de precios de derivados es una teoría de rendimientos deterministas: cubrimos nuestros derivados con el subyacente para eliminar el riesgo, y nuestra cartera libre de riesgo resultante gana la tasa de interés libre de riesgo. Los bancos ganan dinero con este proceso de cobertura; venden algo por un poco más de lo que vale y cubrir el riesgo para obtener una ganancia garantizada. Los gestores de fondos compran y venden activos (incluidos los derivados) con el objetivo de superar la tasa de rendimiento del banco. Al hacerlo, se arriesgan. En este artículo explico algunas de la teorías detrás del riesgo y la recompensa de la inversión y, como optimizar una cartera para obtener el mejor valor por dinero."
  },
  {
    "objectID": "posts/port/index.html#diversificación",
    "href": "posts/port/index.html#diversificación",
    "title": "Portfolio management",
    "section": "Diversificación",
    "text": "Diversificación\nIntroduciremos algo de notación y muestro el efecto de la diversificación sobre la rentabilidad de la cartera. Supongamos que tenemos una cartera de \\(N\\) activos. El valor hoy del i-ésimo activo es \\(S_i\\) y su rendimiento aleatorio es \\(R_i\\) sobre nuestro horizonte de tiempo \\(T\\). Las \\(R_i \\sim N(\\mu_iT, \\sigma_i\\sqrt{T})\\). La correlación entre los rendimientos de la i-ésima y j-ésimo activo es \\(\\rho_{ij}\\) (con \\(\\rho_{ii} = 1\\)).\nLos parámetros \\(\\mu, \\sigma\\) y \\(\\rho\\) corresponden a la media, volatilidad y correlación a la que estamos acostumbrados. Tenga en cuenta la escala con el horizonte de tiempo.\nSi tenemos \\(w_i\\) del i-ésimo activo, entonces nuestra cartera tiene valor\n\\[\n\\Pi = \\sum_{i=1}^{N} w_iS_i\n\\]\nAl final de nuestro horizonte temporal, el valor es\n\\[\\Pi + \\delta\\Pi = \\sum_{i=1}^{N} w_iS_i(1+R_i)\\]\nPodemos escribir el cambio relativo en el valor de la cartera como\n\\[\n\\frac{\\delta\\Pi}{\\Pi} = \\sum_{i=1}^N W_iR_i\\hspace{1.5cm} (1)\n\\]\ndonde\n\\[\nW_i = \\frac{w_iS_i}{\\sum_{i=1}^N w_iS_i}\n\\]\nLos pesos \\(W_i\\) suman uno.\nA partir de (1) es sencillo calcular el rendimiento esperado de la cartera\n\\[\n\\mu_{\\Pi} = \\frac{1}{T}E\\left[\\begin{array}{c}\\frac{\\delta\\Pi}{\\Pi}\\end{array}\\right] = \\sum_{i=1}^{N}W_i \\mu_i\\hspace{6cm} (2)\n\\]\nY la desviación estándar de los retornos son\n\\[\n\\sigma_{\\Pi} = \\frac{1}{\\sqrt{T}}\\sqrt{var\\left[\\begin{array}{0} \\frac{\\delta \\Pi}{\\Pi}\\end{array}\\right]} = \\sqrt{\\sum_{i=1}^{N}\\sum_{j=1}^N W_iW_j \\rho_{ij}\\sigma_i\\sigma_j}\\hspace{1.5cm} (3)\n\\]\nEn ellos hemos relacionado los parámetros de los activos individuales con la rentabilidad esperada y la desviación estándar de toda la cartera.\nSupongamos que tenemos activos en nuestra cartera que no están correlacionados, es decir, \\(\\rho_{ij} = 0\\), \\(i = j\\). Para simplificar las cosas, suponga que tienen el mismo peso, de modo que \\(W_i = \\frac{1}{N}\\). El rendimiento esperado de la cartera está representado por\n\\[\n\\mu_{\\Pi} = \\frac{1}{N}\\sum_{i=1}^N \\mu_i\n\\]\nEl promedio de los rendimientos esperados de todos los activos, y la volatilidad se convierte en\n\\[\n\\sigma_{\\Pi} = \\sqrt{\\frac{1}{N^2}\\sum_{i=1}^N \\sigma_i^2}\n\\]\nEsta volatilidad es \\(O(N^{-1/2})\\) ya que hay \\(N\\) términos en la suma. A medida que aumentamos el número de activos en cartera, la desviación estándar de los rendimientos tiende a cero.\nSupongamos que todos los activos no están correlacionados, pero veremos algo similar cuando describa el Modelo de fijación de precios de activos de capital; la diversificación reduce la volatilidad sin perjudicar las expectativas de rendimientos.\nAhora me voy a referir a la volatilidad o desviación estándar como riesgo, algo malo que debe evitarse (dentro de lo razonable), y el rendimiento esperado como recompensa, algo bueno que queremos tanto como sea posible."
  },
  {
    "objectID": "posts/port/index.html#teoría-moderna-del-portafolio",
    "href": "posts/port/index.html#teoría-moderna-del-portafolio",
    "title": "Portfolio management",
    "section": "Teoría Moderna del Portafolio",
    "text": "Teoría Moderna del Portafolio\nPödemos usar el marco anterior para discutir la “mejor” cartera. La definición de “mejor” fue abordada con mucho éxito por el Premio Nobel Harry Markowitz. Su modelo proporciona una manera de definir carteras que sean eficientes.\nUna cartera eficiente es aquella que tiene la recompensa más alta para un nivel de riesgo, o el riesgo más bajo para una recompensa dada. Para ver cómo funciona esto imagina que hay cuatro activos en el mundo \\(A, B, C\\) y \\(D\\) con recompensa y riesgo como se muestra en la figura 1 (ignore E por el momento). Si pudieras comprar alguno de estos (pero de momentos no te permiten más de uno), ¿cuál comprarías? eliges D? No, porque tiene el mismo riesgo que B pero menos recompensa, tiene la misma recompensa que como C pero pun mayor riesgo. Entonces, podemos descartar \\(D\\). ¿Qué pasa con B o C? Ambos son atractivos cuando se comparan con D, pero entre si no estan claro, B tiene un mayor riesgo, pero obtiene una mayor recompensa. Sin embargo, comparándolos a ambos con A vemos que no hay competencia, ya que A es la elección preferida. Si introducimos el activo E con el mismo riesgo que B y una recompensa mayor que A, entonces no podemos decir objetivamente cuál de A y E es mejor; esta es una elección subjetiva y depende de las preferencias de riesgo de un inversor.\n\n\n\nFigura 1: Riesgo y recompensa de cinco activos\n\n\nAhora suponga que tengo los dos activos A y E de la figura 2, y puedo combinar en mi cartera, ¿qué efecto tiene esto en mi riesgo/recompensa?\n\n\n\nFigura 2: Dos activos y cualquier combinación\n\n\nDe (2) y (3) tenemos\n\\[\\mu_{\\Pi} = W\\mu_{A} + (1-W)\\mu_{E}\\]\ny\n\\[\n\\sigma_{\\Pi}^2 = W^2\\sigma_{A}^2 + 2W(1-W)\\rho\\sigma_{A}\\sigma_{E} + (1-W)^2\\sigma_{E}^2\n\\]\nAquí \\(w\\) es el peso del activo A y, recordando que los pesos deben sumar uno, el peso del activo E es \\(1 - E\\).\nA medida que variamos W, también cambian el riesgo y la recompensa. La linea en el espacio de riesgo/recompensa que es parametrizada por W es una hipérbola, como se muestra en la figura 2. La parte de esta curva en negrita es eficiente, y es preferible al resto de la curva. Una ves más, las preferencias de riesgo de un individuo dirá dónde quiere estar en la curva audaz. Cuando una de las volatilidades es cero la línea se vuelvve recta. en cualquier lugar de la curva entre los dos puntos se requiere una posición larga en cada activo. Fuera de esta región, uno de los activos se vende al descubierto para financiar la compra del otro. Todo lo que sigue asume que podemos vender al descubierto tanto activo como queramos. Los resultados cambian ligeramente cuando hay restricciones.\nSi tenemos muchos activos en nuestra cartera, ya no tenemos una simple hipérbola para nuestros posibles perfiles de riesgo/recompensa; en cambio obtenemos algo como lo que se muestra en la Figura 3.\n\n\n\nFigura 3: Posibilidades de cartera y la frontera eficiente\n\n\nEsta figura ahora usa todo A, B, C, D y E, no solo A y E. Aunque B, C y D no son individualmente atractivos, bien pueden ser útiles en un portafolio, dependiendo de como se correlacionen, o no, con otras inversiones. En esta figura podemos ver la frontera eficiente marcada en negrita. Dado cualquier elección de cartera elegiríamos tener una que se encuentre en esta frontera eficiente."
  },
  {
    "objectID": "posts/port/index.html#incluir-una-inversión-sin-riesgo",
    "href": "posts/port/index.html#incluir-una-inversión-sin-riesgo",
    "title": "Portfolio management",
    "section": "Incluir una inversión sin riesgo",
    "text": "Incluir una inversión sin riesgo\nUna inversión sin riesgo que gana una tasa de rendimiento garantizada \\(r\\) sería el punto F en la Figura 3. Si se nos permite mantener este activo en nuestra cartera, dado que la volatilidad de este activo es cero, obtenemos la nueva frontera eficiente que es la línea recta en la Figura 3. El portafolio para el que la línea recta toca la frontera eficiente original se denomina cartera de mercado. La linea recta en sí misma se llama la línea del mercado de capitales.\n\nDonde quiero estar en la frontera eficiente?\nHabiendo encontrado la frontera eficiente, queremos aber dónde debemos estar. Esta es una elección personal, la frontera eficiente es objetiva, dados los datos, pero la “mejor” posición en ella es subjetiva.\nLa siguiente es una forma de interpretar el diagrama de riesgo/recompensa que puede ser útil en la elección de la mejor cartera.\nEl rendimiento de la cartera se distribuye normalmente porque está compuesto por activos que se distribuyen normalmente. Tiene media \\(\\mu\\) y desviación estándar \\(\\sigma\\) (he ignorado la dependencia del horizonte T). La pendiente de la línea que une la cartera con el activo libre de riesgo es\n\\[\ns = \\frac{\\mu_{\\Pi} - r}{\\sigma_{\\Pi}}\n\\]\nEsta es una cantidad importante; es una medida de la probabilidad de tenter un rendimiento que exceda r. Si \\(C(.)\\) es la función acumulada para la distribución normal estandarizada, entonces \\(C(s)\\) es la probabilidad de que el rendimiento en \\(\\Pi\\) sea al menos q \\(r\\). Mas generalmente\n\\[\nC\\left(\\begin{array}{0}\\frac{\\mu_{\\Pi} - r^*}{\\sigma_{\\Pi}}\\end{array}\\right)\n\\]\nes la probabilidad de que el rendimiento exceda \\(r^*\\). Esto sugiere que si queremos minimizar la posibilidad de una rentabilidad inferior a \\(r^*\\) debemos elegir la cartera del conjunto de fronteras eficientes, \\(\\Pi_{eff}\\) con el mayor valor de la pendiente\n\\[\n\\frac{\\mu_{\\Pi_{eff}} - r^*}{\\sigma_{\\Pi_{eff}}}\n\\]\nPor el contrario, si mantenemos la pendiente de esta línea fija en \\(s\\), entonces podemos decir que con una confianza de \\(C(s)\\) no perderemos más que\n\\[\n\\mu_{\\Pi_{eff}} - s\\sigma_{\\Pi_{eff}}\n\\]\nNuestra elección de cartera podría determinarse maximizando esta cantidad. Estas dos estrategías se muestran esquemáticamente en la Figura 5.\n\n\n\nFigura 5: Dos sencillas formas de elegir la mejor cartera eficiente\n\n\nNinguno de estos métodos da resultados satisfactorios cuando existe inversión libre de riesgo entre los activos y hay ventas cortas sin restricciones, ya que dan como resultado un endeudamiento infinito.\nOtra forma de elegir la cartera óptima es con la ayuda de una función de utilidad. Este enfoque es popular entre los economistas. En la Figura 6 muestro las curvas de indiferencia y la frontera eficiente.\n\n\n\nFigura 6: Frontera eficiente y las curvas de indiferencia\n\n\nLas curvas reciben este nombre porque representan lineas a las cual el inversionista es indiferente al trade-off riesgo/recompensa. Un inversionista quiere un alto rendimiento y riesgo bajo. Frente a las carteras A y B en la Figura, ve a A con bajo rendimiento y bajo riesgo, pero B tiene una mejor recompensa a costa de un mayor riesgo. El inversor es indiferente entre estos dos. Sin embargo, C es mejor que ambos, estando en una curva preferida."
  },
  {
    "objectID": "posts/port/index.html#markowitz-en-la-práctica",
    "href": "posts/port/index.html#markowitz-en-la-práctica",
    "title": "Portfolio management",
    "section": "Markowitz en la Práctica",
    "text": "Markowitz en la Práctica\nLas entradas al modelo de Markowitz son rendimientos esperados, volatilidades y correlaciones. Con \\(N\\) activos esto significa \\(N + N + N(N-1)/2\\) parámetros. La mayoría de estos no se pueden conocer con precisión (¿existen siquiera?); sólo las volatilidades son en absoluto confiable. Habiendo ingresado estos parámetros, debemos optimizar sobre todos los pesos de los activvos en la cartera: Elija un riesgo de cartera y encuentre los pesos que haqcen que el rendimiento de la cartera sea máximo sujeto a esta volatilidad. Este es un proceso que consume mucho tiempo computacionalmente a menos que uno solo tenga una pequeña cantidad de activos.\nEl problema con la implementación práctica de este modelo lo realizaré enm otro post que publicare posterioremente, usando Python. Por los momentos es importante comprender la lógica del modelo."
  },
  {
    "objectID": "posts/port/index.html#modelo-de-precios-de-activos-de-capital-capital-asset-pricing-model",
    "href": "posts/port/index.html#modelo-de-precios-de-activos-de-capital-capital-asset-pricing-model",
    "title": "Portfolio management",
    "section": "Modelo de Precios de Activos de Capital (Capital Asset Pricing Model)",
    "text": "Modelo de Precios de Activos de Capital (Capital Asset Pricing Model)\nAntes de discutir el modelo de fijación de precios de activos de capital o CAPM debemos introducir la idea del valor \\(\\beta\\). El parámetro \\(\\beta_i\\), de un activo en relación con una cartera \\(M\\) es la relación de la covarianza entre el rendimiento del valor y el rendimiento de la cartera a la varianza de la cartera. Del siguiente modo\n\\[\n\\beta_i = \\frac{Cov[R_iR_M]}{Var[R_M]}\n\\]\n\nEl Modelo de Indice Unico\nAhora construire un modelo de índices único y describiré las extenciones más adelante. Voy a relacionar el rendimiento de todos los activos al rendimiento de un índice representativo, \\(M\\). Este índice suele ser tomado como un índice bursátil de amplio rango en el modelo de índice único. Nosotros escribimos el rendimiento del i-ésimo activo como\n\\[\nR_i = \\alpha_i + \\beta_iR_M + \\epsilon_i\n\\]\nUsando esta representación podemos ver que el rendimiento de un activo se puede descomponer en tres partes:\n\nUna media constante\nUna parte aleatoria común con el índice \\(M\\) y,\nuna parte aleatoria no correlacionada con el índice, \\(\\epsilon_i\\).\n\nLa parte aleatoria \\(\\epsilon_i\\) es única para el i-ésimo activo, y tiene media cero. Observe cómo todos los activos están relacionados con el índice \\(M\\) pero son de contrario completamente sin correlación.\nEn la Figura 7 se muestra un gráfico de rendimiento de las acciones de Walt Disney frente a los rendimientos del S&P 500; \\(\\alpha\\) y \\(\\beta\\) se pueden determinar a partir de un análisis de regresión lineal. Los datos utilizados en este gráfico abarcaron desde enero de 1985 hasta casi finales de 1997.\n\n\n\nFigura 7: Rentabilidad de las acciones de Walt Disney frente a la rentabilidad del S&P 500.\n\n\nEl rendimiento esperado del índice se denotará por \\(\\mu_M\\) y su desviación estándar por \\(\\sigma_M\\). El rendimiento esperado del i-ésimo activo es entonces:\n\\[\n\\mu_i = \\alpha_i + \\beta_i\\mu_M\n\\]\ny la desviación estandar\n\\[\n\\sigma_i = \\sqrt{\\beta_i^2\\sigma_M^2 + e_i^2}\n\\]\ndonde \\(e_i\\) es la desviación estándar de \\(\\epsilon_i\\).\nSi tenemos una cartera de dichos activos, el rendimiento viene dado por\n\\[\n\\begin{eqnarray}\n\\frac{\\delta \\Pi}{\\Pi} = \\sum_{i=1}^N W_iR_i = \\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\alpha_i\\end{array}\\right) + R_M\\left(\\begin{array}{0} \\sum_{i=1}^N W_i\\beta_i\\end{array}\\right) + \\sum_{i=1}^N W_i\\epsilon_i\n\\end{eqnarray}\n\\]\nDe esto se sigue que\n\\[\n\\mu_\\Pi = \\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\alpha_i\\end{array}\\right) + E[R_M]\\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\beta_i\\end{array}\\right)\n\\]\nPodemos escribir\n\\[\n\\alpha_\\Pi = \\sum_{i=1}^NW_i\\alpha_i \\hspace{1cm}y \\hspace{1cm} \\beta_\\Pi = \\sum_{i=1}^NW_i\\beta_i\n\\]\nEntonces,\n\\[\n\\mu_\\Pi = \\alpha_\\Pi + \\beta_\\Pi\nE[R_M] = \\alpha_\\Pi + \\beta_\\Pi \\mu_M\\]\nDe manera similar, el riesgo se mide por\n\\[\n\\sigma_\\Pi = \\sqrt{\\sum_{i=1}^N\\sum_{j=1}^N W_iW_j\\beta_i\\beta_j\\sigma_M^2 + \\sum_{i=1}^N W_i^2 e_i^2}\n\\]\nSi los pesos son casi iguales, \\(N^{-1}\\), entonces los términos finales dentro de la raíz cuadrada también son \\(O(N^{-1})\\). Por lo tanto, esta expresión es, al orden principal como \\(N \\longrightarrow \\infty\\),\n\\[\n\\sigma_\\Pi = \\left|\\begin{array}{0}\\sum_{i=1}^N W_i\\beta_i\\end{array}\\right|\\sigma_M = \\left|\\begin{array}{0}\\beta_\\Pi\\end{array}\\right|\\sigma_M\n\\]\nObserve que la contribución de los no correlacionados a la cartera se desvanece a medida que aumentamos le número de activos en la cartera: El riesgo asociado con el \\(\\epsilon_s\\) se llama riesgo diversificable. El riesgo restante, que esta correlacionado con el índice, se denomina riesgo sistematico.\n\n\nElegir la Cartera Optima\nEl principal es el mismo que el modelo de Markowitz para la elección óptima de cartera. La diferencia es que hay muchos menos parámetros para ingresar, y el cálculo es mucho más rapido.\nEl procedimiento es el siguiente. Elija un valor para el rendimiento de la cartera \\(\\mu_\\Pi\\). Sujeto a esta restricción, minimizar \\(\\sigma_\\Pi\\). Repita esta minimización para diferentes rendimientos de carteera para obtener la frontera eficiente. La posición es esta curva es entonces una elección subjetiva."
  },
  {
    "objectID": "posts/port/index.html#medición-del-desempeño",
    "href": "posts/port/index.html#medición-del-desempeño",
    "title": "Portfolio management",
    "section": "Medición del Desempeño",
    "text": "Medición del Desempeño\nSi uno ha seguido una de las estratetias de asignación de activos, o simplemente ha negociado en instinto, ¿puede uno decir qué tan bien lo ha hecho? ¿Fueron los resultados sobresalientes deido a un extraño instinto natural, o los horribles resultados fueron simplemente mala suerte?\nEl rendimiento ideal sería uno en el que los rendimientos superaran la tasa libre de riesgo, pero en una moda consistente. No solo es importante obtener un alto rendimiento de la gestión de la cartera, pero uno debe lograr esto con la menor aleatoriedad posible.\nLas dos medidas más comunes de rendimiento por unidad de riesgo son\n\nRelación de Sharpe de recompensa a variabilidad y el\níndice de Treynor de recompensa a la volatilidad.\n\nEstos se definen como\n\\[\n\\begin{eqnarray}\nratio Sharpe &=& \\frac{\\mu_\\Pi - r}{\\sigma_\\Pi}\\\\[0.2cm]\nratio Treynor &=& \\frac{\\mu_\\Pi - r}{\\beta_\\Pi}\n\\end{eqnarray}\n\\]\nEn estos \\(\\mu\\) y \\(\\sigma\\) son el rendimiento realizado y la desviación estándar de la cartera durante el período. El \\(\\beta\\) es una medida de la volatilidad de la cartera. El ratio de Sharpe generalmente se usa cuando la cartera es la totalidad de la inversión de uno y el ratio de Treynor cuando se examina el rendimiento de un componente de la cartera de toda la empresa, digamos.\nCuando la cartera baja las dos medidas son las mismas (hasta un factor del mercado Desviación Estándar)\n\n\n\nFigura 8: un buen y un gerente (manager); mismos rendimientos, distintas volatilidades\n\n\nLa Figura 8 muestra el valor de la cartera frente al tiempo para un buen administrador y un mal administrador."
  },
  {
    "objectID": "posts/port/index.html#resumen",
    "href": "posts/port/index.html#resumen",
    "title": "Portfolio management",
    "section": "Resumen",
    "text": "Resumen\n\nLa gestión de carteras y la asignación de activos consisten en asumir riesgos a cambio de una recompensa.\nLas preguntas son, ¿como decidir cuánto riesgo tomar? ¿cómo obtener el mejor rendimiento? Pero la teoría de los derivados se basa en no correr ningún riesgo en absoluto, por lo que he dedicado tiempo a gestión de cartera en este post.\nExiste tanta incertidumbre en el tema de las finanzas que la eliminación del riesgo es casi imposible y las ideas detrás de la gestión de carteras deben ser apreciadas por cualquier persona involucrada en derivados."
  },
  {
    "objectID": "posts/welcome - copia/index.html",
    "href": "posts/welcome - copia/index.html",
    "title": "Portfolio management",
    "section": "",
    "text": "La teoría de la fijación de precios de derivados es una teoría de rendimientos deterministas: cubrimos nuestros derivados con el subyacente para eliminar el riesgo, y nuestra cartera libre de riesgo resultante gana la tasa de interés libre de riesgo. Los bancos ganan dinero con este proceso de cobertura; venden algo por un poco más de lo que vale y cubrir el riesgo para obtener una ganancia garantizada. Los gestores de fondos compran y venden activos (incluidos los derivados) con el objetivo de superar la tasa de rendimiento del banco. Al hacerlo, se arriesgan. En este artículo explico algunas de la teorías detrás del riesgo y la recompensa de la inversión y, como optimizar una cartera para obtener el mejor valor por dinero."
  },
  {
    "objectID": "posts/welcome - copia/index.html#descripción-general-del-modelo",
    "href": "posts/welcome - copia/index.html#descripción-general-del-modelo",
    "title": "Modelo Prophet de Facebook",
    "section": "Descripción General del Modelo",
    "text": "Descripción General del Modelo\nFacebook Prophet es un modelo y una biblioteca que proporciona características tanto de modelos lineales generalizados (MLG) como de modelos aditivos (MA), principalmente extendiendo el MLG mediante el uso de funciones de suavizado no lineal. Fue especificado por Taylor y Letham en 2017.\nProphet es un software de código abierto lanzado por el equipo Core Data Science de Facebook. Está disponible para su descarga en CRAN y PyPI. En esta ocasión usaremos el lenguaje R para implementar el modelo, sin embargo, tu puedes hacerlo en Python si es de tu preferencia.\nProphet funciona mejor con series temporales que tienen fuertes efectos estacionales y varias temporadas de datos históricos. Prophet es resistente a los datos faltantes y los cambios en la tendencia, y por lo general maneja bien los valores atípicos. Prophet esta diseñado especificamente para la predicción de series temporales de negocios.\nSu modelo aditivo que consta de cuatro componentes, esta dado por:\n\\[\ny(t) = g(t) + s(t) + h(t) + \\epsilon_{t}\n\\]\ndonde,\n\n\\(g(t)\\): Representa la tendencia y el objetivo es capturar la tendencia de la serie. Por ejemplo, es probable que la cantidad de vistas de anuncios de Facebook aumente con el tiempo a medida que más personas se unen a la red. Pero, ¿cuál sería la función exacta del aumento?\n\\(s(t)\\): Es el componente de Estacionalidad. El número de anuncios también puede depender de la temporada. Por ejemplo, en el hemisferio norte durante los meses de verano, es probable que las personas pasen más tiempo al aire libre y menos tiempo frente a sus computadoras. Tales fluctuaciones pueden ser muy diferentes para diferentes series temporales de negocios. El segundo componente es, por lo tanto, una función que modela las tendencias estacionales.\n\\(h(t)\\): Representa los efectos de las vaciones. Usamos la información para días festivos que tienen claro impacto en la mayoria de las series temporales comerciales. Tenga en cuenta que las vaciones varían entre años, países, etc. Y, por lo tanto, la información debe proporcionarse explícitamente al modelo.\n\\(\\epsilon_{t}\\): Es el término de error. Representa fluctuaciones aleatorias que el modelo no puede explicar. Como de costumbre, se supone que \\(\\epsilon_{t}\\) sigue una distribución \\(N(0,1)\\) con media cero y varianza desconocida \\(\\sigma\\) que debe derivarse de los datos ."
  },
  {
    "objectID": "posts/welcome - copia/index.html#hiperparámetros",
    "href": "posts/welcome - copia/index.html#hiperparámetros",
    "title": "Modelo Prophet de Facebook",
    "section": "Hiperparámetros",
    "text": "Hiperparámetros\nHay varios parámetros personalizables en la implementación de Facebook Prophet (revisar), siendo los principales:\n\nPuntos de cambio: definen los cambios de tendencia. Estos pueden ser encontrados por el propio algoritmo o también pueden ser definidos y ajustados por el analista.\nEstacionalidad: define las funciones periódicas que pueden afectar a la serie temporal. De forma predeterminada, Prophet considera la estacionalidad anual, semanal y diaria e intenta encontrar tendencias que representan esos efectos periódicos en los datos.\nDías festivos: los días especiales (días festivos o cualquier otro evento recurrente) también pueden ser modelados por el modelo aditivo.\n\nEn R, se usa la API de ajuste de modelo normal. Proporcionamos una función prophet que realiza el ajuste y devuelve un objeto de modelo. Posteriormeente usted puede llamar a la función predict y plot en este objeto modelo."
  },
  {
    "objectID": "posts/welcome - copia/index.html#datos-y-preparación",
    "href": "posts/welcome - copia/index.html#datos-y-preparación",
    "title": "Modelo Prophet de Facebook",
    "section": "Datos y Preparación",
    "text": "Datos y Preparación\nLos datos que utilizaremos los encontramos en Yahoo! Finance. Así como Python tiene un paquete para importar datos directamente de Yahoo Finance, R también cuenta con sus paquetes particular que nos permiten realizar una tarea similar. Necesitamos los siguiente paquetes:\n\nlibrary(TTR)\nlibrary(quantmod)\n\nLoading required package: xts\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nSi aún no los tienes instalados sugiero los instales usando install.packages(\"name paquete\"). Muy bien, ahora si estamos listos para poder extraer nuestros datos de yahoo finance y para ello usaremos la funcion getSymbols del paquete quantmod. Veamos,\n\ndf <- getSymbols('HNL=X',src = 'yahoo',\n                 from = \"2010-01-01\",\n                 to = \"2022-12-20\",\n                 auto.assign = FALSE)\n\nTenga en cuenta que from =  \"2010-01-01\" y to = \"2022-12-20\" nos ayudan a indicar desde que fecha quiero comenzar a tomar mis datos y hasta que fecha quiero tomarlos. Además, auto.assign = FALSE indica a getSymbols que devuelva los datos.\nAhora, conozcamos nuestros datos\n\nhead(df)\n\n           HNL=X.Open HNL=X.High HNL=X.Low HNL=X.Close HNL=X.Volume\n2010-01-04     18.690     18.691    18.517      18.518            0\n2010-01-05     18.550     18.550    18.550      18.550            0\n2010-01-06     18.572     18.645    18.544      18.545            0\n2010-01-07     18.451     18.550    18.451      18.539            0\n2010-01-08     18.556     18.556    18.556      18.556            0\n2010-01-11     18.550     18.550    18.550      18.550            0\n           HNL=X.Adjusted\n2010-01-04         18.518\n2010-01-05         18.550\n2010-01-06         18.545\n2010-01-07         18.539\n2010-01-08         18.556\n2010-01-11         18.550\n\n\nDe estos datos únicamente usaremos el valor de cierre (HNL=X.Close) de manera diaria del lempira hondureño contra el dólar, para enfocarnos solo en esos datos, primero convertiremos nuestro conjunto de datos df en un dataframe, dado que inicialmente es un objeto de tipo xts,\n\nclass(df)\n\n[1] \"xts\" \"zoo\"\n\n\npara realizar el cambio a un dataframe, considere la siguiente función\n\nxts_to_datframe<-function(data_xts){\n  df_t<-data.frame(fecha=(index(data_xts)),\n                   value=coredata(data_xts))\n  colnames(df_t)<-c(\"ds\", \"y\")\n  df_t\n}\n\nTiene que tener cuidado con el nombramiento de sus columnas, dado que prophet reconoce unicamente marcos de datos con columnas nombras como ds y y, qu contienen la fecha y el valor numérico de sus observaciones respectivamente. Con esto en mente, pasemos a transformar df a un objeto de clase dataframe por medio de la función que construimos previamente:\n\nHNL <- xts_to_datframe(df$`HNL=X.Close`) \nclass(HNL)\n\n[1] \"data.frame\"\n\n\nPuede apreciar que ya tenemos nuestro marco de datos como un dataframe, y estamos listos para comenzar a crear nuestro modelo."
  },
  {
    "objectID": "posts/welcome - copia/index.html#implementación-del-modelo",
    "href": "posts/welcome - copia/index.html#implementación-del-modelo",
    "title": "Modelo Prophet de Facebook",
    "section": "Implementación del Modelo",
    "text": "Implementación del Modelo\nPrimero visualicemos nuestros datos\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.5.0 \n✔ readr   2.1.2      ✔ forcats 0.5.1 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::first()  masks xts::first()\n✖ dplyr::lag()    masks stats::lag()\n✖ dplyr::last()   masks xts::last()\n\nlibrary(ggplot2)\n\nHNL %>% ggplot(aes(x = ds, y = y))+\n  geom_line()+\n  theme_minimal()+\n   labs(title = 'Datos Historicos del Tipo de Cambio del USD/HNL',\n       subtitle = '2010 - 2022',\n       x = 'Fecha',\n       y = 'HNL',\n       caption = 'Elaboracion propia con datos de yahoo finance')\n\n\n\n\n\nlibrary(prophet)\n\nLoading required package: Rcpp\n\n\nLoading required package: rlang\n\n\n\nAttaching package: 'rlang'\n\n\nThe following objects are masked from 'package:purrr':\n\n    %@%, as_function, flatten, flatten_chr, flatten_dbl, flatten_int,\n    flatten_lgl, flatten_raw, invoke, splice\n\nm <- prophet(HNL,daily.seasonality = TRUE)\n\nfuture <- make_future_dataframe(m,periods = 3,freq = 'day')\ntail(future)\n\n             ds\n3380 2022-12-16\n3381 2022-12-19\n3382 2022-12-20\n3383 2022-12-21\n3384 2022-12-22\n3385 2022-12-23\n\n\n\nforecast <- predict(m, future)\n\ndyplot.prophet(m, forecast)\n\n\n\n\n\nDe la figura previa,\n\nLos puntos negros representan medidas reales\nLa linea azul el pronóstico de Prophet\nLa banda azul representa el intervalo de incertidumbre"
  },
  {
    "objectID": "posts/welcome - copia/index.html#desglose-del-pronóstico",
    "href": "posts/welcome - copia/index.html#desglose-del-pronóstico",
    "title": "Modelo Prophet de Facebook",
    "section": "Desglose del Pronóstico",
    "text": "Desglose del Pronóstico\nSi bien el pronóstico arroja muchas cosas, podemos centrarnos en algunas como:\n\nds fecha que se pronostica\nyhat predicción para el valor y (tipo de cambio) ese día en particular.\nyhat_lower valor esperado más bajo para el rango del valor y previsto ese día\nyhat_upper valor esperado más alto para el rango de valor y previsto de ese día\n\nCon tail() podemos ver la salida de los últimos días pronosticados los cuales son 21, 22 y 23 de diciembre 2022.\n\ntail(forecast[c('ds', 'yhat', 'yhat_lower', 'yhat_upper')])\n\n             ds     yhat yhat_lower yhat_upper\n3380 2022-12-16 24.10924   23.36855   24.83427\n3381 2022-12-19 24.04473   23.29132   24.77730\n3382 2022-12-20 24.11075   23.36487   24.87835\n3383 2022-12-21 24.08755   23.36138   24.77045\n3384 2022-12-22 24.12633   23.45007   24.84871\n3385 2022-12-23 24.13436   23.35588   24.85642\n\n\nSegun nuestros resultados, nuestro modelo nos ve obteniendo para el día 21 de diciembre entre 23.35901 (yhat_lower) y 24.83438 (yhat_upper) lempiras por un dolar de EE.UU.\nPara entender el pronóstico más a detalle, podemos gráficar sus componentes con:\n\nprophet_plot_components(m,forecast)\n\n\n\n\nRecuerde que el fin de este post, no es abogar por el uso indiscriminado de Prophet como el mejor modelo para pronosticar el tipo de cambio hondureño vs el dólar. Espero hayas conocido las generalidades de este modelo y su utilidad en el ambito predictivo."
  },
  {
    "objectID": "posts/welcome - copia/index.html#diversificación",
    "href": "posts/welcome - copia/index.html#diversificación",
    "title": "Portfolio management",
    "section": "Diversificación",
    "text": "Diversificación\nIntroduciremos algo de notación y muestro el efecto de la diversificación sobre la rentabilidad de la cartera. Supongamos que tenemos una cartera de \\(N\\) activos. El valor hoy del i-ésimo activo es \\(S_i\\) y su rendimiento aleatorio es \\(R_i\\) sobre nuestro horizonte de tiempo \\(T\\). Las \\(R_i \\sim N(\\mu_iT, \\sigma_i\\sqrt{T})\\). La correlación entre los rendimientos de la i-ésima y j-ésimo activo es \\(\\rho_{ij}\\) (con \\(\\rho_{ii} = 1\\)).\nLos parámetros \\(\\mu, \\sigma\\) y \\(\\rho\\) corresponden a la media, volatilidad y correlación a la que estamos acostumbrados. Tenga en cuenta la escala con el horizonte de tiempo.\nSi tenemos \\(w_i\\) del i-ésimo activo, entonces nuestra cartera tiene valor\n\\[\n\\Pi = \\sum_{i=1}^{N} w_iS_i\n\\]\nAl final de nuestro horizonte temporal, el valor es\n\\[\\Pi + \\delta\\Pi = \\sum_{i=1}^{N} w_iS_i(1+R_i)\\]\nPodemos escribir el cambio relativo en el valor de la cartera como\n\\[\n\\frac{\\delta\\Pi}{\\Pi} = \\sum_{i=1}^N W_iR_i\\hspace{1.5cm} (1)\n\\]\ndonde\n\\[\nW_i = \\frac{w_iS_i}{\\sum_{i=1}^N w_iS_i}\n\\]\nLos pesos \\(W_i\\) suman uno.\nA partir de (1) es sencillo calcular el rendimiento esperado de la cartera\n\\[\n\\mu_{\\Pi} = \\frac{1}{T}E\\left[\\begin{array}{c}\\frac{\\delta\\Pi}{\\Pi}\\end{array}\\right] = \\sum_{i=1}^{N}W_i \\mu_i\\hspace{6cm} (2)\n\\]\nY la desviación estándar de los retornos son\n\\[\n\\sigma_{\\Pi} = \\frac{1}{\\sqrt{T}}\\sqrt{var\\left[\\begin{array}{0} \\frac{\\delta \\Pi}{\\Pi}\\end{array}\\right]} = \\sqrt{\\sum_{i=1}^{N}\\sum_{j=1}^N W_iW_j \\rho_{ij}\\sigma_i\\sigma_j}\\hspace{1.5cm} (3)\n\\]\nEn ellos hemos relacionado los parámetros de los activos individuales con la rentabilidad esperada y la desviación estándar de toda la cartera.\nSupongamos que tenemos activos en nuestra cartera que no están correlacionados, es decir, \\(\\rho_{ij} = 0\\), \\(i = j\\). Para simplificar las cosas, suponga que tienen el mismo peso, de modo que \\(W_i = \\frac{1}{N}\\). El rendimiento esperado de la cartera está representado por\n\\[\n\\mu_{\\Pi} = \\frac{1}{N}\\sum_{i=1}^N \\mu_i\n\\]\nEl promedio de los rendimientos esperados de todos los activos, y la volatilidad se convierte en\n\\[\n\\sigma_{\\Pi} = \\sqrt{\\frac{1}{N^2}\\sum_{i=1}^N \\sigma_i^2}\n\\]\nEsta volatilidad es \\(O(N^{-1/2})\\) ya que hay \\(N\\) términos en la suma. A medida que aumentamos el número de activos en cartera, la desviación estándar de los rendimientos tiende a cero.\nSupongamos que todos los activos no están correlacionados, pero veremos algo similar cuando describa el Modelo de fijación de precios de activos de capital; la diversificación reduce la volatilidad sin perjudicar las expectativas de rendimientos.\nAhora me voy a referir a la volatilidad o desviación estándar como riesgo, algo malo que debe evitarse (dentro de lo razonable), y el rendimiento esperado como recompensa, algo bueno que queremos tanto como sea posible."
  },
  {
    "objectID": "posts/welcome - copia/index.html#teoría-moderna-del-portafolio",
    "href": "posts/welcome - copia/index.html#teoría-moderna-del-portafolio",
    "title": "Portfolio management",
    "section": "Teoría Moderna del Portafolio",
    "text": "Teoría Moderna del Portafolio\nPödemos usar el marco anterior para discutir la “mejor” cartera. La definición de “mejor” fue abordada con mucho éxito por el Premio Nobel Harry Markowitz. Su modelo proporciona una manera de definir carteras que sean eficientes.\nUna cartera eficiente es aquella que tiene la recompensa más alta para un nivel de riesgo, o el riesgo más bajo para una recompensa dada. Para ver cómo funciona esto imagina que hay cuatro activos en el mundo \\(A, B, C\\) y \\(D\\) con recompensa y riesgo como se muestra en la figura 1 (ignore E por el momento). Si pudieras comprar alguno de estos (pero de momentos no te permiten más de uno), ¿cuál comprarías? eliges D? No, porque tiene el mismo riesgo que B pero menos recompensa, tiene la misma recompensa que como C pero pun mayor riesgo. Entonces, podemos descartar \\(D\\). ¿Qué pasa con B o C? Ambos son atractivos cuando se comparan con D, pero entre si no estan claro, B tiene un mayor riesgo, pero obtiene una mayor recompensa. Sin embargo, comparándolos a ambos con A vemos que no hay competencia, ya que A es la elección preferida. Si introducimos el activo E con el mismo riesgo que B y una recompensa mayor que A, entonces no podemos decir objetivamente cuál de A y E es mejor; esta es una elección subjetiva y depende de las preferencias de riesgo de un inversor.\n\n\n\nFigura 1: Riesgo y recompensa de cinco activos\n\n\nAhora suponga que tengo los dos activos A y E de la figura 2, y puedo combinar en mi cartera, ¿qué efecto tiene esto en mi riesgo/recompensa?\n\n\n\nFigura 2: Dos activos y cualquier combinación\n\n\nDe (2) y (3) tenemos\n\\[\\mu_{\\Pi} = W\\mu_{A} + (1-W)\\mu_{E}\\]\ny\n\\[\n\\sigma_{\\Pi}^2 = W^2\\sigma_{A}^2 + 2W(1-W)\\rho\\sigma_{A}\\sigma_{E} + (1-W)^2\\sigma_{E}^2\n\\]\nAquí \\(w\\) es el peso del activo A y, recordando que los pesos deben sumar uno, el peso del activo E es \\(1 - E\\).\nA medida que variamos W, también cambian el riesgo y la recompensa. La linea en el espacio de riesgo/recompensa que es parametrizada por W es una hipérbola, como se muestra en la figura 2. La parte de esta curva en negrita es eficiente, y es preferible al resto de la curva. Una ves más, las preferencias de riesgo de un individuo dirá dónde quiere estar en la curva audaz. Cuando una de las volatilidades es cero la línea se vuelvve recta. en cualquier lugar de la curva entre los dos puntos se requiere una posición larga en cada activo. Fuera de esta región, uno de los activos se vende al descubierto para financiar la compra del otro. Todo lo que sigue asume que podemos vender al descubierto tanto activo como queramos. Los resultados cambian ligeramente cuando hay restricciones.\nSi tenemos muchos activos en nuestra cartera, ya no tenemos una simple hipérbola para nuestros posibles perfiles de riesgo/recompensa; en cambio obtenemos algo como lo que se muestra en la Figura 3.\n\n\n\nFigura 3: Posibilidades de cartera y la frontera eficiente\n\n\nEsta figura ahora usa todo A, B, C, D y E, no solo A y E. Aunque B, C y D no son individualmente atractivos, bien pueden ser útiles en un portafolio, dependiendo de como se correlacionen, o no, con otras inversiones. En esta figura podemos ver la frontera eficiente marcada en negrita. Dado cualquier elección de cartera elegiríamos tener una que se encuentre en esta frontera eficiente."
  },
  {
    "objectID": "posts/welcome - copia/index.html#incluir-una-inversión-sin-riesgo",
    "href": "posts/welcome - copia/index.html#incluir-una-inversión-sin-riesgo",
    "title": "Portfolio management",
    "section": "Incluir una inversión sin riesgo",
    "text": "Incluir una inversión sin riesgo\nUna inversión sin riesgo que gana una tasa de rendimiento garantizada \\(r\\) sería el punto F en la Figura 3. Si se nos permite mantener este activo en nuestra cartera, dado que la volatilidad de este activo es cero, obtenemos la nueva frontera eficiente que es la línea recta en la Figura 3. El portafolio para el que la línea recta toca la frontera eficiente original se denomina cartera de mercado. La linea recta en sí misma se llama la línea del mercado de capitales.\n\nDonde quiero estar en la frontera eficiente?\nHabiendo encontrado la frontera eficiente, queremos aber dónde debemos estar. Esta es una elección personal, la frontera eficiente es objetiva, dados los datos, pero la “mejor” posición en ella es subjetiva.\nLa siguiente es una forma de interpretar el diagrama de riesgo/recompensa que puede ser útil en la elección de la mejor cartera.\nEl rendimiento de la cartera se distribuye normalmente porque está compuesto por activos que se distribuyen normalmente. Tiene media \\(\\mu\\) y desviación estándar \\(\\sigma\\) (he ignorado la dependencia del horizonte T). La pendiente de la línea que une la cartera con el activo libre de riesgo es\n\\[\ns = \\frac{\\mu_{\\Pi} - r}{\\sigma_{\\Pi}}\n\\]\nEsta es una cantidad importante; es una medida de la probabilidad de tenter un rendimiento que exceda r. Si \\(C(.)\\) es la función acumulada para la distribución normal estandarizada, entonces \\(C(s)\\) es la probabilidad de que el rendimiento en \\(\\Pi\\) sea al menos q \\(r\\). Mas generalmente\n\\[\nC\\left(\\begin{array}{0}\\frac{\\mu_{\\Pi} - r^*}{\\sigma_{\\Pi}}\\end{array}\\right)\n\\]\nes la probabilidad de que el rendimiento exceda \\(r^*\\). Esto sugiere que si queremos minimizar la posibilidad de una rentabilidad inferior a \\(r^*\\) debemos elegir la cartera del conjunto de fronteras eficientes, \\(\\Pi_{eff}\\) con el mayor valor de la pendiente\n\\[\n\\frac{\\mu_{\\Pi_{eff}} - r^*}{\\sigma_{\\Pi_{eff}}}\n\\]\nPor el contrario, si mantenemos la pendiente de esta línea fija en \\(s\\), entonces podemos decir que con una confianza de \\(C(s)\\) no perderemos más que\n\\[\n\\mu_{\\Pi_{eff}} - s\\sigma_{\\Pi_{eff}}\n\\]\nNuestra elección de cartera podría determinarse maximizando esta cantidad. Estas dos estrategías se muestran esquemáticamente en la Figura 5.\n\n\n\nFigura 5: Dos sencillas formas de elegir la mejor cartera eficiente\n\n\nNinguno de estos métodos da resultados satisfactorios cuando existe inversión libre de riesgo entre los activos y hay ventas cortas sin restricciones, ya que dan como resultado un endeudamiento infinito.\nOtra forma de elegir la cartera óptima es con la ayuda de una función de utilidad. Este enfoque es popular entre los economistas. En la Figura 6 muestro las curvas de indiferencia y la frontera eficiente.\n\n\n\nFigura 6: Frontera eficiente y las curvas de indiferencia\n\n\nLas curvas reciben este nombre porque representan lineas a las cual el inversionista es indiferente al trade-off riesgo/recompensa. Un inversionista quiere un alto rendimiento y riesgo bajo. Frente a las carteras A y B en la Figura, ve a A con bajo rendimiento y bajo riesgo, pero B tiene una mejor recompensa a costa de un mayor riesgo. El inversor es indiferente entre estos dos. Sin embargo, C es mejor que ambos, estando en una curva preferida."
  },
  {
    "objectID": "posts/welcome - copia/index.html#markowitz-en-la-práctica",
    "href": "posts/welcome - copia/index.html#markowitz-en-la-práctica",
    "title": "Portfolio management",
    "section": "Markowitz en la Práctica",
    "text": "Markowitz en la Práctica\nLas entradas al modelo de Markowitz son rendimientos esperados, volatilidades y correlaciones. Con \\(N\\) activos esto significa \\(N + N + N(N-1)/2\\) parámetros. La mayoría de estos no se pueden conocer con precisión (¿existen siquiera?); sólo las volatilidades son en absoluto confiable. Habiendo ingresado estos parámetros, debemos optimizar sobre todos los pesos de los activvos en la cartera: Elija un riesgo de cartera y encuentre los pesos que haqcen que el rendimiento de la cartera sea máximo sujeto a esta volatilidad. Este es un proceso que consume mucho tiempo computacionalmente a menos que uno solo tenga una pequeña cantidad de activos.\nEl problema con la implementación práctica de este modelo lo realizaré enm otro post que publicare posterioremente, usando Python. Por los momentos es importante comprender la lógica del modelo."
  },
  {
    "objectID": "posts/welcome - copia/index.html#modelo-de-precios-de-activos-de-capital-capital-asset-pricing-model",
    "href": "posts/welcome - copia/index.html#modelo-de-precios-de-activos-de-capital-capital-asset-pricing-model",
    "title": "Portfolio management",
    "section": "Modelo de Precios de Activos de Capital (Capital Asset Pricing Model)",
    "text": "Modelo de Precios de Activos de Capital (Capital Asset Pricing Model)\nAntes de discutir el modelo de fijación de precios de activos de capital o CAPM debemos introducir la idea del valor \\(\\beta\\). El parámetro \\(\\beta_i\\), de un activo en relación con una cartera \\(M\\) es la relación de la covarianza entre el rendimiento del valor y el rendimiento de la cartera a la varianza de la cartera. Del siguiente modo\n\\[\n\\beta_i = \\frac{Cov[R_iR_M]}{Var[R_M]}\n\\]\n\nEl Modelo de Indice Unico\nAhora construire un modelo de índices único y describiré las extenciones más adelante. Voy a relacionar el rendimiento de todos los activos al rendimiento de un índice representativo, \\(M\\). Este índice suele ser tomado como un índice bursátil de amplio rango en el modelo de índice único. Nosotros escribimos el rendimiento del i-ésimo activo como\n\\[\nR_i = \\alpha_i + \\beta_iR_M + \\epsilon_i\n\\]\nUsando esta representación podemos ver que el rendimiento de un activo se puede descomponer en tres partes:\n\nUna media constante\nUna parte aleatoria común con el índice \\(M\\) y,\nuna parte aleatoria no correlacionada con el índice, \\(\\epsilon_i\\).\n\nLa parte aleatoria \\(\\epsilon_i\\) es única para el i-ésimo activo, y tiene media cero. Observe cómo todos los activos están relacionados con el índice \\(M\\) pero son de contrario completamente sin correlación.\nEn la Figura 7 se muestra un gráfico de rendimiento de las acciones de Walt Disney frente a los rendimientos del S&P 500; \\(\\alpha\\) y \\(\\beta\\) se pueden determinar a partir de un análisis de regresión lineal. Los datos utilizados en este gráfico abarcaron desde enero de 1985 hasta casi finales de 1997.\n\n\n\nFigura 7: Rentabilidad de las acciones de Walt Disney frente a la rentabilidad del S&P 500.\n\n\nEl rendimiento esperado del índice se denotará por \\(\\mu_M\\) y su desviación estándar por \\(\\sigma_M\\). El rendimiento esperado del i-ésimo activo es entonces:\n\\[\n\\mu_i = \\alpha_i + \\beta_i\\mu_M\n\\]\ny la desviación estandar\n\\[\n\\sigma_i = \\sqrt{\\beta_i^2\\sigma_M^2 + e_i^2}\n\\]\ndonde \\(e_i\\) es la desviación estándar de \\(\\epsilon_i\\).\nSi tenemos una cartera de dichos activos, el rendimiento viene dado por\n\\[\n\\begin{eqnarray}\n\\frac{\\delta \\Pi}{\\Pi} = \\sum_{i=1}^N W_iR_i = \\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\alpha_i\\end{array}\\right) + R_M\\left(\\begin{array}{0} \\sum_{i=1}^N W_i\\beta_i\\end{array}\\right) + \\sum_{i=1}^N W_i\\epsilon_i\n\\end{eqnarray}\n\\]\nDe esto se sigue que\n\\[\n\\mu_\\Pi = \\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\alpha_i\\end{array}\\right) + E[R_M]\\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\beta_i\\end{array}\\right)\n\\]\nPodemos escribir\n\\[\n\\alpha_\\Pi = \\sum_{i=1}^NW_i\\alpha_i \\hspace{1cm}y \\hspace{1cm} \\beta_\\Pi = \\sum_{i=1}^NW_i\\beta_i\n\\]\nEntonces,\n\\[\n\\mu_\\Pi = \\alpha_\\Pi + \\beta_\\Pi\nE[R_M] = \\alpha_\\Pi + \\beta_\\Pi \\mu_M\\]\nDe manera similar, el riesgo se mide por\n\\[\n\\sigma_\\Pi = \\sqrt{\\sum_{i=1}^N\\sum_{j=1}^N W_iW_j\\beta_i\\beta_j\\sigma_M^2 + \\sum_{i=1}^N W_i^2 e_i^2}\n\\]\nSi los pesos son casi iguales, \\(N^{-1}\\), entonces los términos finales dentro de la raíz cuadrada también son \\(O(N^{-1})\\). Por lo tanto, esta expresión es, al orden principal como \\(N \\longrightarrow \\infty\\),\n\\[\n\\sigma_\\Pi = \\left|\\begin{array}{0}\\sum_{i=1}^N W_i\\beta_i\\end{array}\\right|\\sigma_M = \\left|\\begin{array}{0}\\beta_\\Pi\\end{array}\\right|\\sigma_M\n\\]\nObserve que la contribución de los no correlacionados a la cartera se desvanece a medida que aumentamos le número de activos en la cartera: El riesgo asociado con el \\(\\epsilon_s\\) se llama riesgo diversificable. El riesgo restante, que esta correlacionado con el índice, se denomina riesgo sistematico.\n\n\nElegir la Cartera Optima\nEl principal es el mismo que el modelo de Markowitz para la elección óptima de cartera. La diferencia es que hay muchos menos parámetros para ingresar, y el cálculo es mucho más rapido.\nEl procedimiento es el siguiente. Elija un valor para el rendimiento de la cartera \\(\\mu_\\Pi\\). Sujeto a esta restricción, minimizar \\(\\sigma_\\Pi\\). Repita esta minimización para diferentes rendimientos de carteera para obtener la frontera eficiente. La posición es esta curva es entonces una elección subjetiva."
  },
  {
    "objectID": "posts/welcome - copia/index.html#medición-del-desempeño",
    "href": "posts/welcome - copia/index.html#medición-del-desempeño",
    "title": "Portfolio management",
    "section": "Medición del Desempeño",
    "text": "Medición del Desempeño\nSi uno ha seguido una de las estratetias de asignación de activos, o simplemente ha negociado en instinto, ¿puede uno decir qué tan bien lo ha hecho? ¿Fueron los resultados sobresalientes deido a un extraño instinto natural, o los horribles resultados fueron simplemente mala suerte?\nEl rendimiento ideal sería uno en el que los rendimientos superaran la tasa libre de riesgo, pero en una moda consistente. No solo es importante obtener un alto rendimiento de la gestión de la cartera, pero uno debe lograr esto con la menor aleatoriedad posible.\nLas dos medidas más comunes de rendimiento por unidad de riesgo son\n\nRelación de Sharpe de recompensa a variabilidad y el\níndice de Treynor de recompensa a la volatilidad.\n\nEstos se definen como\n\\[\n\\begin{eqnarray}\nratio Sharpe &=& \\frac{\\mu_\\Pi - r}{\\sigma_\\Pi}\\\\[0.2cm]\nratio Treynor &=& \\frac{\\mu_\\Pi - r}{\\beta_\\Pi}\n\\end{eqnarray}\n\\]\nEn estos \\(\\mu\\) y \\(\\sigma\\) son el rendimiento realizado y la desviación estándar de la cartera durante el período. El \\(\\beta\\) es una medida de la volatilidad de la cartera. El ratio de Sharpe generalmente se usa cuando la cartera es la totalidad de la inversión de uno y el ratio de Treynor cuando se examina el rendimiento de un componente de la cartera de toda la empresa, digamos.\nCuando la cartera baja las dos medidas son las mismas (hasta un factor del mercado Desviación Estándar)\n\n\n\nFigura 8: un buen y un gerente (manager); mismos rendimientos, distintas volatilidades\n\n\nLa Figura 8 muestra el valor de la cartera frente al tiempo para un buen administrador y un mal administrador."
  },
  {
    "objectID": "posts/welcome - copia/index.html#resumen",
    "href": "posts/welcome - copia/index.html#resumen",
    "title": "Portfolio management",
    "section": "Resumen",
    "text": "Resumen\n\nLa gestión de carteras y la asignación de activos consisten en asumir riesgos a cambio de una recompensa.\nLas preguntas son, ¿como decidir cuánto riesgo tomar? ¿cómo obtener el mejor rendimiento? Pero la teoría de los derivados se basa en no correr ningún riesgo en absoluto, por lo que he dedicado tiempo a gestión de cartera en este post.\nExiste tanta incertidumbre en el tema de las finanzas que la eliminación del riesgo es casi imposible y las ideas detrás de la gestión de carteras deben ser apreciadas por cualquier persona involucrada en derivados."
  },
  {
    "objectID": "posts/port_mg/index.html",
    "href": "posts/port_mg/index.html",
    "title": "Portfolio management",
    "section": "",
    "text": "La teoría de la fijación de precios de derivados es una teoría de rendimientos deterministas: cubrimos nuestros derivados con el subyacente para eliminar el riesgo, y nuestra cartera libre de riesgo resultante gana la tasa de interés libre de riesgo. Los bancos ganan dinero con este proceso de cobertura; venden algo por un poco más de lo que vale y cubrir el riesgo para obtener una ganancia garantizada. Los gestores de fondos compran y venden activos (incluidos los derivados) con el objetivo de superar la tasa de rendimiento del banco. Al hacerlo, se arriesgan. En este artículo explico algunas de la teorías detrás del riesgo y la recompensa de la inversión y, como optimizar una cartera para obtener el mejor valor por dinero."
  },
  {
    "objectID": "posts/port_mg/index.html#diversificación",
    "href": "posts/port_mg/index.html#diversificación",
    "title": "Portfolio management",
    "section": "Diversificación",
    "text": "Diversificación\nIntroduciremos algo de notación y muestro el efecto de la diversificación sobre la rentabilidad de la cartera. Supongamos que tenemos una cartera de \\(N\\) activos. El valor hoy del i-ésimo activo es \\(S_i\\) y su rendimiento aleatorio es \\(R_i\\) sobre nuestro horizonte de tiempo \\(T\\). Las \\(R_i \\sim N(\\mu_iT, \\sigma_i\\sqrt{T})\\). La correlación entre los rendimientos de la i-ésima y j-ésimo activo es \\(\\rho_{ij}\\) (con \\(\\rho_{ii} = 1\\)).\nLos parámetros \\(\\mu, \\sigma\\) y \\(\\rho\\) corresponden a la media, volatilidad y correlación a la que estamos acostumbrados. Tenga en cuenta la escala con el horizonte de tiempo.\nSi tenemos \\(w_i\\) del i-ésimo activo, entonces nuestra cartera tiene valor\n\\[\n\\Pi = \\sum_{i=1}^{N} w_iS_i\n\\]\nAl final de nuestro horizonte temporal, el valor es\n\\[\\Pi + \\delta\\Pi = \\sum_{i=1}^{N} w_iS_i(1+R_i)\\]\nPodemos escribir el cambio relativo en el valor de la cartera como\n\\[\n\\frac{\\delta\\Pi}{\\Pi} = \\sum_{i=1}^N W_iR_i\\hspace{1.5cm} (1)\n\\]\ndonde\n\\[\nW_i = \\frac{w_iS_i}{\\sum_{i=1}^N w_iS_i}\n\\]\nLos pesos \\(W_i\\) suman uno.\nA partir de (1) es sencillo calcular el rendimiento esperado de la cartera\n\\[\n\\mu_{\\Pi} = \\frac{1}{T}E\\left[\\begin{array}{c}\\frac{\\delta\\Pi}{\\Pi}\\end{array}\\right] = \\sum_{i=1}^{N}W_i \\mu_i\\hspace{6cm} (2)\n\\]\nY la desviación estándar de los retornos son\n\\[\n\\sigma_{\\Pi} = \\frac{1}{\\sqrt{T}}\\sqrt{var\\left[\\begin{array}{0} \\frac{\\delta \\Pi}{\\Pi}\\end{array}\\right]} = \\sqrt{\\sum_{i=1}^{N}\\sum_{j=1}^N W_iW_j \\rho_{ij}\\sigma_i\\sigma_j}\\hspace{1.5cm} (3)\n\\]\nEn ellos hemos relacionado los parámetros de los activos individuales con la rentabilidad esperada y la desviación estándar de toda la cartera.\nSupongamos que tenemos activos en nuestra cartera que no están correlacionados, es decir, \\(\\rho_{ij} = 0\\), \\(i = j\\). Para simplificar las cosas, suponga que tienen el mismo peso, de modo que \\(W_i = \\frac{1}{N}\\). El rendimiento esperado de la cartera está representado por\n\\[\n\\mu_{\\Pi} = \\frac{1}{N}\\sum_{i=1}^N \\mu_i\n\\]\nEl promedio de los rendimientos esperados de todos los activos, y la volatilidad se convierte en\n\\[\n\\sigma_{\\Pi} = \\sqrt{\\frac{1}{N^2}\\sum_{i=1}^N \\sigma_i^2}\n\\]\nEsta volatilidad es \\(O(N^{-1/2})\\) ya que hay \\(N\\) términos en la suma. A medida que aumentamos el número de activos en cartera, la desviación estándar de los rendimientos tiende a cero.\nSupongamos que todos los activos no están correlacionados, pero veremos algo similar cuando describa el Modelo de fijación de precios de activos de capital; la diversificación reduce la volatilidad sin perjudicar las expectativas de rendimientos.\nAhora me voy a referir a la volatilidad o desviación estándar como riesgo, algo malo que debe evitarse (dentro de lo razonable), y el rendimiento esperado como recompensa, algo bueno que queremos tanto como sea posible."
  },
  {
    "objectID": "posts/port_mg/index.html#teoría-moderna-del-portafolio",
    "href": "posts/port_mg/index.html#teoría-moderna-del-portafolio",
    "title": "Portfolio management",
    "section": "Teoría Moderna del Portafolio",
    "text": "Teoría Moderna del Portafolio\nPödemos usar el marco anterior para discutir la “mejor” cartera. La definición de “mejor” fue abordada con mucho éxito por el Premio Nobel Harry Markowitz. Su modelo proporciona una manera de definir carteras que sean eficientes.\nUna cartera eficiente es aquella que tiene la recompensa más alta para un nivel de riesgo, o el riesgo más bajo para una recompensa dada. Para ver cómo funciona esto imagina que hay cuatro activos en el mundo \\(A, B, C\\) y \\(D\\) con recompensa y riesgo como se muestra en la figura 1 (ignore E por el momento). Si pudieras comprar alguno de estos (pero de momentos no te permiten más de uno), ¿cuál comprarías? eliges D? No, porque tiene el mismo riesgo que B pero menos recompensa, tiene la misma recompensa que como C pero pun mayor riesgo. Entonces, podemos descartar \\(D\\). ¿Qué pasa con B o C? Ambos son atractivos cuando se comparan con D, pero entre si no estan claro, B tiene un mayor riesgo, pero obtiene una mayor recompensa. Sin embargo, comparándolos a ambos con A vemos que no hay competencia, ya que A es la elección preferida. Si introducimos el activo E con el mismo riesgo que B y una recompensa mayor que A, entonces no podemos decir objetivamente cuál de A y E es mejor; esta es una elección subjetiva y depende de las preferencias de riesgo de un inversor.\n\n\n\nFigura 1: Riesgo y recompensa de cinco activos\n\n\nAhora suponga que tengo los dos activos A y E de la figura 2, y puedo combinar en mi cartera, ¿qué efecto tiene esto en mi riesgo/recompensa?\n\n\n\nFigura 2: Dos activos y cualquier combinación\n\n\nDe (2) y (3) tenemos\n\\[\\mu_{\\Pi} = W\\mu_{A} + (1-W)\\mu_{E}\\]\ny\n\\[\n\\sigma_{\\Pi}^2 = W^2\\sigma_{A}^2 + 2W(1-W)\\rho\\sigma_{A}\\sigma_{E} + (1-W)^2\\sigma_{E}^2\n\\]\nAquí \\(w\\) es el peso del activo A y, recordando que los pesos deben sumar uno, el peso del activo E es \\(1 - E\\).\nA medida que variamos W, también cambian el riesgo y la recompensa. La linea en el espacio de riesgo/recompensa que es parametrizada por W es una hipérbola, como se muestra en la figura 2. La parte de esta curva en negrita es eficiente, y es preferible al resto de la curva. Una ves más, las preferencias de riesgo de un individuo dirá dónde quiere estar en la curva audaz. Cuando una de las volatilidades es cero la línea se vuelvve recta. en cualquier lugar de la curva entre los dos puntos se requiere una posición larga en cada activo. Fuera de esta región, uno de los activos se vende al descubierto para financiar la compra del otro. Todo lo que sigue asume que podemos vender al descubierto tanto activo como queramos. Los resultados cambian ligeramente cuando hay restricciones.\nSi tenemos muchos activos en nuestra cartera, ya no tenemos una simple hipérbola para nuestros posibles perfiles de riesgo/recompensa; en cambio obtenemos algo como lo que se muestra en la Figura 3.\n\n\n\nFigura 3: Posibilidades de cartera y la frontera eficiente\n\n\nEsta figura ahora usa todo A, B, C, D y E, no solo A y E. Aunque B, C y D no son individualmente atractivos, bien pueden ser útiles en un portafolio, dependiendo de como se correlacionen, o no, con otras inversiones. En esta figura podemos ver la frontera eficiente marcada en negrita. Dado cualquier elección de cartera elegiríamos tener una que se encuentre en esta frontera eficiente."
  },
  {
    "objectID": "posts/port_mg/index.html#incluir-una-inversión-sin-riesgo",
    "href": "posts/port_mg/index.html#incluir-una-inversión-sin-riesgo",
    "title": "Portfolio management",
    "section": "Incluir una inversión sin riesgo",
    "text": "Incluir una inversión sin riesgo\nUna inversión sin riesgo que gana una tasa de rendimiento garantizada \\(r\\) sería el punto F en la Figura 3. Si se nos permite mantener este activo en nuestra cartera, dado que la volatilidad de este activo es cero, obtenemos la nueva frontera eficiente que es la línea recta en la Figura 3. El portafolio para el que la línea recta toca la frontera eficiente original se denomina cartera de mercado. La linea recta en sí misma se llama la línea del mercado de capitales.\n\nDonde quiero estar en la frontera eficiente?\nHabiendo encontrado la frontera eficiente, queremos aber dónde debemos estar. Esta es una elección personal, la frontera eficiente es objetiva, dados los datos, pero la “mejor” posición en ella es subjetiva.\nLa siguiente es una forma de interpretar el diagrama de riesgo/recompensa que puede ser útil en la elección de la mejor cartera.\nEl rendimiento de la cartera se distribuye normalmente porque está compuesto por activos que se distribuyen normalmente. Tiene media \\(\\mu\\) y desviación estándar \\(\\sigma\\) (he ignorado la dependencia del horizonte T). La pendiente de la línea que une la cartera con el activo libre de riesgo es\n\\[\ns = \\frac{\\mu_{\\Pi} - r}{\\sigma_{\\Pi}}\n\\]\nEsta es una cantidad importante; es una medida de la probabilidad de tenter un rendimiento que exceda r. Si \\(C(.)\\) es la función acumulada para la distribución normal estandarizada, entonces \\(C(s)\\) es la probabilidad de que el rendimiento en \\(\\Pi\\) sea al menos q \\(r\\). Mas generalmente\n\\[\nC\\left(\\begin{array}{0}\\frac{\\mu_{\\Pi} - r^*}{\\sigma_{\\Pi}}\\end{array}\\right)\n\\]\nes la probabilidad de que el rendimiento exceda \\(r^*\\). Esto sugiere que si queremos minimizar la posibilidad de una rentabilidad inferior a \\(r^*\\) debemos elegir la cartera del conjunto de fronteras eficientes, \\(\\Pi_{eff}\\) con el mayor valor de la pendiente\n\\[\n\\frac{\\mu_{\\Pi_{eff}} - r^*}{\\sigma_{\\Pi_{eff}}}\n\\]\nPor el contrario, si mantenemos la pendiente de esta línea fija en \\(s\\), entonces podemos decir que con una confianza de \\(C(s)\\) no perderemos más que\n\\[\n\\mu_{\\Pi_{eff}} - s\\sigma_{\\Pi_{eff}}\n\\]\nNuestra elección de cartera podría determinarse maximizando esta cantidad. Estas dos estrategías se muestran esquemáticamente en la Figura 5.\n\n\n\nFigura 5: Dos sencillas formas de elegir la mejor cartera eficiente\n\n\nNinguno de estos métodos da resultados satisfactorios cuando existe inversión libre de riesgo entre los activos y hay ventas cortas sin restricciones, ya que dan como resultado un endeudamiento infinito.\nOtra forma de elegir la cartera óptima es con la ayuda de una función de utilidad. Este enfoque es popular entre los economistas. En la Figura 6 muestro las curvas de indiferencia y la frontera eficiente.\n\n\n\nFigura 6: Frontera eficiente y las curvas de indiferencia\n\n\nLas curvas reciben este nombre porque representan lineas a las cual el inversionista es indiferente al trade-off riesgo/recompensa. Un inversionista quiere un alto rendimiento y riesgo bajo. Frente a las carteras A y B en la Figura, ve a A con bajo rendimiento y bajo riesgo, pero B tiene una mejor recompensa a costa de un mayor riesgo. El inversor es indiferente entre estos dos. Sin embargo, C es mejor que ambos, estando en una curva preferida."
  },
  {
    "objectID": "posts/port_mg/index.html#markowitz-en-la-práctica",
    "href": "posts/port_mg/index.html#markowitz-en-la-práctica",
    "title": "Portfolio management",
    "section": "Markowitz en la Práctica",
    "text": "Markowitz en la Práctica\nLas entradas al modelo de Markowitz son rendimientos esperados, volatilidades y correlaciones. Con \\(N\\) activos esto significa \\(N + N + N(N-1)/2\\) parámetros. La mayoría de estos no se pueden conocer con precisión (¿existen siquiera?); sólo las volatilidades son en absoluto confiable. Habiendo ingresado estos parámetros, debemos optimizar sobre todos los pesos de los activvos en la cartera: Elija un riesgo de cartera y encuentre los pesos que haqcen que el rendimiento de la cartera sea máximo sujeto a esta volatilidad. Este es un proceso que consume mucho tiempo computacionalmente a menos que uno solo tenga una pequeña cantidad de activos.\nEl problema con la implementación práctica de este modelo lo realizaré enm otro post que publicare posterioremente, usando Python. Por los momentos es importante comprender la lógica del modelo."
  },
  {
    "objectID": "posts/port_mg/index.html#modelo-de-precios-de-activos-de-capital-capital-asset-pricing-model",
    "href": "posts/port_mg/index.html#modelo-de-precios-de-activos-de-capital-capital-asset-pricing-model",
    "title": "Portfolio management",
    "section": "Modelo de Precios de Activos de Capital (Capital Asset Pricing Model)",
    "text": "Modelo de Precios de Activos de Capital (Capital Asset Pricing Model)\nAntes de discutir el modelo de fijación de precios de activos de capital o CAPM debemos introducir la idea del valor \\(\\beta\\). El parámetro \\(\\beta_i\\), de un activo en relación con una cartera \\(M\\) es la relación de la covarianza entre el rendimiento del valor y el rendimiento de la cartera a la varianza de la cartera. Del siguiente modo\n\\[\n\\beta_i = \\frac{Cov[R_iR_M]}{Var[R_M]}\n\\]\n\nEl Modelo de Indice Unico\nAhora construire un modelo de índices único y describiré las extenciones más adelante. Voy a relacionar el rendimiento de todos los activos al rendimiento de un índice representativo, \\(M\\). Este índice suele ser tomado como un índice bursátil de amplio rango en el modelo de índice único. Nosotros escribimos el rendimiento del i-ésimo activo como\n\\[\nR_i = \\alpha_i + \\beta_iR_M + \\epsilon_i\n\\]\nUsando esta representación podemos ver que el rendimiento de un activo se puede descomponer en tres partes:\n\nUna media constante\nUna parte aleatoria común con el índice \\(M\\) y,\nuna parte aleatoria no correlacionada con el índice, \\(\\epsilon_i\\).\n\nLa parte aleatoria \\(\\epsilon_i\\) es única para el i-ésimo activo, y tiene media cero. Observe cómo todos los activos están relacionados con el índice \\(M\\) pero son de contrario completamente sin correlación.\nEn la Figura 7 se muestra un gráfico de rendimiento de las acciones de Walt Disney frente a los rendimientos del S&P 500; \\(\\alpha\\) y \\(\\beta\\) se pueden determinar a partir de un análisis de regresión lineal. Los datos utilizados en este gráfico abarcaron desde enero de 1985 hasta casi finales de 1997.\n\n\n\nFigura 7: Rentabilidad de las acciones de Walt Disney frente a la rentabilidad del S&P 500.\n\n\nEl rendimiento esperado del índice se denotará por \\(\\mu_M\\) y su desviación estándar por \\(\\sigma_M\\). El rendimiento esperado del i-ésimo activo es entonces:\n\\[\n\\mu_i = \\alpha_i + \\beta_i\\mu_M\n\\]\ny la desviación estandar\n\\[\n\\sigma_i = \\sqrt{\\beta_i^2\\sigma_M^2 + e_i^2}\n\\]\ndonde \\(e_i\\) es la desviación estándar de \\(\\epsilon_i\\).\nSi tenemos una cartera de dichos activos, el rendimiento viene dado por\n\\[\n\\begin{eqnarray}\n\\frac{\\delta \\Pi}{\\Pi} = \\sum_{i=1}^N W_iR_i = \\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\alpha_i\\end{array}\\right) + R_M\\left(\\begin{array}{0} \\sum_{i=1}^N W_i\\beta_i\\end{array}\\right) + \\sum_{i=1}^N W_i\\epsilon_i\n\\end{eqnarray}\n\\]\nDe esto se sigue que\n\\[\n\\mu_\\Pi = \\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\alpha_i\\end{array}\\right) + E[R_M]\\left(\\begin{array}{0}\\sum_{i=1}^N W_i\\beta_i\\end{array}\\right)\n\\]\nPodemos escribir\n\\[\n\\alpha_\\Pi = \\sum_{i=1}^NW_i\\alpha_i \\hspace{1cm}y \\hspace{1cm} \\beta_\\Pi = \\sum_{i=1}^NW_i\\beta_i\n\\]\nEntonces,\n\\[\n\\mu_\\Pi = \\alpha_\\Pi + \\beta_\\Pi\nE[R_M] = \\alpha_\\Pi + \\beta_\\Pi \\mu_M\\]\nDe manera similar, el riesgo se mide por\n\\[\n\\sigma_\\Pi = \\sqrt{\\sum_{i=1}^N\\sum_{j=1}^N W_iW_j\\beta_i\\beta_j\\sigma_M^2 + \\sum_{i=1}^N W_i^2 e_i^2}\n\\]\nSi los pesos son casi iguales, \\(N^{-1}\\), entonces los términos finales dentro de la raíz cuadrada también son \\(O(N^{-1})\\). Por lo tanto, esta expresión es, al orden principal como \\(N \\longrightarrow \\infty\\),\n\\[\n\\sigma_\\Pi = \\left|\\begin{array}{0}\\sum_{i=1}^N W_i\\beta_i\\end{array}\\right|\\sigma_M = \\left|\\begin{array}{0}\\beta_\\Pi\\end{array}\\right|\\sigma_M\n\\]\nObserve que la contribución de los no correlacionados a la cartera se desvanece a medida que aumentamos le número de activos en la cartera: El riesgo asociado con el \\(\\epsilon_s\\) se llama riesgo diversificable. El riesgo restante, que esta correlacionado con el índice, se denomina riesgo sistematico.\n\n\nElegir la Cartera Optima\nEl principal es el mismo que el modelo de Markowitz para la elección óptima de cartera. La diferencia es que hay muchos menos parámetros para ingresar, y el cálculo es mucho más rapido.\nEl procedimiento es el siguiente. Elija un valor para el rendimiento de la cartera \\(\\mu_\\Pi\\). Sujeto a esta restricción, minimizar \\(\\sigma_\\Pi\\). Repita esta minimización para diferentes rendimientos de carteera para obtener la frontera eficiente. La posición es esta curva es entonces una elección subjetiva."
  },
  {
    "objectID": "posts/port_mg/index.html#medición-del-desempeño",
    "href": "posts/port_mg/index.html#medición-del-desempeño",
    "title": "Portfolio management",
    "section": "Medición del Desempeño",
    "text": "Medición del Desempeño\nSi uno ha seguido una de las estratetias de asignación de activos, o simplemente ha negociado en instinto, ¿puede uno decir qué tan bien lo ha hecho? ¿Fueron los resultados sobresalientes deido a un extraño instinto natural, o los horribles resultados fueron simplemente mala suerte?\nEl rendimiento ideal sería uno en el que los rendimientos superaran la tasa libre de riesgo, pero en una moda consistente. No solo es importante obtener un alto rendimiento de la gestión de la cartera, pero uno debe lograr esto con la menor aleatoriedad posible.\nLas dos medidas más comunes de rendimiento por unidad de riesgo son\n\nRelación de Sharpe de recompensa a variabilidad y el\níndice de Treynor de recompensa a la volatilidad.\n\nEstos se definen como\n\\[\n\\begin{eqnarray}\nratio Sharpe &=& \\frac{\\mu_\\Pi - r}{\\sigma_\\Pi}\\\\[0.2cm]\nratio Treynor &=& \\frac{\\mu_\\Pi - r}{\\beta_\\Pi}\n\\end{eqnarray}\n\\]\nEn estos \\(\\mu\\) y \\(\\sigma\\) son el rendimiento realizado y la desviación estándar de la cartera durante el período. El \\(\\beta\\) es una medida de la volatilidad de la cartera. El ratio de Sharpe generalmente se usa cuando la cartera es la totalidad de la inversión de uno y el ratio de Treynor cuando se examina el rendimiento de un componente de la cartera de toda la empresa, digamos.\nCuando la cartera baja las dos medidas son las mismas (hasta un factor del mercado Desviación Estándar)\n\n\n\nFigura 8: un buen y un gerente (manager); mismos rendimientos, distintas volatilidades\n\n\nLa Figura 8 muestra el valor de la cartera frente al tiempo para un buen administrador y un mal administrador."
  },
  {
    "objectID": "posts/port_mg/index.html#resumen",
    "href": "posts/port_mg/index.html#resumen",
    "title": "Portfolio management",
    "section": "Resumen",
    "text": "Resumen\n\nLa gestión de carteras y la asignación de activos consisten en asumir riesgos a cambio de una recompensa.\nLas preguntas son, ¿como decidir cuánto riesgo tomar? ¿cómo obtener el mejor rendimiento? Pero la teoría de los derivados se basa en no correr ningún riesgo en absoluto, por lo que he dedicado tiempo a gestión de cartera en este post.\nExiste tanta incertidumbre en el tema de las finanzas que la eliminación del riesgo es casi imposible y las ideas detrás de la gestión de carteras deben ser apreciadas por cualquier persona involucrada en derivados."
  },
  {
    "objectID": "posts/port_mg/index.html#definición",
    "href": "posts/port_mg/index.html#definición",
    "title": "Portfolio management",
    "section": "Definición",
    "text": "Definición\nEl valor en riesgo es una estimación, con un cierto grado de confianza, de cuánto se puede perder de la cartera, en un horizonte de tiempo dado.\n\nEl grado de confianza normalmente se establece en 95%, 87.5%, 99%, etc. El horizonte temporal de interés puede ser de un día, por ejemplo, para actividades comerciales o de meses para gestión de cartera.\nComo ejemplo de VaR, podemos calcular (mediane los métodos que e describirán aquí) que durante la próxima semana hay un 95% de probabilidad de que no perdamos más de $10 millones. Podemos escribir esto como\n\\[\nProb\\{\\delta V \\leq -\\$10 m\\} = 0.05\n\\]\ndonde \\(\\delta V\\) es el cambio en el valor de la cartera. (uso \\(\\delta\\) para “el cambio en” para enfatizar que estamos considerando cambios en un tiempo finito.) En símbolos, esto es\n\\[\nProb\\{\\delta V \\leq -VaR\\}= 1- c\n\\]\ndonde el grado de confianza es \\(c\\).\nEl VaR se calcula asumiendo circustancias de mercado normales, lo que significa que el mercado extremo no se consideran condiciones como choques, o se examinan por separado. Así, efectivamente, el VaR mide lo que se puede esperar que suceda durante la operación diaria de una institución.\nPara el computo del VaR requerimos disponer al menos de los siguientes datos:\n\nLos precios vigentes de todos los activos en cartera y,\nsus volatilidadesa y correlaciones entre ellos\n\nSi los bienes son negociados podemos tomar los precios del mercado (marking to market).\nPor lo general, se supone que el movimiento de los componentes de la cartera son aleatorias y extraídas de distribuciones normales."
  },
  {
    "objectID": "posts/port_mg/index.html#var-para-un-único-activo",
    "href": "posts/port_mg/index.html#var-para-un-único-activo",
    "title": "Portfolio management",
    "section": "VaR para un único activo",
    "text": "VaR para un único activo\nEmpecemos por estimar el VaR de una cartera compuesta por un único activo.\nSupongamos que tenemos una cantidad de una acción con precio \\(S\\) y volatilidad \\(\\sigma\\). Queremos saber con el 99% de confianza cuál es el máximo que podemos perder durante la próxima semana, estoy usando notación deliberadamente similar al del mundo de los derivados\n\\[\n\\sigma S\\left(\\begin{array}{0}\\frac{1}{52}\\end{array}\\right)^{1/2}\n\\]\nya que el paso de tiempo es \\(1/52\\) de un año. Finalmente, debemos calcular la posición de la cola extrema izquierda de esta distribución correspondiente a\n\\[\n1\\% = 100 - 99\\%\n\\]\nSolo necesitamos hacer esto para la distribución normal estandarizada, porque podemos llegar a cualquier otra distribución escalando. En la siguiente tabla, vemos que el intervalo de confianza del 99% corresponde a 2.33 desviaciones estándar de la media.\n\nGrado de confianza y la relación con la desviación de la media.\n\n\nGrado de Confianza (%)\nNúmero de desviaciones estándar de la media\n\n\n\n\n99\n2.326342\n\n\n98\n2.053748\n\n\n97\n1.88079\n\n\n96\n1.750686\n\n\n95\n1.644853\n\n\n90\n1.281551\n\n\n\n\n\n\n\nDado que tenemos una cantidad de acciones, el VaR es dado por\n\\[\n2.33\\sigma\\triangle S(1/52)^{1/2}\n\\]\nDe manera general, si el horizonte de tiempo es \\(\\delta t\\) y el grado de confianza es \\(c\\), tenemos\n\\[\nVaR = -\\sigma \\triangle S(\\delta t)^{1/2}\\alpha(1-c)\n\\]\ndonde \\(\\alpha(.)\\) es la función de distribución acumulativa inverdsa para la distribución Normal estandarizada, que se muestra en la Figura 9,\n\n\n\nFigura 9: Función de distribución acumulativa inversa para la distribución Normal Estandarizada.\n\n\nEn la Figura 10 hemos supuesto que el rendimiento del activo se distribuye normalmente con una media cero. La suposición de media cero es válida para horizontes temporales cortos: La desviación estándar del rendimiento escala con la raíz cuadrada del tiempo pero la media escala con el tiempo mismo.\n\n\n\nFigura 10: La distribución de los rendimientos futuros de las acciones.\n\n\nPara horizontes a más largo plazo, el rendimiento se desplaza hacia la derecha (es de esperar) en una cantidad proporcional al horizonte de tiempo. Por lo tanto, para escalas de tiempo más largas, la ecuación anterior debe modificarse para tener en cuenta el derivado del valor del activo. Si la tasa de este derivado es \\(\\mu\\) entonces la ecuación anterior se convierte en\n\\[\nVaR = \\triangle S(\\mu \\delta t - \\sigma \\delta t^{1/2} \\alpha(1-c))\n\\]"
  },
  {
    "objectID": "posts/port_mg/index.html#var-para-un-portafolio-o-cartera",
    "href": "posts/port_mg/index.html#var-para-un-portafolio-o-cartera",
    "title": "Portfolio management",
    "section": "VaR para un Portafolio o Cartera",
    "text": "VaR para un Portafolio o Cartera\nSi conocemos las volatilidades de todos los activos de nuestra cartera y las correlaciones entre ellos entonces podemos calcular el VaR para toda la cartera.\nSi la volatilidad del i-ésimo activo es \\(\\sigma_i\\) y la correlación entre el i-ésimo y el j-ésimo activo es \\(\\rho_{ij}\\) (con \\(\\rho_{ii} = 1\\)), entonces el VaR para la cartera compuesta por M activos con una participación de i del i-ésimo activo es\n\\[\n-\\alpha(1-c)\\delta t^{1/2}\\sqrt{\\sum_{j=1}^M\\sum_{i=1}^M \\triangle_i\\triangle_j\\sigma_i\\sigma_j\\rho_{ij}S_iS_j}\n\\]"
  },
  {
    "objectID": "posts/port_mg/index.html#uso-del-var-como-medida-de-rendimiento",
    "href": "posts/port_mg/index.html#uso-del-var-como-medida-de-rendimiento",
    "title": "Portfolio management",
    "section": "Uso del VaR como medida de rendimiento",
    "text": "Uso del VaR como medida de rendimiento\nUno de los usos del VaR en la medición del desempeño de bancos, mesas o comerciantes. En el pasado, el “talento comercial” se ha medido únicamente en términos de ganancias; la bonificación de un comerciante esta relacionado con esa ganancia. Esto anima a los comerciante a asumir riesgos; piensa en lanzar una moneda al aire y recibes un porcentaje de la ganancia pero sin la desventaja (que se lleva el banco), ¿cuánto apostarías? Una mejor medida del talento comercial podría tener en cuenta el riesgo en tal apuesta, y premiar una buena relación rendimiento-roesgo. El ratio\n\\[\n\\frac{\\mbox{Retorno superior al libre de riesgo}}{volatilidad} = \\frac{\\mu - r}{\\sigma}\n\\]\nLa relación de Sharpe, es una medida de este tipo. Alternativamente, use VaR como la medida de riesgo y ganancia/pérdida como medida de rendimiento.\n\\[\n\\frac{\\mbox{Perdidads y ganancias diarias}}{\\mbox{VaR diaria}}\n\\]"
  },
  {
    "objectID": "documentos.html#ejercicios-a-resolver-primer-modulo",
    "href": "documentos.html#ejercicios-a-resolver-primer-modulo",
    "title": "Cursos",
    "section": "Ejercicios a Resolver Primer Modulo",
    "text": "Ejercicios a Resolver Primer Modulo\n\nGuía de Ejercicios #1\nGuía de Ejercicios #2\nGuía de Ejercicios # 3"
  },
  {
    "objectID": "documentos.html#videos",
    "href": "documentos.html#videos",
    "title": "Cursos",
    "section": "Videos",
    "text": "Videos\n\nIntroducción a R\nCreación y Operaciones con Vectores en R\nMatrices y DataFrame en R\nCreación de Funciones en R\nIntroducción a Teoría del Productor\nExplicación de Ejercicio\nIntroducción a Estructuras de Mercado\nEjercicio mercado en competencia perfecta"
  },
  {
    "objectID": "posts/estructuras_mercado/index.html",
    "href": "posts/estructuras_mercado/index.html",
    "title": "Estructuras de Mercado con Python",
    "section": "",
    "text": "Este post tiene como objetivo dar a conocer la importancia del software de Python en el ambito microeconomico, particularmente en este caso hablamos de las diferentes estructuras de mercado; competencia perfecta, monopolio y oligopolio."
  },
  {
    "objectID": "posts/estructuras_mercado/index.html#condiciones-necesaria-para-la-competencia-perfecta",
    "href": "posts/estructuras_mercado/index.html#condiciones-necesaria-para-la-competencia-perfecta",
    "title": "Estructuras de Mercado con Python",
    "section": "Condiciones necesaria para la competencia perfecta",
    "text": "Condiciones necesaria para la competencia perfecta\n\nMuchos productores, ninguno de los cuales tiene una gran cuota de mercado.\nUna industria puede ser perfectamente competitiva sólo si los consumidores consideran como equivalentes a los productos de todos los productores (producto homogéneo)"
  },
  {
    "objectID": "posts/estructuras_mercado/index.html#libre-entrada-y-salida",
    "href": "posts/estructuras_mercado/index.html#libre-entrada-y-salida",
    "title": "Estructuras de Mercado con Python",
    "section": "Libre entrada y salida",
    "text": "Libre entrada y salida\nExiste libre entrada y salida en una industria cuando nuevos productores pueden entrar facilmente en esa industria a los que ya estan en ella pueden abondonarla sin coste alguno.\n\nRegla de Producción Optima\nLa regla de producción optima dice que el beneficio se maximiza cuando se produce la cantidad de output para la cual el ingreso marginal de la última unidad de output producida es igual a su coste marginal.\n\\[\nIMg = CMg\n\\]\n\n\nFunción de Benenficios\nLa función de beneficios \\((\\pi)\\) representa las diferencias entre los costos totales, \\(C(Q)\\) e ingresos totales,\\(R(Q)\\) , de las empresas\n\\[\n\\pi = R(Q) - C(Q)\n\\]\n\n\nTomador de Precios\nPrecio igual al costo marginal\n\\[\n\\begin{eqnarray*}\nCMg = IMg = P\n\\end{eqnarray*}\n\\]\nPor tanto, se dice que el beneficio de una empresa precio-aceptante se maximiza produciendo la cantidad de output para la cual el costo marginal de la última unidad producida es igual al precio de mercado, tal como se aprecia en el siguiente gráfico\n\n\n\nCantidad de producto que maximiza el beneficio de una empresa precio-aceptante"
  },
  {
    "objectID": "posts/estructuras_mercado/index.html#costes-y-producción-en-el-corto-plazo",
    "href": "posts/estructuras_mercado/index.html#costes-y-producción-en-el-corto-plazo",
    "title": "Estructuras de Mercado con Python",
    "section": "Costes y Producción en el Corto Plazo",
    "text": "Costes y Producción en el Corto Plazo\nEn el corto plazo tenemos las siguientes condiciones de producción de empresas competitivas\n\n\n\n\n\n\n\nCondiciones\nResultados\n\n\n\n\nP > CVMe mínimo\nLa empresa produce en el corto plazo. Si P < CTMe mínimo, la empresa cubre sus costos variables y parte de sus costes fijos pero no todos. Si P > CTMe mínimo, la empresa cubre todos sus costes variables y sus costes fijos.\n\n\nP = CVMe mínimo\nLa empresa es indiferente entre producir en el corto plazo o no producir. Cubre exactamente sus costes variables.\n\n\nP < CVMe mínimo\nLa empresa cierra en el corto plazo. No cubre sus costes variables."
  },
  {
    "objectID": "posts/estructuras_mercado/index.html#ejemplo---corto-plazo",
    "href": "posts/estructuras_mercado/index.html#ejemplo---corto-plazo",
    "title": "Estructuras de Mercado con Python",
    "section": "Ejemplo - Corto Plazo",
    "text": "Ejemplo - Corto Plazo\nPrimero resolveremos el siguiente ejercicio de manera manual y posteriormente lo resolveremos en Python.\nSuponga que la empresa tiene una curva de costos de corto plazo dada por\n\\[\nC(Q) = 100 + 20Q + Q^2\n\\]\n\n¿Cuál es la ecuación para el costo variable Medio?\n¿Cuál es el valor mínimo para el costo variable promedio?\n¿Cuál es la curva de oferta de corto plazo?\n\nSolución\n\nDada la función de costo \\(C(Q) = 100 + 20Q + Q^2\\) es claro que el costo variable, CV, esta dado por \\[CV = 20Q + Q^2\\] por tanto su costo variable promedio es \\[CVMe = \\frac{CV}{Q} = 20 + Q\\]\nAhora bien, su costo marginal sabemos que unicamente requiere aplicar la regla de diferenciación, ya que \\[CMg = \\frac{\\partial C(Q)}{\\partial Q} = 20 + 2Q\\]\nSi queremos encontrar el costo variable promedio mínimo, \\[CVMe_{\\min}\\], se obtiene como \\[CMg = CVMe \\longrightarrow Q = \\fbox{0}\\]\nEntonces la función de oferta es: \\[\\begin{eqnarray*}CMg &=& p\\\\[0.2cm] 20 + 2Q &=& P\\\\[0.2cm] Q(P) &=& \\frac{P}{2} - 10 \\end{eqnarray*}\\]\n\nPor tanto, también podemos obtener el precio de equilibrio, ya que \\[0 = \\frac{P}{2} - 10 \\longrightarrow P = \\fbox{20}\\]\nAhora, encontremos estos resultados en Python:\n\n# Paquete previo \nfrom sympy import *\nQ = symbols(\"Q\")\n\n\n# función de costo de corto plazo \nCT = 100 + 20*Q + Q**2\n# costo variale promedio \nCV = 20 + Q \n# Encontrar el costo variable minimo \n# Primero: costo marginal\n\nCM = diff(CT,Q)\n\n\n# igualar costo marginal y costo variable promedio \nsolve(Eq(CM,CV))\n\n[0]\n\n\n\ncantidad = solve(Eq(CM,CV))\ncantidad[0]\n\n\\(\\displaystyle 0\\)\n\n\n\nP = CV.subs({Q:cantidad[0]})\nP\n\n\\(\\displaystyle 20\\)\n\n\n\nplot(CT, CT/Q, CV, CM, (Q,0,100), xlim = (0, 100), ylim = (0,100), xlabel = \"Q\", ylabel = \"P\")\n\n\n\n\n<sympy.plotting.plot.Plot at 0x24e362bed90>\n\n\nPuedes notar lo rápido y fácil que resulta realizar estos procedimientos con Python y la utilidad que puede brindarte en caso de que trabajes con volumnes de datos."
  },
  {
    "objectID": "posts/estructuras_mercado/index.html#ejemplo-1--corto-plazo",
    "href": "posts/estructuras_mercado/index.html#ejemplo-1--corto-plazo",
    "title": "Estructuras de Mercado con Python",
    "section": "Ejemplo # 1- Corto Plazo",
    "text": "Ejemplo # 1- Corto Plazo\nPrimero resolveremos el siguiente ejercicio de manera manual y posteriormente lo resolveremos en Python.\nSuponga que la empresa tiene una curva de costos de corto plazo dada por\n\\[\nC(Q) = 100 + 20Q + Q^2\n\\]\n\n¿Cuál es la ecuación para el costo variable Medio?\n¿Cuál es el valor mínimo para el costo variable promedio?\n¿Cuál es la curva de oferta de corto plazo?\n\nSolución\n\nDada la función de costo \\(C(Q) = 100 + 20Q + Q^2\\) es claro que el costo variable, CV, esta dado por \\[CV = 20Q + Q^2\\] por tanto su costo variable promedio es \\[CVMe = \\frac{CV}{Q} = 20 + Q\\]\nAhora bien, su costo marginal sabemos que unicamente requiere aplicar la regla de diferenciación, ya que \\[CMg = \\frac{\\partial C(Q)}{\\partial Q} = 20 + 2Q\\]\nSi queremos encontrar el costo variable promedio mínimo, \\[CVMe_{\\min}\\], se obtiene como \\[CMg = CVMe \\longrightarrow Q = \\fbox{0}\\]\nEntonces la función de oferta es: \\[\\begin{eqnarray*}CMg &=& p\\\\[0.2cm] 20 + 2Q &=& P\\\\[0.2cm] Q(P) &=& \\frac{P}{2} - 10 \\end{eqnarray*}\\]\n\nPor tanto, también podemos obtener el precio de equilibrio, ya que \\[0 = \\frac{P}{2} - 10 \\longrightarrow P = \\fbox{20}\\]\nAhora, encontremos estos resultados en Python:\n\n# Paquete previo \nfrom sympy import *\nQ = symbols(\"Q\")\n\n\n# función de costo de corto plazo \nCT = 100 + 20*Q + Q**2\n# costo variale promedio \nCV = 20 + Q \n# Encontrar el costo variable minimo \n# Primero: costo marginal\n\nCM = diff(CT,Q)\n\n\n# igualar costo marginal y costo variable promedio \nsolve(Eq(CM,CV))\n\n[0]\n\n\n\ncantidad = solve(Eq(CM,CV))\ncantidad[0]\n\n\\(\\displaystyle 0\\)\n\n\n\nP = CV.subs({Q:cantidad[0]})\nP\n\n\\(\\displaystyle 20\\)\n\n\n\nplot(CT, CT/Q, CV, CM, (Q,0,100), xlim = (0, 100), ylim = (0,100), xlabel = \"Q\", ylabel = \"P\")\n\n\n\n\n<sympy.plotting.plot.Plot at 0x1d21a63ab20>\n\n\nPuedes notar lo rápido y fácil que resulta realizar estos procedimientos con Python y la utilidad que puede brindarte en caso de que trabajes con volumnes de datos.\n\nEjemplo # 2 - Corto Plazo\nAhora suponga que la empresa tiene una curva costos en el corto plazo de la siguiente forma:\n\\[\nC(Q) = 1 + 10Q + Q^2\n\\]\nSi la empresa opera en un mercado perfectamente competitivo, donde \\(P = 12\\), ¿Cuál será los beneficios de la empresa en el corto plazo?\nSolución\nSabemos que la función de beneficios esta dada por\n\\[\n\\pi = R - C\n\\]\nentonces,\n\\[\n\\frac{\\partial \\pi}{\\partial Q} = IMg - CMg = 0\n\\]\nasí pues,\n\\[\nCMg = 10 + 2Q \\hspace{1cm}y\\hspace{1cm} IMg = P\n\\]\npor tanto,\n\\[\n\\begin{eqnarray*}\nCMg &=& IMg\\\\[0.2cm]\n10 + 2Q &=& P\\\\[0.2cm]\nQ &=& \\frac{P}{2} - 5\\\\[0.2cm]\nQ &=& \\frac{12}{2} - 5, \\hspace{2cm}\\mbox{ya que P = 12}\\\\[0.2cm]\nQ &=& \\fbox{1}\n\\end{eqnarray*}\n\\]\nentonces,\n\\[\n\\pi = 12 - (1 + 10 +1) = \\fbox{0}\n\\]\nAhora veamos esta solución en Python:\n\n# Función de costos a corto plazo \nQ = symbols(\"Q\")\nCT = Q**2 + 10*Q + 1\nP = 12\nR = P*Q\n# costo marginal\nCM = diff(CT,Q)\nCM\nIM = diff(R,Q)\nIM\ncantidad = solve(Eq(IM,CM))\nprint(\"El valor de la producción que garantiza un equilibrio será:\", cantidad[0])\n\nEl valor de la producción que garantiza un equilibrio será: 1\n\n\nEste resultado lo que nos dice es que la empresa oferta una unidad de producción \\(Q = 1\\).\n\n# Beneficio = IT - CT\ncosto = CT.subs({Q:cantidad[0]})\ncosto\n\n\\(\\displaystyle 12\\)\n\n\n\ningreso = R.subs({Q:cantidad[0]})\ningreso \n\n\\(\\displaystyle 12\\)\n\n\n\nBeneficios = R - CT\npi = Beneficios.subs({Q:cantidad[0]})\npi\n\n\\(\\displaystyle 0\\)\n\n\n\nplot(CT,CM,CT/Q,(Q,0,60), xlim=(0,5), ylim=(0,30), xlabel='Q', ylabel='CT,CM')\n\n\n\n\n<sympy.plotting.plot.Plot at 0x1d219ed7ac0>\n\n\nRecuerde que todo este análisis se realizo para un mercado en competencia perfecta a corto plazo.\nPronto actualizare para el mercado en competencia perfecta a largo plazo, monopolio, e introducirnos un poco a la teoria de juegos."
  }
]